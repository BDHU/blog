<!doctype html><html><head><meta name=generator content="Hugo 0.98.0"><meta charset=utf-8><meta name=viewport content="width=device-width"><link href=/blog/index.xml rel=alternate type=application/rss+xml title=std::bodun::blog><link href=/blog/index.xml rel=feed type=application/rss+xml title=std::bodun::blog><title>std::bodun::blog</title><link rel=stylesheet href=https://www.bodunhu.com/blog/css/colors-preference.min.3ad46450d59177206f28dcac6dd37d7032546cd0e43b77a576f6aa60a5e4d5d8.css><link rel="shortcut icon" href=https://www.bodunhu.com/blog/favicon.ico><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},svg:{fontCache:"global"}}</script><script type=text/javascript id=MathJax-script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js async></script><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-108144808-1","auto"),ga("send","pageview"))</script><script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-108144808-1","auto"),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script></head><body><header id=header><h1><a href=https://www.bodunhu.com/blog/>std::bodun::blog</a></h1><p>PhD student at University of Texas at Austin ðŸ¤˜. Doing systems for ML.</p></header><div id=page><div id=sidebar><nav><ul class=nav><li><a href=/blog/posts/><span>Archive</span>&nbsp;&nbsp;</a></li><li><a href=https://www.bodunhu.com/><span>About</span>&nbsp;&nbsp;</a></li><li><a href=/blog/index.xml><span>Feed</span>&nbsp;&nbsp;</a></li></ul></nav></div><div id=content><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/flexflow/>FlexFlow</a></h1><div class=post-content><p>FlexFlow is a deep learning framework that discovers a fast parallelization strategy for distributed DNN training. It uses SOAP (Sample-Operation-Attribute-Parameter) search space of parallelization strategies. in short, FlexFlow automates the parallelization of model training.</p></div><p class=meta>Posted on <span class=postdate>22. February 2022</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/add-mermaid-to-hugo-with-dark-mode/>Add Mermaid to Hugo with Dark Mode</a></h1><div class=post-content><p>Recently, I was revisiting materials in Deep Learning. I need tools that generate diagrams easily. Drawing the graphs from scratch and upload them individually to the image hosting platform is a daunting process. This is when Mermaid comes into rescue. Now I can generate diagrams directly using Markdown. Here&rsquo;s how to do it inside a Hugo site.</p></div><p class=meta>Posted on <span class=postdate>15. February 2022</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/cross-entropy-loss/>Cross Entropy Loss</a></h1><div class=post-content><p>Many deep learning tasks involve classification, where a model outputs a series of probabilities for their corresponding labels. The goal is to correctly predict a given input&rsquo;s label. Mathematically, it means generating max probabilities for the correct label. The probabilities are generated through a process called softmax.
The softmax function outputs a vector \(\hat{y}\), which represents estimated conditional probabilities of each class given an input \(x\), For example, \(\hat{y}_1 = P(y=\textrm{car}\ |\ x)\). â€¦</p></div><p class=meta>Posted on <span class=postdate>13. February 2022</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/maximum-likelihood-for-classification/>Maximum Likelihood for Classification</a></h1><div class=post-content><p>Let&rsquo;s say we want to classify an input text \(y\) and give it a label \(x\). Formally, we want to find:
\[ \textrm{argmax} P(x | y) \]
By Bayes&rsquo; rule this is the same as
\[ \textrm{argmax} \frac{P(y|x)P(y)}{P(x)} \]
Suppose we have five documents as training data and one document as the input as testing data. Our objective is to give a label to the test sentence.
Credit: Eunsol Choi Let&rsquo;s define the probability of class as (\(N\) is the total number of classes) â€¦</p></div><p class=meta>Posted on <span class=postdate>24. January 2022</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/machine-learning-system-resources/>Machine Learning System Resources</a></h1><div class=post-content><p>This is my personal list of resources related to machine learning systems. Feel free to drop me an email if you think there&rsquo;s something worth mentioning. I will try to update this page frequently to include the most recent stuffs in mlsys. Resources Facebook&rsquo;s external large-scale work Courses 15-884: Machine Learning Systems: offered by Tianqi Chen at CMU. CSE 291F: Advanced Data Analytics and ML Systems: offered by Arun Kumar â€¦</p></div><p class=meta>Posted on <span class=postdate>08. January 2022</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/megatron-with-fastmoe/>Megatron with FastMoE</a></h1><div class=post-content><p>This is a guide on setting up Megatron-LM with FastMoE. Megatron is a transformer developed by the Applied Deep Learning Research team at NVIDIA. FastMoE enables PyTorch support for the Mixture of Experts (MoE) models. We use the FastMoE layer to replace the MLP layers in the transformer language model.
Prerequisites Docker We recommend using one of NGC&rsquo;s recent PyTorch containers. The Megatron-LM repo uses pytorch:20.12-py3. We pull the image with: â€¦</p></div><p class=meta>Posted on <span class=postdate>01. December 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/set-up-slurm-across-multiple-machines/>Set up Slurm across Multiple Machines</a></h1><div class=post-content><p>To install Slurm, we need to have admin access to the machine. This post explains how I got Slurm running in multiple Linux servers. All servers are running on Ubuntu 18.04 LTS.</p></div><p class=meta>Posted on <span class=postdate>16. November 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/paper-review-dynamic-tensor-rematerialization/>Paper Review - Dynamic Tensor Rematerialization</a></h1><div class=post-content><p>Dynamic Tensor Rematerialization (DTR) treats GPU memory as a large cache, where tensors can be evicted to save memory, and recomputed if needed later.
DTR&rsquo;s eviction policy relies on the heuristic \(h\). The heuristic assigns a value \(h(t)\) to each resident tensor \(t\), approximating the cost of evicting the tensor. DTR evicts the tensor with the lowest cost based on the value of \(h\). \(h\) can factor in arbitrary metadata. â€¦</p></div><p class=meta>Posted on <span class=postdate>09. November 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/paper-review-capuchin-tensor-based-gpu-memory-management-for-deep-learning/>Paper Review - Capuchin: Tensor-based GPU Memory Management for Deep Learning</a></h1><div class=post-content><p>This paper aims to reduce GPU memory usage during DNN training. Capuchin achieves this goal though swapping and recomputation, using tensor as unit of operation. The major question is how to balance between swapping and recomputation to achieve max resource utilization.
Swap and Recomputation Benefit The ultimate goal of swapping and recomputation is to hide the overhead as much as possible to minimize the wait time of back-access (a tensor evicted earlier being accessed again). â€¦</p></div><p class=meta>Posted on <span class=postdate>07. November 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/starting-out-phd/>Starting Out PhD</a></h1><div class=post-content><p>Today marks the third month of my PhD life. Things finally start to become a little bit clearer. I finally have some potentially concrete ideas to work on.
Finding a research topic was the most difficult part. For several months, I was wondering around like a headless chicken, reading papers after papers: serverless, ML inference, compiler, pathlet routing, RDMA, you name it. The feeling of not having a topic was suffocating. â€¦</p></div><p class=meta>Posted on <span class=postdate>05. November 2021</span></p></article><nav class=pagination role=pagination><span class=page-number>Page 1 of 6</span>
<a class=older-posts href=/blog/page/2/>Older Posts <span aria-hidden=true>&rarr;</span></a></nav></div><footer id=footer><p class=copyright><p>Â© 2022 <a href=https://www.bodunhu.com>Bodun Hu</a>. All rights reserved.</p></p></footer></div></body></html>