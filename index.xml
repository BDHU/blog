<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>std::bodun::blog</title>
    <link>https://www.bodunhu.com/blog/</link>
    <description>Recent content on std::bodun::blog</description>
    <image>
      <url>https://www.bodunhu.com/blog/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://www.bodunhu.com/blog/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Mon, 19 Apr 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://www.bodunhu.com/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Blockchain</title>
      <link>https://www.bodunhu.com/blog/posts/blockchain/</link>
      <pubDate>Mon, 19 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.bodunhu.com/blog/posts/blockchain/</guid>
      <description>The first time I&amp;rsquo;ve heard the term &amp;ldquo;blockchain&amp;rdquo; was around 2014. Since then, its popularity has grown rapidly. However, I&amp;rsquo;ve never actually understand what blockchain is exactly, until recently. In fact, I didn&amp;rsquo;t really understand the difference between blockchain and bitcoin. For me, blockchain is clubbed with cryptocurrencies. So here is a short summary of what blockchain is and why people use blockchain.
What is Blockchain I tried reading the articles about blockchain before, and it didn&amp;rsquo;t take long before I was completely overwhelmed by technical terms: consensus, asymmetric crypto, consistency, etc.</description>
    </item>
    
    <item>
      <title>Hoare Logic</title>
      <link>https://www.bodunhu.com/blog/posts/hoarelogic/</link>
      <pubDate>Sat, 17 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.bodunhu.com/blog/posts/hoarelogic/</guid>
      <description>Hoare logic forms the basis of all deductive verification. To illustrate Hoare logic, we will first consider a smaller imperative programming language IMP.</description>
    </item>
    
    <item>
      <title>About</title>
      <link>https://www.bodunhu.com/blog/about/</link>
      <pubDate>Fri, 16 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.bodunhu.com/blog/about/</guid>
      <description>My name is Edward Hu, a Computer Science student in the SCEA lab under Dr. Christopher Rossbach at UT Austin. I will joining WISR lab under the supervision of Prof. Aditya Akella this following Fall. I spent most time doing system stuff and got confused. This site is intended to serve as the dumpster of my random thoughts. If you want to know more about me, please visit my main website.</description>
    </item>
    
    <item>
      <title>Congruence Closure</title>
      <link>https://www.bodunhu.com/blog/posts/congruence_closure/</link>
      <pubDate>Sat, 27 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.bodunhu.com/blog/posts/congruence_closure/</guid>
      <description>This is a summary of how to compute congruence closure. I implemented the algorithm to compute congruence closure and thought I’d never forget it. But my memory starts to get blurry just after two days. So I figured I’d put things down so I don’t have to watch the entire lecture again the next time I need it.</description>
    </item>
    
    <item>
      <title>Program Loading and Memory Mapping in Linux</title>
      <link>https://www.bodunhu.com/blog/posts/programloadingandmemorymappinginlinux/</link>
      <pubDate>Tue, 03 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.bodunhu.com/blog/posts/programloadingandmemorymappinginlinux/</guid>
      <description>The goal here is to familiarize yourself with how programs are loaded, dynamically paged, and some of the mechanics of signal handling and memory mapping in Linux.
 execve Syscall The operating system, as one of itsd basic services, loads programs into memory for them to execute. Programs rely on execve syscall to get the OS to load the program into memory and start it executing as a process. The kernel version we used to testing is 5.</description>
    </item>
    
    <item>
      <title>Scheduler Activation</title>
      <link>https://www.bodunhu.com/blog/posts/scheduleractivation/</link>
      <pubDate>Sat, 24 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.bodunhu.com/blog/posts/scheduleractivation/</guid>
      <description>What is a thread? A thread of execution is the smallest sequence of programmed instructions that can be managed independently by a scheduler.
Kernel Level Threads Pros/Cons  Good functionality, system wide integration Threads are seen and scheduled only by the kernel. A lot of kernel information should be invisible to user thread and can be useful for scheduling Poor performance, every thread_related call traps. This situation is a lot worse in the 1990s than it is now mainly due to clock speed.</description>
    </item>
    
    <item>
      <title>Add MathJax v3 Support to Jekyll and Hugo</title>
      <link>https://www.bodunhu.com/blog/posts/mathjaxjekyll/</link>
      <pubDate>Thu, 22 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.bodunhu.com/blog/posts/mathjaxjekyll/</guid>
      <description>I was using Mathjax v2 for a while and I heard v3 perform significantly better than v2. Many great tutorials explains explains how to add Mathjax support to Jekyll websites. Some of them only cover Mathjax v2. So here is the brief summary on how to add Mathjax v3 support to your Jekyll website (Recently I&amp;rsquo;ve migrated to Hugo but adding support to Hugo is also pretty similar).
  In the _config.</description>
    </item>
    
    <item>
      <title>Linux Program Measurement and mmap</title>
      <link>https://www.bodunhu.com/blog/posts/linuxkernelmeasurementandmmap/</link>
      <pubDate>Wed, 23 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.bodunhu.com/blog/posts/linuxkernelmeasurementandmmap/</guid>
      <description>This is a summary over Linux kernel program measurement and mmap. The specs of our experiment environment is listed below. For more details regarding the CPU spec please refer to cpu world. This is the system spec:
   Attribute Value     Processor name (BIOS) Intel(R) Core(TM) i7-6800K CPU @ 3.40GHz   Cores 6   Logical processors 12   TLB/Cache details 64-byte Prefetching Data TLB: 1-GB pages, 4-way set associative, 4 entries Data TLB: 4-KB Pages, 4-way set associative, 64 entries Instruction TLB: 4-KByte pages, 8-way set associative, 64 entries L2 TLB: 1-MB, 4-way set associative, 64-byte line size Shared 2nd-Level TLB: 4-KB / 2-MB pages, 6-way associative, 1536 entries.</description>
    </item>
    
    <item>
      <title>Memory Resource Management in VMware ESX Server</title>
      <link>https://www.bodunhu.com/blog/posts/vmwareesxserver/</link>
      <pubDate>Mon, 21 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.bodunhu.com/blog/posts/vmwareesxserver/</guid>
      <description>VMWare ESX Server is a software layer designed to multiplex hardware resources among virtual machines running unmodified commodity operating systems. ESX Server, different to VMware Workstation, is a type 1 hypervisor, which means it runs directly on bare metal. ESX Server focuses on running guest VMs without modifying the guest OSes at all, which is challenging.
  Memory Virtualization is done by interposing an extra abstraction layer between a physical address from the VM&amp;rsquo;s point of view, and a machine address which represents the actual hardware memory.</description>
    </item>
    
    <item>
      <title>Xen and the Art of Virtualization</title>
      <link>https://www.bodunhu.com/blog/posts/xenvirtualization/</link>
      <pubDate>Wed, 16 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.bodunhu.com/blog/posts/xenvirtualization/</guid>
      <description>Xen is an x86 virtual machine monitor which allows multiple commodity operating systems to share conventional hardware in a safe and resource managed fashion, without sacrificing either performance or functionality. Xen is type I hypervisor, which directly runs on top of bare metal.
 paravirtualization - presents a virtual machine abstraction that is similar but not identical to the underlying hardware.
  The Virtual Machine Interface Memory is hard to virtualize mostly because x86 doesn&amp;rsquo;t support software-managed TLB.</description>
    </item>
    
    <item>
      <title>Start Linux Kernel Hacking</title>
      <link>https://www.bodunhu.com/blog/posts/kernelhacking/</link>
      <pubDate>Mon, 14 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.bodunhu.com/blog/posts/kernelhacking/</guid>
      <description>This is a summary of how to compile and boot the Linux kernel on the KVM-qemu virtual machine. It covers how to get a VM running in KVM, how to build a customized kernel, and how to use GDB with the Linux kernel. The experiment is conducted on an amd64 architecture CPU. We use Ubuntu as our testing environment but the steps covered here should apply to other distros as well.</description>
    </item>
    
    <item>
      <title>Performance Anamoly of 802.11b</title>
      <link>https://www.bodunhu.com/blog/posts/wireless_anomaly/</link>
      <pubDate>Sun, 13 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.bodunhu.com/blog/posts/wireless_anomaly/</guid>
      <description>This research is conducted by Martin Heusse, Franck Rousseau, Cilles Berger-Sabbatel, Andrzej Duda on analyzing the performance of the IEEE 802.11b wireless local area networks. Degraded transmitting rate is caused by CSMA/CA channel access method.
 Overview The performance of the IEEE 802.11b wireless local area networks have degraded performances when some mobile hosts use a lower bit rate than the others, which is caused by CSMA/CA channel access method. When one host changes it modulation type which degrades bit rate, it occupies the channel for a longer time, causing other hosts still using higher bit rate to be penalized.</description>
    </item>
    
    <item>
      <title>Exokernel</title>
      <link>https://www.bodunhu.com/blog/posts/exokernel/</link>
      <pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.bodunhu.com/blog/posts/exokernel/</guid>
      <description>Exokernel is a term every system researcher has heard of at some point in life. However, according to the PDOS group at MIT, there aren&amp;rsquo;t any exokernel-based operating systems in active use today. It&amp;rsquo;s interesting to discover what ideas exokernels brought to the OS high-level design and some potential drawbacks of such design choice.
 Perhaps the most important thing to keep in mind is that exokernel operating system architecture pushes management of physical resources to the application level, contrary to what most monolithic kernel would do: providing hardware resource management through some form of abstraction, usually hiding hardware-related details.</description>
    </item>
    
    <item>
      <title>Sketch on the UNIX Timesharing System</title>
      <link>https://www.bodunhu.com/blog/posts/unix/</link>
      <pubDate>Thu, 27 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.bodunhu.com/blog/posts/unix/</guid>
      <description>Unix is general-purpose, multi-user, interactive operating system, it offers several new features hardly found in other larger operating systems back in the day. These features include (1) a hierarchical file system incorporating demountable volumes; (2) compatible file, device, and inter-process I/O; (3) the ability to initiate asynchronous processes; (4) system command language selectable on a per-user basis; and (5) over 100 subsystems including a dozen languages.
 Simplicity at its Core Simplicity was engraved into the gene of Unix since its birth, as the paper states: &amp;ldquo;Perhaps the most important achievement of UNIX is to demonstrate that a powerful operating system for interactive use need not be expensive either in equipment or in human effort&amp;rdquo;.</description>
    </item>
    
    <item>
      <title>Monads in Haskell</title>
      <link>https://www.bodunhu.com/blog/posts/monad/</link>
      <pubDate>Sun, 01 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.bodunhu.com/blog/posts/monad/</guid>
      <description>I&amp;rsquo;ve scratched my head for quite a while trying to understand the concept of monad in Haskell. This is a brief summary of monads. I take William Cook&amp;rsquo;s Anatomy of Programming Languages as my reference.
 Definitions of Monads A monad is defined as a computational structure that involves three parts:
 A generic data type \(m\) A return function \(return_m\) :: \(t\rightarrow mt\) A bind function \(\triangleright_mt\rightarrow (t\rightarrow ms)\rightarrow ms\)  Here the symbol \(m\) gives the name of the monad as well as the shape of the computation.</description>
    </item>
    
    <item>
      <title>Singular Value Decomposition</title>
      <link>https://www.bodunhu.com/blog/posts/svd/</link>
      <pubDate>Mon, 10 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.bodunhu.com/blog/posts/svd/</guid>
      <description>Unitary matrices and the Singular Value Decomposition (SVD) are two important concepts in linear algebra. In order to fully understand these concepts, we will need to first discuss orthogonality. Most materials are convered in Advanced Linear Algebra: Foundations to Frontiers taught by professor Robert van de Geijn. This is a brief summary over the important concepts covered in Chapter 2.
 Components in the direction of a vector By Pythagorean theorem, we know that \(b = \chi a + c\) where \(a\) is a unit vector orthogonal to \(c\) and \(\chi\) is a scaler.</description>
    </item>
    
    <item>
      <title>Understanding Probabilistic Clock Synchronization</title>
      <link>https://www.bodunhu.com/blog/posts/probabilistic_clock_synchronization/</link>
      <pubDate>Tue, 17 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.bodunhu.com/blog/posts/probabilistic_clock_synchronization/</guid>
      <description>This post is meant to discuss the probabilistic clock synchronization technique. The main goal of this technique is to bound the difference between systems by setting up an upper bound. In short, \(|P(t)-Q(t)|\leq \varepsilon\). We will discuss what these symbols represent later.
 Perfect Synchronization The motivation behind this technique is that synchronization always involves overheads. In a perfect environment where network delay and request processing time are both 0, the clocks can be synchronized with ease.</description>
    </item>
    
    <item>
      <title>How to Put Papers on ArXiv</title>
      <link>https://www.bodunhu.com/blog/posts/arxivsubmition/</link>
      <pubDate>Tue, 25 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.bodunhu.com/blog/posts/arxivsubmition/</guid>
      <description>I was recently trying to put my research paper draft on ArXiv. I thought it would be as simple as submitting the pdf file, which should take approximately less than ten minutes. I was wrong. It took several hours to figure what was going on. I included some tips here to prevent mistakes I made from happening again.
 The first mistake I made was assuming a single submission of pdf file would be sufficient.</description>
    </item>
    
    <item>
      <title>A Little Review on Barrelfish Memory Management </title>
      <link>https://www.bodunhu.com/blog/posts/operatingsystemmemorymanagement/</link>
      <pubDate>Mon, 18 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.bodunhu.com/blog/posts/operatingsystemmemorymanagement/</guid>
      <description>The memory management has been mentioned numerous times and still remains huge topic. virtual vs. physical memory, physical frame allocation, MMUs, page faults, address space layout, and demand paging and swapping are familiar terms for every undergrad in college.
In monolithic kernels such as Linux, much of the functionality is handled in kernel. However, there are OSes that push these functionalities to user space such as Barrelfish. Many concept here will thus be borrowed from the Barrelfish OS.</description>
    </item>
    
    <item>
      <title>Pascal GPU memory and cache hierarchy</title>
      <link>https://www.bodunhu.com/blog/posts/gpumemoryhierarchy/</link>
      <pubDate>Tue, 15 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.bodunhu.com/blog/posts/gpumemoryhierarchy/</guid>
      <description>Memory access efﬁciency is an important factor in fully utilizing the computational power of graphics processing units (GPUs). However, many GPU vendors like NVIDIA kept the GPU memory hierarchy as a secret. Therefore it becomes hard to measure GPUs performance and sets barriers to understand memory access patterns, which is a key component to improve program&amp;rsquo;s performance. Here we introduce a novel fine-grained microbenchmark approach and apply to the Pascal generation.</description>
    </item>
    
    <item>
      <title>Map Reduce</title>
      <link>https://www.bodunhu.com/blog/posts/mapreduce/</link>
      <pubDate>Sun, 01 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://www.bodunhu.com/blog/posts/mapreduce/</guid>
      <description>I was always interested by the name &amp;ldquo;map reduce&amp;rdquo; since two years ago when I first heard this term. But I&amp;rsquo;ve never put any effort to know the concept until Chris mentioned it in class because it will be on the next exam so I figured I&amp;rsquo;d better figure out what is going on before it was too late. Just kidding:) But map reduce does borrows a lot of characteristics from traditional relational databases even though many useful and important features in RDBMS are eliminated from the map reduce system.</description>
    </item>
    
    <item>
      <title>Networks</title>
      <link>https://www.bodunhu.com/blog/posts/networks/</link>
      <pubDate>Mon, 13 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.bodunhu.com/blog/posts/networks/</guid>
      <description>The concept of a worldwide of networks of information was introduced long before the technology used to build the internet. The first workable prototype came in the late 1960s with the creation of ARPANET(The Advanced Research Projects Agency Network). The famous TCP/IP, or Transmission Control Protocol and Internet Protocol, was developed by Robert Kahn and Vinton Cerf in the 1970s. In the 1980s, research by Tim Berners-Lee gave birth to the World Wide Web, linking hypertext documents into an information system, making them accessible from any node on the network (History of Internet).</description>
    </item>
    
    <item>
      <title>File System Design</title>
      <link>https://www.bodunhu.com/blog/posts/filesystem/</link>
      <pubDate>Mon, 30 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.bodunhu.com/blog/posts/filesystem/</guid>
      <description>What exactly is a file system? The general concept is that the file system provides naming organization. It manages the physical disk layout such as picking a block constituting a file, balancing locality with expandability, and managing free space. It can translate from file name and offset to the actual data block. In a nutshell, it is a servant that manages all the dirty details of communicating the data between system and the hardware in an optimal way which you aren&amp;rsquo;t required to understand so you can go on and do other things with your life.</description>
    </item>
    
    <item>
      <title>Disk Introduction</title>
      <link>https://www.bodunhu.com/blog/posts/disks/</link>
      <pubDate>Wed, 25 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.bodunhu.com/blog/posts/disks/</guid>
      <description>This chapter is all about disk. Before we start. We won&amp;rsquo;t go deep into the mechanical part of disk operation; rather we will be focusing on general concept related to disk and algorithms to improve disk performance.
  The Evaluation Criteria Here we are introduing the basic components used to evaluate the performance of disk operation.
Seek Time This is the time to position the head over the track. Maximum can be going from innermost track to outer most track.</description>
    </item>
    
    <item>
      <title>Virtual Memory Mechanisms</title>
      <link>https://www.bodunhu.com/blog/posts/virtualaddressmechanism/</link>
      <pubDate>Thu, 19 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.bodunhu.com/blog/posts/virtualaddressmechanism/</guid>
      <description>As we can see in the previous post, all allocation algorithms we discussed lead to external fragmentation. As time goes by, external fragmentation is going to get worse and we need solutions for the problem. We can use swap areas to swap out memory onto the disk, or move allocated memory together(a process named memory compaction), leaving empty spaces together. Even these approaches can reduce external fragmentation and allow a higher degree of multiprogramming, they are not perfect.</description>
    </item>
    
    <item>
      <title>Virtual Memory Overview</title>
      <link>https://www.bodunhu.com/blog/posts/virtualaddress/</link>
      <pubDate>Sun, 08 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://www.bodunhu.com/blog/posts/virtualaddress/</guid>
      <description>I love pointers. Pointer is very a useful feature in programming languages like C/C++. I can pass weird hexidecimal numbers to a function and then it will magically locate where the program is in memory. However, all those values we see are merely virtual addresses, a running program&amp;rsquo;s view of memory in system. Any address we can see while programming user-level programs is a virtual address. It is no more than an illusion of where the data is actually laid out in memory.</description>
    </item>
    
    
    
  </channel>
</rss>
