<!doctype html><html><head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta name=description content="std::bodun::blog. Personal Blog of Bodun (Edward) Hu. CS PhD student at University of Texas at Austin. Operating systems, network, heterogeneity, MLSys, anything system. UTCS">
<link rel="shortcut icon" href=https://www.bodunhu.com/blog/favicon.ico>
<link rel=stylesheet href=/blog/css/style.min.css>
<script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},svg:{fontCache:"global"}}</script>
<script type=text/javascript id=MathJax-script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js async></script>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-108144808-1","auto"),ga("send","pageview"))</script>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-108144808-1","auto"),ga("send","pageview"))</script>
<script async src=https://www.google-analytics.com/analytics.js></script>
<title>Maximum Likelihood for Classification</title></head><body><header id=banner>
<h2><a href=https://www.bodunhu.com/blog/>std::bodun::blog</a></h2><nav>
<ul>
<li>
<a href=/blog/posts/ title=posts>archive</a>
</li><li>
<a href=https://www.bodunhu.com/ title=about>about</a>
</li></ul></nav></header><main id=content>
<article>
<header id=post-header>
<h1>Maximum Likelihood for Classification</h1><div>
<time>Updated Feb 14, 2022</time>
</div></header><p>Let&rsquo;s say we want to classify an input text \(y\) and give it a label \(x\). Formally, we want to find:</p><p>\[
\textrm{argmax} P(x | y)
\]</p><p>By Bayes&rsquo; rule this is the same as</p><p>\[
\textrm{argmax} \frac{P(y|x)P(y)}{P(x)}
\]</p><p>Suppose we have five documents as training data and one document as the input as testing data. Our objective is to give a label to the test sentence.</p><p><img src=https://cdn.jsdelivr.net/gh/BDHU/Page_Pics/posts/MLE/text-example.png alt=text-example></p><center>Credit: Eunsol Choi</center>
<p>Let&rsquo;s define the probability of class as (\(N\) is the total number of classes)</p><p>\[
p(x) = \frac{count(x)}{N}
\]</p><p>and the probability of a word appearing given a class label (total number of vocabs)</p><p>\[
p(w_i|x) = \frac{count(w_i,x) + 1}{count(x) + |V|}
\]</p><p>The conditional probabilities for \(p(w_i|y)\) is</p><p><img src=https://cdn.jsdelivr.net/gh/BDHU/Page_Pics/posts/MLE/conditional_prob.png alt=conditional-probabilities></p><p>Now, we want to find out which language label should we assign the sentence &ldquo;Chinese Chinese Chinese Tokyo Japan&rdquo;. This is the same as asking which labels (\(x\))) should we pick so that \(P(W|x)P(x)\) yields the greatest value. Mathematically, we want to find out where the gradient of the function \(P(W|x)P(x)\) is flat.</p><p>If we label the sentence as j (Japanese), we have \(P(j | d_5) \propto \frac{1}{4}\cdot (\frac{2}{9}^3)\cdot \frac{2}{9}\cdot \frac{2}{9} \approx 0.0001\). If we calculate \(P(c|d_5)\), we get 0.0003, which generates the largest value for \(P(x | y)\).</p><div style=width:100% id=comment>
<script src=https://utteranc.es/client.js repo=BDHU/blog issue-term=pathname theme=preferred-color-scheme crossorigin=anonymous async></script>
</div></article></main><footer id=footer>
<p>Â© 2022 Bodun Hu. All rights reserved.</p></footer></body></html>