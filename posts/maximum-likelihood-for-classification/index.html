<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="PhD student at University of Texas at Austin ðŸ¤˜. Doing systems for ML."><link rel="shortcut icon" href=/blog/favicon.ico><link rel=stylesheet href=/blog/css/style.min.65fee12c3de7945505d2df881b53ad9402a1780736bd4aa18e7383244352f41c.css integrity="sha256-Zf7hLD3nlFUF0t+IG1OtlAKheAc2vUqhjnODJENS9Bw=" crossorigin=anonymous><script>MathJax={tex:{inlineMath:{"[+]":[["$","$"],["\\(","\\)"]]}},svg:{fontCache:"global"},output:{displayOverflow:"linebreak",linebreaks:{inline:!0,width:"100%",lineleading:.2,LinebreakVisitor:null}}}</script><script defer src=https://cdn.jsdelivr.net/npm/mathjax@4/tex-svg.js></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-ZLK2GHB055"></script><script>var doNotTrack=!1,dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes";if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-ZLK2GHB055")}</script><link rel=canonical href=https://www.bodunhu.com/blog/posts/maximum-likelihood-for-classification/><title>Maximum Likelihood for Classification | std::bodun::blog</title></head><body><header class=banner><nav class=site-nav aria-label=Primary><a href=/blog/ title=blog>blog</a> | <a href=/blog/posts/ title=posts>posts</a> | <a href=https://www.bodunhu.com/ title=about>about</a></nav></header><main class=content><article><header class=post-header><h1>Maximum Likelihood for Classification</h1><div><time datetime=2025-11-17>November 17, 2025</time></div></header><p>Let&rsquo;s say we want to classify an input text \(y\) and give it a label \(x\). Formally, we want to find:</p><p>\[
\textrm{argmax} P(x | y)
\]</p><p>By Bayes&rsquo; rule this is the same as</p><p>\[
\textrm{argmax} \frac{P(y|x)P(y)}{P(x)}
\]</p><p>Suppose we have five documents as training data and one document as the input as testing data. Our objective is to give a label to the test sentence.</p><p><img src=https://cdn.jsdelivr.net/gh/BDHU/Page_Pics/posts/MLE/text-example.png alt=text-example></p><center>Credit: Eunsol Choi</center><p>Let&rsquo;s define the probability of class as (\(N\) is the total number of classes)</p><p>\[
p(x) = \frac{count(x)}{N}
\]</p><p>and the probability of a word appearing given a class label (total number of vocabs)</p><p>\[
p(w_i|x) = \frac{count(w_i,x) + 1}{count(x) + |V|}
\]</p><p>The conditional probabilities for \(p(w_i|y)\) is</p><p><img src=https://cdn.jsdelivr.net/gh/BDHU/Page_Pics/posts/MLE/conditional_prob.png alt=conditional-probabilities></p><p>Now, we want to find out which language label should we assign the sentence &ldquo;Chinese Chinese Chinese Tokyo Japan&rdquo;. This is the same as asking which labels (\(x\))) should we pick so that \(P(W|x)P(x)\) yields the greatest value. Mathematically, we want to find out where the gradient of the function \(P(W|x)P(x)\) is flat.</p><p>If we label the sentence as j (Japanese), we have \(P(j | d_5) \propto \frac{1}{4}\cdot (\frac{2}{9}^3)\cdot \frac{2}{9}\cdot \frac{2}{9} \approx 0.0001\). If we calculate \(P(c|d_5)\), we get 0.0003, which generates the largest value for \(P(x | y)\).</p><script src=https://giscus.app/client.js data-repo=BDHU/blog-comments data-repo-id=R_kgDOKZLDLA data-category=Announcements data-category-id=DIC_kwDOKZLDLM4CZrU- data-mapping=pathname data-strict=0 data-reactions-enabled=0 data-emit-metadata=0 data-input-position=bottom data-theme=light data-lang=en crossorigin=anonymous async></script></article></main><footer><p>Copyright Â© 2026 <a href=https://www.bodunhu.com/>Bodun Hu</a>&nbsp;&bull; <a href=/blog/index.xml>RSS</a></p></footer></body></html>