<!doctype html><html><head><meta charset=utf-8><meta name=viewport content="width=device-width"><title>Maximum Likelihood for Classification</title><link rel=stylesheet href=https://www.bodunhu.com/blog/css/colors-preference.min.3ad46450d59177206f28dcac6dd37d7032546cd0e43b77a576f6aa60a5e4d5d8.css><link rel="shortcut icon" href=https://www.bodunhu.com/blog/favicon.ico><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},svg:{fontCache:"global"}}</script><script type=text/javascript id=MathJax-script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js async></script><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-108144808-1","auto"),ga("send","pageview"))</script><script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-108144808-1","auto"),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script></head><body><header id=header><h1><a href=https://www.bodunhu.com/blog/>std::bodun::blog</a></h1><p>PhD student at University of Texas at Austin ðŸ¤˜. Doing systems for ML.</p></header><div id=page><div id=sidebar><nav><ul class=nav><li><a href=/blog/posts/><span>Archive</span>&nbsp;&nbsp;</a></li><li><a href=https://www.bodunhu.com/><span>About</span>&nbsp;&nbsp;</a></li><li><a href=/blog/index.xml><span>Feed</span>&nbsp;&nbsp;</a></li></ul></nav></div><div id=content><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/maximum-likelihood-for-classification/>Maximum Likelihood for Classification</a></h1><div class=post-content><p>Let&rsquo;s say we want to classify an input text \(y\) and give it a label \(x\). Formally, we want to find:</p><p>\[
\textrm{argmax} P(x | y)
\]</p><p>By Bayes&rsquo; rule this is the same as</p><p>\[
\textrm{argmax} \frac{P(y|x)P(y)}{P(x)}
\]</p><p>Suppose we have five documents as training data and one document as the input as testing data. Our objective is to give a label to the test sentence.</p><p><img src=https://cdn.jsdelivr.net/gh/BDHU/Page_Pics/posts/MLE/text-example.png alt=text-example></p><center>Credit: Eunsol Choi</center><p>Let&rsquo;s define the probability of class as (\(N\) is the total number of classes)</p><p>\[
p(x) = \frac{count(x)}{N}
\]</p><p>and the probability of a word appearing given a class label (total number of vocabs)</p><p>\[
p(w_i|x) = \frac{count(w_i,x) + 1}{count(x) + |V|}
\]</p><p>The conditional probabilities for \(p(w_i|y)\) is</p><p><img src=https://cdn.jsdelivr.net/gh/BDHU/Page_Pics/posts/MLE/conditional_prob.png alt=conditional-probabilities></p><p>Now, we want to find out which language label should we assign the sentence &ldquo;Chinese Chinese Chinese Tokyo Japan&rdquo;. This is the same as asking which labels (\(x\))) should we pick so that \(P(W|x)P(x)\) yields the greatest value. Mathematically, we want to find out where the gradient of the function \(P(W|x)P(x)\) is flat.</p><p>If we label the sentence as j (Japanese), we have \(P(j | d_5) \propto \frac{1}{4}\cdot (\frac{2}{9}^3)\cdot \frac{2}{9}\cdot \frac{2}{9} \approx 0.0001\). If we calculate \(P(c|d_5)\), we get 0.0003, which generates the largest value for \(P(x | y)\).</p></div><p class=meta>Posted on <span class=postdate>24. January 2022</span></p></article></div><footer id=footer><p class=copyright><p>Â© 2022 <a href=https://www.bodunhu.com>Bodun Hu</a>. All rights reserved.</p></p></footer></div></body></html>