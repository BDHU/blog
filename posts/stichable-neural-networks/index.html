<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="PhD student at University of Texas at Austin ðŸ¤˜. Doing systems for ML."><link rel="shortcut icon" href=/blog/favicon.ico><link rel=stylesheet href=/blog/css/style.min.65fee12c3de7945505d2df881b53ad9402a1780736bd4aa18e7383244352f41c.css integrity="sha256-Zf7hLD3nlFUF0t+IG1OtlAKheAc2vUqhjnODJENS9Bw=" crossorigin=anonymous><script>MathJax={tex:{inlineMath:{"[+]":[["$","$"],["\\(","\\)"]]}},svg:{fontCache:"global"},output:{displayOverflow:"linebreak",linebreaks:{inline:!0,width:"100%",lineleading:.2,LinebreakVisitor:null}}}</script><script defer src=https://cdn.jsdelivr.net/npm/mathjax@4/tex-svg.js></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-ZLK2GHB055"></script><script>var doNotTrack=!1,dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes";if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-ZLK2GHB055")}</script><link rel=canonical href=https://www.bodunhu.com/blog/posts/stichable-neural-networks/><title>Stichable Neural Networks | std::bodun::blog</title></head><body><header class=banner><nav class=site-nav aria-label=Primary><a href=/blog/ title=blog>blog</a> | <a href=/blog/posts/ title=posts>posts</a> | <a href=https://www.bodunhu.com/ title=about>about</a></nav></header><main class=content><article><header class=post-header><h1>Stichable Neural Networks</h1><div><time datetime=2024-09-01>September 1, 2024</time></div></header><p>TLDR; the <a href=https://arxiv.org/abs/2302.06586>Stichable Neural Networks</a> paper includes some interesting concepts. It allows the creation of multiple neural networks with varying complexity and performance trade-offs from a family of pretrained models.</p><h2 id=key-principles>Key Principles</h2><ul><li>How to choose <strong>anchors</strong> from well-performed pretrained models in a model family</li><li>The design of stitching layers</li><li>The stitching direction and strategy</li><li>Simple but effective training strateg</li></ul><p>A key question about combining sub-networks from different pretrained models is how to maintain accuracy. The paper concludes that the final performance of these combinations is nearly predictable due to an interpolation-like performance curve between anchors. This predictability allows for selective pre-training of stitches based on various deployment scenarios.</p><h2 id=the-choice-of-anchors>The Choice of Anchors</h2><p>Anchors that are pretrained on different tasks can learn very different representations due to the large distribution gap of different domains. Therefore, the selected anchors
should be consistent in terms of the pretrained domain.</p><h2 id=the-stitching-layer-and-its-initialization>The Stitching Layer and its Initialization</h2><p>SN-Net is built upon pretrained models. Therefore, the anchors have already learned good representations, which allows to directly obtain an accurate transformation matrix by solving the least squares problem:</p><p>$$||AM_o - B|| = min||AM - b||_F$$</p><p>where $A \in R^{N \times D_1}$ and \(B \in R^{N \times D_2}\) are two feature maps
of the same spatial size but with different number of hidden
dimensions.</p><p>This function indicates a closed form expression based on singular value decomposition, in which case the optimal solution can be achieved through an orthogonal projection in the space of matrices:</p><p>$$M_o = A^\dagger B$$</p><p>where $A^\dagger$ denotes the Moore-Penrose pseudoinverse of $A$.</p><h2 id=where-to-stitch>Where to Stitch</h2><p>SN-Net takes Fast-to-Slow as the default stitching direction, meaning it will stitch bigger and slower network after smaller and faster networks to achieve better model performance. Besides, it also proposes a <strong>nearest stitching strategy</strong> by limiting the stitching between two anchors of the nearest model complexity/performance.</p><h2 id=way-to-stitch>Way to Stitch</h2><p>Prior works shows neighboring layers dealing with the same scale feature maps share
similar representations. Therefore, SN-Net uses <strong>slideing window</strong>: where the same window shares a common stitching layer.</p><p><img src=stitching.png alt=sliding-window></p><h2 id=stitching-space>Stitching Space</h2><p>The stitching space is controlled by the configuring the sliding window kernel size $k$ and step size $s$.</p><h2 id=training-strategy>Training Strategy</h2><p>The training algorithm of SN-Net can be described as:</p><p><img src=stitch-net-train.png alt=sn-net-training></p><p>The training algorithm can be summarized as:</p><ol><li>Firstly define a configuration set that contains all possible stitches</li><li>Initialize all stitching layers with least-squares matching</li><li>At each training iteration, we randomly sample a stitch and follow the standard training process as in common practices</li></ol><script src=https://giscus.app/client.js data-repo=BDHU/blog-comments data-repo-id=R_kgDOKZLDLA data-category=Announcements data-category-id=DIC_kwDOKZLDLM4CZrU- data-mapping=pathname data-strict=0 data-reactions-enabled=0 data-emit-metadata=0 data-input-position=bottom data-theme=light data-lang=en crossorigin=anonymous async></script></article></main><footer><p>Copyright Â© 2026 <a href=https://www.bodunhu.com/>Bodun Hu</a>&nbsp;&bull; <a href=/blog/index.xml>RSS</a></p></footer></body></html>