<!doctype html><html lang=en-us>
<head>
<title>In-Network Aggregation for Shared Machine Learning Clusters | std::bodun::blog</title>
<meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge,chrome=1">
<meta name=viewport content="width=device-width,minimum-scale=1">
<meta name=description content="This [paper](https://proceedings.mlsys.org/paper/2021/file/eae27d77ca20db309e056e3d2dcd7d69-Paper.pdf) by Nadeen appeared in MLSys 2021. It presents an in-network aggregation framework called *PANAMA* for distributed ML training tasks. *PANAMA* has two components: (1) an in-network hardware accelerator with support for floating-point gradient aggregation; (2) a domain-specific load-balancing and congestion control protocol">
<meta name=generator content="Hugo 0.88.0">
<meta name=ROBOTS content="INDEX, FOLLOW">
<link rel=stylesheet href=/blog/css/style.css>
<link rel="shortcut icon" href=/blog/images/favicon.ico type=image/x-icon>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga('create','UA-108144808-1','auto'),ga('send','pageview'))</script>
<script async src=https://www.google-analytics.com/analytics.js></script>
<script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']]},svg:{fontCache:'global'}}</script>
<script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script>
<meta name=twitter:card content="summary">
<meta name=twitter:title content="In-Network Aggregation for Shared Machine Learning Clusters">
<meta name=twitter:description content="This [paper](https://proceedings.mlsys.org/paper/2021/file/eae27d77ca20db309e056e3d2dcd7d69-Paper.pdf) by Nadeen appeared in MLSys 2021. It presents an in-network aggregation framework called *PANAMA* for distributed ML training tasks. *PANAMA* has two components: (1) an in-network hardware accelerator with support for floating-point gradient aggregation; (2) a domain-specific load-balancing and congestion control protocol">
<meta name=twitter:site content="@https://twitter.com/BodunHu">
<script>document.getElementById("scroll-to-top").addEventListener("click",function(){window.scrollTo({top:0,left:0,behavior:'smooth'})})</script>
</head>
<body>
<nav class=navigation>
<a href=/blog/> <span class=arrow>‚Üê</span>Home</a>
<a href=/blog/posts>Archive</a>
<a href=/blog/tags>Tags</a>
<a href=https://www.bodunhu.com/>About</a>
<a class=button href=https://www.bodunhu.com/blog/index.xml>Subscribe</a>
</nav>
<main class=main>
<section id=single>
<h1 class=title>In-Network Aggregation for Shared Machine Learning Clusters</h1>
<div class=tip>
<time datetime="2021-08-31 00:00:00 +0000 UTC">Aug 31, 2021</time>
<span class=split>
¬∑
</span>
<span>
2 minute read
</span>
</div>
<div class=content>
<p>This <a href=https://proceedings.mlsys.org/paper/2021/file/eae27d77ca20db309e056e3d2dcd7d69-Paper.pdf target=_blank rel=noopener>paper</a> by Nadeen appeared in MLSys 2021. It presents an in-network aggregation framework called <em>PANAMA</em> for distributed ML training tasks. <em>PANAMA</em> has two components: (1) an in-network hardware accelerator with support for floating-point gradient aggregation; (2) a domain-specific load-balancing and congestion control protocol.</p>
<h2 id=motivation>Motivation <a href=#motivation class=anchor>üîó</a></h2><p>The primary motivation behind <em>PANAMA</em> is the <em>data-parallel</em> training (in which the neural network is replicated across \(N\) worker where each worker processes a subset of the training data) demands constant local gradient exchanging at every iteration, thus creating a huge amount of traffic.</p>
<p>For example, for a training job with \(1000\) workers and 1 GB DNN model size requring \(1000\) iterations, the total traffic will be about 2 PB.</p>
<p><p class=markdown-image>
<img src=https://raw.githubusercontent.com/BDHU/Page_pics/master/posts/in-network-aggregation-for-shared-machine-learning-clusters/network-flow-size.png#center alt=in-network-aggregation-traffic>
</p></p>
<h2 id=network-design>Network Design <a href=#network-design class=anchor>üîó</a></h2><p>The paper assumes a traditional data center multi-tier folded <a href=https://en.wikipedia.org/wiki/Clos_network target=_blank rel=noopener>Clos topology</a>:</p>
<p><p class=markdown-image>
<img src=https://raw.githubusercontent.com/BDHU/Page_pics/master/posts/in-network-aggregation-for-shared-machine-learning-clusters/clos.png#center alt=clos-topology>
</p></p>
<p><em>PANAMA</em> uses multiple aggregation trees per training job to spread the traffic across multiple paths and avoid congestion hotspots. This is different to equal-cost multi-path (ECMP) protocol because the aggregation flows are typically large. Bounding such flows to a single aggregation tree will create network imbalance.</p>
<h2 id=congestion-control>Congestion Control <a href=#congestion-control class=anchor>üîó</a></h2><p><em>PANAMA</em> uses <strong>implicit acknowledgments</strong> instead of traditional point-to-point approaches. Because each aggregated packets are constructed on the fly, one-to-one mapping between packets and the acknowledgements is unnecessary, if a worker receives aggregation results, that automatically serves as an <em>implicit</em> acknowledgement. This eliminated the need to keep a per-flow congestion state at PSwitches.</p>
<p>Similar to <a href>DCTCP</a>, <em>PANAMA</em> relies on ECN marks in the IP header to react to the network congestion. Since aggregation packets are created on the switch, each hardware accelerator need to perform a bitwise \(OR\) on the ECN field of received packets to mirror the traditional ECN bit.</p>
<h2 id=hardware-design>Hardware Design <a href=#hardware-design class=anchor>üîó</a></h2><p>The design of the aggregation accelerator in <em>PANAMA</em> is straightforward: it utilized the SIMD architecture in which the gradients are partitioned across adder trees. Adder tree can operate in parallel and pack the results and sent them to the output ports. The VID fields are merely used to correct aggregation.</p>
<p><p class=markdown-image>
<img src=https://raw.githubusercontent.com/BDHU/Page_pics/master/posts/in-network-aggregation-for-shared-machine-learning-clusters/aggregater-arch.png#center alt=aggregator-arch>
</p></p>
<p>Overall, the workflow is really simple and illustrated below:</p>
<p><p class=markdown-image>
<img src=https://raw.githubusercontent.com/BDHU/Page_pics/master/posts/in-network-aggregation-for-shared-machine-learning-clusters/network-aggregation-workflow.png alt=network-aggregation-workflow>
</p></p>
</div>
<div class=tags>
<a href=https://www.bodunhu.com/blog/tags/network>network</a>
<a href=https://www.bodunhu.com/blog/tags/mlsys>mlsys</a>
<a href=https://www.bodunhu.com/blog/tags/paper-review>paper-review</a>
</div>
<div id=comment>
<script src=https://utteranc.es/client.js repo=BDHU/blog issue-term=pathname theme=github-light crossorigin=anonymous async></script>
</div>
</section>
</main>
<footer id=footer>
<div id=social>
<a class=symbol href=https://github.com/BDHU rel=me target=_blank><svg fill="#bbb" width="28" height="28" viewBox="0 0 72 72" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><title>Github</title><desc>Created with Sketch.</desc><defs/><g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="Social-Icons---Rounded-Black" transform="translate(-264.000000, -939.000000)"><g id="Github" transform="translate(264.000000, 939.000000)"><path d="M8 72H64c4.418278.0 8-3.581722 8-8V8c0-4.418278-3.581722-8-8-8H8c-4.418278 811624501e-24-8 3.581722-8 8V64c541083001e-24 4.418278 3.581722 8 8 8z" id="Rounded" fill="#bbb"/><path d="M35.9985 13C22.746 13 12 23.7870921 12 37.096644c0 10.6440272 6.876 19.6751861 16.4145 22.8617681C29.6145 60.1797862 30.0525 59.4358488 30.0525 58.7973276 30.0525 58.2250681 30.0315 56.7100863 30.0195 54.6996482c-6.6765 1.4562499-8.085-3.2302544-8.085-3.2302544-1.0905-2.7829884-2.664-3.5239139-2.664-3.5239139C17.091 46.4500754 19.4355 46.4801943 19.4355 46.4801943c2.4075.1701719 3.675 2.4833051 3.675 2.4833051 2.142 3.6820383 5.6175 2.6188404 6.9855 2.0014024C30.3135 49.4077535 30.9345 48.3460615 31.62 47.7436831 26.2905 47.1352808 20.688 45.0691228 20.688 35.8361671c0-2.6308879.9345-4.781379 2.4705-6.4665327C22.911 28.7597262 22.0875 26.3110578 23.3925 22.9934585c0 0 2.016-.6475568 6.6 2.4697516C31.908 24.9285993 33.96 24.6620468 36.0015 24.6515052 38.04 24.6620468 40.0935 24.9285993 42.0105 25.4632101c4.581-3.1173084 6.5925-2.4697516 6.5925-2.4697516C49.9125 26.3110578 49.089 28.7597262 48.8415 29.3696344 50.3805 31.0547881 51.309 33.2052792 51.309 35.8361671c0 9.2555448-5.6115 11.29309-10.9575 11.8894446.860999999999997.7439374 1.629 2.2137408 1.629 4.4621184C41.9805 55.4089489 41.9505 58.0067059 41.9505 58.7973276 41.9505 59.4418726 42.3825 60.1918338 43.6005 59.9554002 53.13 56.7627944 60 47.7376593 60 37.096644 60 23.7870921 49.254 13 35.9985 13" fill="#fff"/></g></g></g></svg>
</a>
<a class=symbol href=https://twitter.com/BodunHu rel=me target=_blank><svg fill="#bbb" width="28" height="28" id="Capa_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="438.536" height="438.536" viewBox="0 0 438.536 438.536" style="enable-background:new 0 0 438.536 438.536"><g><path d="M414.41 24.123C398.333 8.042 378.963.0 356.315.0H82.228C59.58.0 40.21 8.042 24.126 24.123 8.045 40.207.003 59.576.003 82.225v274.084c0 22.647 8.042 42.018 24.123 58.102 16.084 16.084 35.454 24.126 58.102 24.126h274.084c22.648.0 42.018-8.042 58.095-24.126 16.084-16.084 24.126-35.454 24.126-58.102V82.225C438.532 59.576 430.49 40.204 414.41 24.123zM335.471 168.735c.191 1.713.288 4.278.288 7.71.0 15.989-2.334 32.025-6.995 48.104-4.661 16.087-11.8 31.504-21.416 46.254-9.606 14.749-21.074 27.791-34.396 39.115-13.325 11.32-29.311 20.365-47.968 27.117-18.648 6.762-38.637 10.143-59.953 10.143-33.116.0-63.76-8.952-91.931-26.836 4.568.568 9.329.855 14.275.855 27.6.0 52.439-8.565 74.519-25.7-12.941-.185-24.506-4.179-34.688-11.991-10.185-7.803-17.273-17.699-21.271-29.691 4.947.76 8.658 1.137 11.132 1.137 4.187.0 9.042-.76 14.56-2.279-13.894-2.669-25.598-9.562-35.115-20.697-9.519-11.136-14.277-23.84-14.277-38.114v-.571c10.085 4.755 19.602 7.229 28.549 7.422-17.321-11.613-25.981-28.265-25.981-49.963.0-10.66 2.758-20.747 8.278-30.264 15.035 18.464 33.311 33.213 54.816 44.252 21.507 11.038 44.54 17.227 69.092 18.558-.95-3.616-1.427-8.186-1.427-13.704.0-16.562 5.853-30.692 17.56-42.399 11.703-11.706 25.837-17.561 42.394-17.561 17.515.0 32.079 6.283 43.688 18.846 13.134-2.474 25.892-7.33 38.26-14.56-4.757 14.652-13.613 25.788-26.55 33.402 12.368-1.716 23.88-4.95 34.537-9.708C357.458 149.793 347.462 160.166 335.471 168.735z"/></g></svg>
</a>
</div>
<div class=copyright>
¬©
2016-2021
<a href=https://www.bodunhu.com/>Bodun Hu</a>. All rights reserved.
</div>
<div class=powerby>
Powered by <a href=http://www.gohugo.io/>Hugo</a> Theme By <a href=https://github.com/nodejh/hugo-theme-cactus-plus>nodejh</a>
</div>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)">
<button class=top-link id=top-link><i class="fa fa-chevron-up"></i></button>
</a>
</footer>
</body>
</html>