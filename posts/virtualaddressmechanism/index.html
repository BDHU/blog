<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Virtual Memory Mechanisms | std::bodun::blog</title><meta name=keywords content="os,mm"><meta name=description content="As we can see in the previous post, all allocation algorithms we discussed lead to external fragmentation. As time goes by, external fragmentation is going to get worse and we need solutions for the problem. We can use swap areas to swap out memory onto the disk, or move allocated memory together(a process named memory compaction), leaving empty spaces together. Even these approaches can reduce external fragmentation and allow a higher degree of multiprogramming, they are not perfect."><meta name=author content><link rel=canonical href=https://www.bodunhu.com/blog/posts/virtualaddressmechanism/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/blog/assets/css/stylesheet.min.a5e03b66b1e33e7f33d24d6965bc0a1987dd2e5edf97d3a2f7713a6ff21dcecf.css integrity="sha256-peA7ZrHjPn8z0k1pZbwKGYfdLl7fl9Oi93E6b/Idzs8=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/blog/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://www.cs.utexas.edu/sites/default/files/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://www.utexas.edu/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://www.utexas.edu/favicon-32x32.png><link rel=apple-touch-icon href=https://www.utexas.edu/apple-touch-icon.png><link rel=mask-icon href=https://www.cs.utexas.edu/sites/default/files/favicon.ico><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.83.1"><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(a,e,f,g,b,c,d){a.GoogleAnalyticsObject=b,a[b]=a[b]||function(){(a[b].q=a[b].q||[]).push(arguments)},a[b].l=1*new Date,c=e.createElement(f),d=e.getElementsByTagName(f)[0],c.async=1,c.src=g,d.parentNode.insertBefore(c,d)}(window,document,'script','https://www.google-analytics.com/analytics.js','ga'),ga('create','UA-108144808-1','auto'),ga('send','pageview'))</script><meta property="og:title" content="Virtual Memory Mechanisms"><meta property="og:description" content="As we can see in the previous post, all allocation algorithms we discussed lead to external fragmentation. As time goes by, external fragmentation is going to get worse and we need solutions for the problem. We can use swap areas to swap out memory onto the disk, or move allocated memory together(a process named memory compaction), leaving empty spaces together. Even these approaches can reduce external fragmentation and allow a higher degree of multiprogramming, they are not perfect."><meta property="og:type" content="article"><meta property="og:url" content="https://www.bodunhu.com/blog/posts/virtualaddressmechanism/"><meta property="og:image" content="https://www.bodunhu.com/blog/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2017-10-19T00:00:00+00:00"><meta property="article:modified_time" content="2017-10-19T00:00:00+00:00"><meta property="og:site_name" content="Bodun's blog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://www.bodunhu.com/blog/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Virtual Memory Mechanisms"><meta name=twitter:description content="As we can see in the previous post, all allocation algorithms we discussed lead to external fragmentation. As time goes by, external fragmentation is going to get worse and we need solutions for the problem. We can use swap areas to swap out memory onto the disk, or move allocated memory together(a process named memory compaction), leaving empty spaces together. Even these approaches can reduce external fragmentation and allow a higher degree of multiprogramming, they are not perfect."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://www.bodunhu.com/blog/posts/"},{"@type":"ListItem","position":2,"name":"Virtual Memory Mechanisms","item":"https://www.bodunhu.com/blog/posts/virtualaddressmechanism/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Virtual Memory Mechanisms","name":"Virtual Memory Mechanisms","description":"As we can see in the previous post, all allocation algorithms we discussed lead to external fragmentation. As time goes by, external fragmentation is going to get worse and we need solutions for the problem. We can use swap areas to swap out memory onto the disk, or move allocated memory together(a process named memory compaction), leaving empty spaces together. Even these approaches can reduce external fragmentation and allow a higher degree of multiprogramming, they are not perfect.","keywords":["os","mm"],"articleBody":"As we can see in the previous post, all allocation algorithms we discussed lead to external fragmentation. As time goes by, external fragmentation is going to get worse and we need solutions for the problem. We can use swap areas to swap out memory onto the disk, or move allocated memory together(a process named memory compaction), leaving empty spaces together. Even these approaches can reduce external fragmentation and allow a higher degree of multiprogramming, they are not perfect. In addition, it is possible to have a single process that is just too big to fit into memory. We are going to discuss methods used to completely eliminate external fragmentation. More than that, we will discuss how to make memory sharing possible and how to allow more processes to execute at once.\n Too big to fit It’s easy for us to assume the amount of available memory that can be allocated is not a big problem. It’s easy for programmers to assume the available memory resource is almost infinite and thus we rarely care about the situation in which the code we wrote is going to occupy all memory resource. But let’s just consider the scenario where we create a program which later create a process that is just too big to fit into memory, what should we do?\nThe natural response would be: just cut them into pieces! This is a technique called overlay: programmers manually cut the program into pieces, or overlays. When the program executes, a overlay manager is created to swap pieces in and out, allowing only necessary pieces in memory at a given time. But tell me, what is the last time you see an user-level application manually cut into “pieces” by the programmer? Doing things manually is not desired trait of a programmer. Programmers should always be lazy and automate things, or just leave it to someone else!\nPaging I’m pretty sure you don’t like the idea of overlaying as it requires you to do things manually. That’s where paging comes into play. Instead of dividing the program by the programmer, why don’t we let the system do the dirty job? Before we start, I’m going to throw two questions to you: why can a virtual address space be bigger than the physical memory? How are each piece of a process brought into the memory?\nThe technique to divide a address space into fixed-size pages is called paging. A copy of the address space is stored on the disk. The physical memory is viewed as a series of equal-sized page frames. We will discuss later about how the system choose to load a page into a frame and how to manage pages that are currently in memory.\nSo how do we use virtual addresses with the our recently introduced pages to find a location in memory? As we can see, a virtual address space is divided into pages, each with a fixed number of entries. In order to represent the number of pages and number of entries, we need two variables:\np - page number(pMAX pages)\no - page offset (difference between the byte address to search and the start of the page, MAX indicates the total number of entries in a table)\nVirtual Address calculation: oMAX x p + o (here o is the offset in the last page)\nThe frame size is equal to that of a page. It’s easy to understand since we need to put everything stored in a page into the frame, we need them both to be equally sized. Note that since virtual address space can be bigger than physical memory, the number of frames can be smaller than the number of pages, which means the number of bits reserved for frame number can be smaller than the number of bits used to indicate the number of pages.\nsource\nFrom Virtual to Physical: Allocation Policy We’ve discussed how that a process’s virtual address space can be divided into pages and mapped to frames in physical memory. Here we are going to discuss some policies used to implement the mapping process. I’m going to leave three questions to think here as well: why pages are arbitrarily located in physical memory? How do we find them if they are arbitrarily located in physical memory? Why aren’t all pages mapped to frames? These questions will become more clear as we progress into further discussion.\nHere’s the solution: a page table. Each process has one page table that contains all mapping information for each possible virtual address belonged to that process. Even though we call it table, it’s merely a data structure used by a virtual memory system in a computer operating system to store the mapping between virtual addresses and physical addresses. However, the mapping is invisible to the process. The protection mechanism is the same as dynamic relocation we’ve discussed before.\nVirtual Address Translation Now we are going through a step-by-step description of address how to translate virtual address to physical address.\n  First, the process will give the CPU a virtual address to translate.\n  Then MMU will split the address into two parts, the page number and the offset.\n  Since the size of a page and a frame are the same, the offset of the virtual address is sent along without no modification to the physical memory.\n  Use page number to find the corresponding entry in the page table.\n  Check if the page exists in physical memory.\n  If the page does exist in physical memory, the frame number is sent along. If the requested page is on the disk, then the corresponding page is moved to memory and frame number is recorded now.\n  Offset is appended to the end of the frame number to get the physical address.\n  So, we’ve achieved several goals now by using paging technique:\n  Reduce or even eliminate external fragmentation.\n  Easy to grow processes.\n  Allow more process that is too big to fit into memory to be able to execute.\n  Easy to allocate and deallocate.\n  Share memory is between processes is easy since memory used by difference processes no longer has to be contiguous. Even pages may exist in different position, they can be mapped to the same physical address in memory.\n  More about Page Table One thing to notice is that there’s only one page table for each process. The page table is part of the process’s state and serves as protection mechanism to prevent processes accessing each other’s memory. There’re several elements in each page table entry as well:\n  Flags: dirty bit, resident bit, and dirty bit (we will talk about them later). Flag is stored at the beginning of each entry.\n  Frame number: stored in the remaining bits. It tells where the page lives in physical memory.\n  However, page table still has its disadvantages, the most important thing to notice is that we need two memory accesses to implement virtual memory reference, first access is to get the page table entry, the second access is used to get the actual data from memory, if it’s present. As we know, memory access is extremly slow and expensive, thus we need something faster.\nTranslation Lookaside Buffer (TLB) Since it’s hard to improve the speed from the algorithm side, let’s just drop the algorithm for a minute and switch our focus onto the hardware. Here we will discuss how to improve the speed of memory reference by adding a hardware component called TLB. Here are several basic characteristics of TLB:\n  The TLB holds recently used frame/page pairings.\n  It has high hit ratios due to locality.\n  For a TLB hit, translation can be finished in one cycle.\n  So how does TLB help with efficiency? It’s actually really simple. The system simultaneously sends the page number to both page table and TLB. If there’s TLB hit, then the TLB cache sends the frame number to the memory without having to look into the page table, which avoids the first reference into the memory to find the page table. If there’s missing TLB, everything stays the same: look for the page table in memory and update the TLB.\nsource\nProblems with Page Table Now we solved the problems of external fragmentation. It seems paging works like a charm and makes things a lot easier. However, we notice it’s still not perfect in terms of space usage:\n  Data structure overhead (The page table can be huge!)\n  Inappropriate page size can lead to internal fragmentation, and less processes to exist in memory in the same(page too big)!\n  Thus we need more complex methods to solve the above issues.\nMulti-level Page Tables The basic concept of multi-level page table is to subdivide page number into n parts(n stands for number levels of pages tables). n is decided by the architecture of the system. Each entry in each page table which is exists each entry points to the corresponding page table in the next level. The last level page table entries hold the bit/frame information associated to the page table entry.\nSO how does it work exactly? First, we have only one first-level page table. We extract the first subdivision of the virtual address, added to the PTBR to get the corresponding entry in the first-level page table. Then we extract the second subdivision of the virtual address, add it to the address of the beginning of the second-level page table which we got from the corresponding first-level page table entry. This process continues until we reach the last-level page table. From the corresponding entry we can get the frame number. The offset is preserved so we just need to append the offset to the frame number and we’re done! One reminder is that multi-level page table requires several lookups to eventually find the frame number, so TLB becomes extremely important here in terms of improving performance.\nHow does multi-level page table save space? You’re probably still confused why multi-level page table saves space by adding more tables. Don’t worry, I will walk you through an example to illustrate the magic behind the scene:)\nAssume a process has a ((2^{10}\\) pages, each PTE occupying 4 bytes (32-bit system). Without multilevel page table, we need \\(2^{20} \\times 4 = 4MB\\) for one page table stored in memory. Even we just need a portion of all pages, we need the whole page table present in memory to find the corresponding frames. Now, if we divide the virtual address into 3 sections with last one being the offset, we have a two-level page table. The first 10 bits are used to index the page table in the first level and the next 10 bits are used to index the page table in the second level. If we only need virtual addresses that have the second 10 bits modified and leave the first 10 bits untouched, then we only need to find one entry in the first-level page table. Since the first-level page table has to be always present in memory, it will consume \\(2^{10} \\times 4=4KB\\) memory space. Now, since we need every entry in a second-level page table pointed by the entry we just found in an entry in the first-level page table, it requires \\(2^{10} \\times 4bytes = 4KB\\) memory. So we only need to use 4 + 4 = 8KB for all memory we need instead of 4MB without multi-level page tables.\nAnother interesting fact is that, even if we need to use all pages of a process, multi-level page table will potentially increase the space needed. Let’s take the above example and assume we need every single pages from a process. Then we need to store the first-level page table, which takes $2^{10} \\times 4bytes = 4KB$. Then, for each entry in the first-level page table, there’s a corresponding second-level page table, each with the size of \\(2^{10} \\times 4 = 4KB\\). Since the first-level table has \\(2^{10}\\) entries, the total number of second-level page tables is \\(2^{10}\\), each with the size of 4KB, so the total amount of spaces is \\(2^{10} \\times 4kb + 4kb = 4MB + 4KB\\). Then bottom line is: if we need to map every pages to its frames, then the total amount of entries in the last level will be the number of pages regardless of how many levels we use since each page has to have a mapping. Under such case, the total amount of memory used by the last-level page tables will be equivalent to the amount used when we use only one huge page table. The additional space comes from the upper levels, but the previous level will only save the corresponding number of entries. (number of table in the next level).\nsource\n","wordCount":"2109","inLanguage":"en","datePublished":"2017-10-19T00:00:00Z","dateModified":"2017-10-19T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.bodunhu.com/blog/posts/virtualaddressmechanism/"},"publisher":{"@type":"Organization","name":"std::bodun::blog","logo":{"@type":"ImageObject","url":"https://www.cs.utexas.edu/sites/default/files/favicon.ico"}}}</script><script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']]},svg:{fontCache:'global'}}</script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add('dark')</script><noscript><style type=text/css>#theme-toggle,.top-link{display:none}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://www.bodunhu.com/blog/ accesskey=h title="std::bodun::blog (Alt + H)">std::bodun::blog</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://www.bodunhu.com/blog/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://www.bodunhu.com/blog/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://www.bodunhu.com/blog/about/ title=About><span>About</span></a></li><li><a href=https://www.bodunhu.com/blog/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://www.bodunhu.com/blog/>Home</a>&nbsp;»&nbsp;<a href=https://www.bodunhu.com/blog/posts/>Posts</a></div><h1 class=post-title>Virtual Memory Mechanisms</h1><div class=post-meta>October 19, 2017&nbsp;·&nbsp;10 min</div></header><div class=post-content><p>As we can see in the <a href=https://bdhu.github.io/2017/10/08/virtualaddress/>previous post</a>,
all allocation algorithms we discussed lead to external fragmentation. As time goes by, external fragmentation is going to get worse and we need solutions for the problem. We can use swap areas to swap out memory onto the disk, or move allocated memory together(a process named memory compaction), leaving empty spaces together. Even these approaches can reduce external fragmentation and allow a higher degree of multiprogramming, they are not perfect. In addition, it is possible to have a single process that is just too big to fit into memory. We are going to discuss methods used to completely eliminate external fragmentation. More than that, we will discuss how to make memory sharing possible and how to allow more processes to execute at once.</p><h2 id=too-big-to-fit>Too big to fit<a hidden class=anchor aria-hidden=true href=#too-big-to-fit>#</a></h2><p>It&rsquo;s easy for us to assume the amount of available memory that can be allocated is not a big problem. It&rsquo;s easy for programmers to assume the available memory resource is almost infinite and thus we rarely care about the situation in which the code we wrote is going to occupy all memory resource. But let&rsquo;s just consider the scenario where we create a program which later create a process that is just too big to fit into memory, what should we do?</p><p>The natural response would be: just cut them into pieces! This is a technique called overlay: programmers manually cut the program into pieces, or <em>overlays</em>. When the program executes, a overlay manager is created to swap pieces in and out, allowing only necessary pieces in memory at a given time. But tell me, what is the last time you see an user-level application manually cut into &ldquo;pieces&rdquo; by the programmer? Doing things manually is not desired trait of a programmer. Programmers should always be lazy and automate things, or just leave it to someone else!</p><h2 id=paging>Paging<a hidden class=anchor aria-hidden=true href=#paging>#</a></h2><p>I&rsquo;m pretty sure you don&rsquo;t like the idea of overlaying as it requires you to do things manually. That&rsquo;s where paging comes into play. Instead of dividing the program by the programmer, why don&rsquo;t we let the system do the dirty job? Before we start, I&rsquo;m going to throw two questions to you: why can a virtual address space be bigger than the physical memory? How are each piece of a process brought into the memory?</p><p>The technique to divide a address space into fixed-size <em>pages</em> is called paging. A copy of the address space is stored on the disk. The physical memory is viewed as a series of equal-sized <em>page frames</em>. We will discuss later about how the system choose to load a page into a frame and how to manage pages that are currently in memory.</p><p>So how do we use virtual addresses with the our recently introduced pages to find a location in memory? As we can see, a virtual address space is divided into pages, each with a fixed number of entries. In order to represent the number of pages and number of entries, we need two variables:</p><p>p - page number(p<sub>MAX</sub> pages)<br>o - page offset (difference between the byte address to search and the start of the page, <sub>MAX</sub> indicates the total number of entries in a table)<br>Virtual Address calculation: o<sub>MAX</sub> x p + o (here o is the offset in the last page)</p><p>The frame size is equal to that of a page. It&rsquo;s easy to understand since we need to put everything stored in a page into the frame, we need them both to be equally sized. Note that since virtual address space can be bigger than physical memory, the number of frames can be smaller than the number of pages, which means the number of bits reserved for frame number can be smaller than the number of bits used to indicate the number of pages.</p><p align=center><img src=https://www.bottomupcs.com/chapter05/figures/virtaddress.png></p><p align=center><a href=https://www.bottomupcs.com/virtual_addresses.xhtml>source</a></p><h2 id=from-virtual-to-physical-allocation-policy>From Virtual to Physical: Allocation Policy<a hidden class=anchor aria-hidden=true href=#from-virtual-to-physical-allocation-policy>#</a></h2><p>We&rsquo;ve discussed how that a process&rsquo;s virtual address space can be divided into pages and mapped to frames in physical memory. Here we are going to discuss some policies used to implement the mapping process. I&rsquo;m going to leave three questions to think here as well: why pages are arbitrarily located in physical memory? How do we find them if they are arbitrarily located in physical memory? Why aren&rsquo;t all pages mapped to frames? These questions will become more clear as we progress into further discussion.</p><p>Here&rsquo;s the solution: a page table. Each process has one page table that contains all mapping information for each possible virtual address belonged to that process. Even though we call it table, it&rsquo;s merely a data structure used by a virtual memory system in a computer operating system to store the mapping between virtual addresses and physical addresses. However, the mapping is invisible to the process. The protection mechanism is the same as dynamic relocation we&rsquo;ve discussed before.</p><h2 id=virtual-address-translation>Virtual Address Translation<a hidden class=anchor aria-hidden=true href=#virtual-address-translation>#</a></h2><p>Now we are going through a step-by-step description of address how to translate virtual address to physical address.</p><ul><li><p>First, the process will give the CPU a virtual address to translate.</p></li><li><p>Then MMU will split the address into two parts, the page number and the offset.</p></li><li><p>Since the size of a page and a frame are the same, the offset of the virtual address is sent along without no modification to the physical memory.</p></li><li><p>Use page number to find the corresponding entry in the page table.</p></li><li><p>Check if the page exists in physical memory.</p></li><li><p>If the page does exist in physical memory, the frame number is sent along. If the requested page is on the disk, then the corresponding page is moved to memory and frame number is recorded now.</p></li><li><p>Offset is appended to the end of the frame number to get the physical address.</p></li></ul><p align=center><img src=https://upload.wikimedia.org/wikipedia/commons/8/8d/Memory_paging.jpg></p><p>So, we&rsquo;ve achieved several goals now by using paging technique:</p><ul><li><p>Reduce or even eliminate external fragmentation.</p></li><li><p>Easy to grow processes.</p></li><li><p>Allow more process that is too big to fit into memory to be able to execute.</p></li><li><p>Easy to allocate and deallocate.</p></li><li><p>Share memory is between processes is easy since memory used by difference processes no longer has to be contiguous. Even pages may exist in different position, they can be mapped to the same physical address in memory.</p></li></ul><h3 id=more-about-page-table>More about Page Table<a hidden class=anchor aria-hidden=true href=#more-about-page-table>#</a></h3><p>One thing to notice is that there&rsquo;s only one page table for each process. The page table is part of the process&rsquo;s state and serves as protection mechanism to prevent processes accessing each other&rsquo;s memory. There&rsquo;re several elements in each page table entry as well:</p><ul><li><p>Flags: dirty bit, resident bit, and dirty bit (we will talk about them later). Flag is stored at the beginning of each entry.</p></li><li><p>Frame number: stored in the remaining bits. It tells where the page lives in physical memory.</p></li></ul><p>However, page table still has its disadvantages, the most important thing to notice is that we need two memory accesses to implement virtual memory reference, first access is to get the page table entry, the second access is used to get the actual data from memory, if it&rsquo;s present. As we know, memory access is extremly slow and expensive, thus we need something faster.</p><h2 id=translation-lookaside-buffer-tlb>Translation Lookaside Buffer (TLB)<a hidden class=anchor aria-hidden=true href=#translation-lookaside-buffer-tlb>#</a></h2><p>Since it&rsquo;s hard to improve the speed from the algorithm side, let&rsquo;s just drop the algorithm for a minute and switch our focus onto the hardware. Here we will discuss how to improve the speed of memory reference by adding a hardware component called TLB. Here are several basic characteristics of TLB:</p><ul><li><p>The TLB holds recently used frame/page pairings.</p></li><li><p>It has high hit ratios due to locality.</p></li><li><p>For a TLB hit, translation can be finished in one cycle.</p></li></ul><p>So how does TLB help with efficiency? It&rsquo;s actually really simple. The system simultaneously sends the page number to both page table and TLB. If there&rsquo;s TLB hit, then the TLB cache sends the frame number to the memory without having to look into the page table, which avoids the first reference into the memory to find the page table. If there&rsquo;s missing TLB, everything stays the same: look for the page table in memory and update the TLB.</p><p align=center><img src=https://upload.wikimedia.org/wikipedia/commons/thumb/b/be/Page_table_actions.svg/500px-Page_table_actions.svg.png></p><p align=center><a href=https://commons.wikimedia.org/wiki/File:Page_table_actions.svg>source</a></p><h2 id=problems-with-page-table>Problems with Page Table<a hidden class=anchor aria-hidden=true href=#problems-with-page-table>#</a></h2><p>Now we solved the problems of external fragmentation. It seems paging works like a charm and makes things a lot easier. However, we notice it&rsquo;s still not perfect in terms of space usage:</p><ul><li><p>Data structure overhead (The page table can be huge!)</p></li><li><p>Inappropriate page size can lead to internal fragmentation, and less processes to exist in memory in the same(page too big)!</p></li></ul><p>Thus we need more complex methods to solve the above issues.</p><h2 id=multi-level-page-tables>Multi-level Page Tables<a hidden class=anchor aria-hidden=true href=#multi-level-page-tables>#</a></h2><p>The basic concept of multi-level page table is to subdivide page number into n parts(n stands for number levels of pages tables). n is decided by the architecture of the system. Each entry in each page table which is exists each entry points to the corresponding page table in the next level. The last level page table entries hold the bit/frame information associated to the page table entry.</p><p>SO how does it work exactly? First, we have only one first-level page table. We extract the first subdivision of the virtual address, added to the PTBR to get the corresponding entry in the first-level page table. Then we extract the second subdivision of the virtual address, add it to the address of the beginning of the second-level page table which we got from the corresponding first-level page table entry. This process continues until we reach the last-level page table. From the corresponding entry we can get the frame number. The offset is preserved so we just need to append the offset to the frame number and we&rsquo;re done! One reminder is that multi-level page table requires several lookups to eventually find the frame number, so TLB becomes extremely important here in terms of improving performance.</p><h3 id=how-does-multi-level-page-table-save-space>How does multi-level page table save space?<a hidden class=anchor aria-hidden=true href=#how-does-multi-level-page-table-save-space>#</a></h3><p>You&rsquo;re probably still confused why multi-level page table saves space by adding <strong>more tables</strong>. Don&rsquo;t worry, I will walk you through an example to illustrate the magic behind the scene:)</p><p>Assume a process has a ((2^{10}\) pages, each PTE occupying 4 bytes (32-bit system). Without multilevel page table, we need \(2^{20} \times 4 = 4MB\) for one page table stored in memory. Even we just need a portion of all pages, we need the whole page table present in memory to find the corresponding frames. Now, if we divide the virtual address into 3 sections with last one being the offset, we have a two-level page table. The first 10 bits are used to index the page table in the first level and the next 10 bits are used to index the page table in the second level. If we only need virtual addresses that have the second 10 bits modified and leave the first 10 bits untouched, then we only need to find one entry in the first-level page table. Since the first-level page table has to be always present in memory, it will consume \(2^{10} \times 4=4KB\) memory space. Now, since we need every entry in a second-level page table pointed by the entry we just found in an entry in the first-level page table, it requires \(2^{10} \times 4bytes = 4KB\) memory. So we only need to use 4 + 4 = 8KB for all memory we need instead of 4MB without multi-level page tables.</p><p>Another interesting fact is that, even if we need to use all pages of a process, multi-level page table will potentially increase the space needed. Let&rsquo;s take the above example and assume we need every single pages from a process. Then we need to store the first-level page table, which takes $2^{10} \times 4bytes = 4KB$. Then, for each entry in the first-level page table, there&rsquo;s a corresponding second-level page table, each with the size of \(2^{10} \times 4 = 4KB\). Since the first-level table has \(2^{10}\) entries, the total number of second-level page tables is \(2^{10}\), each with the size of 4KB, so the total amount of spaces is \(2^{10} \times 4kb + 4kb = 4MB + 4KB\). Then bottom line is: if we need to map every pages to its frames, then the total amount of entries in the last level will be the number of pages regardless of how many levels we use since each page has to have a mapping. Under such case, the total amount of memory used by the last-level page tables will be equivalent to the amount used when we use only one huge page table. The additional space comes from the upper levels, but the previous level will only save the corresponding number of entries. (number of table in the next level).</p><p align=center><img src=https://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/X86_Paging_PAE_4K.svg/440px-X86_Paging_PAE_4K.svg.png></p><p align=center><a href=https://en.wikipedia.org/wiki/Page_table>source</a></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://www.bodunhu.com/blog/tags/os/>os</a></li><li><a href=https://www.bodunhu.com/blog/tags/mm/>mm</a></li></ul><nav class=paginav><a class=prev href=https://www.bodunhu.com/blog/posts/disks/><span class=title>« Prev Page</span><br><span>Disk Introduction</span></a>
<a class=next href=https://www.bodunhu.com/blog/posts/virtualaddress/><span class=title>Next Page »</span><br><span>Virtual Memory Overview</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Virtual Memory Mechanisms on twitter" href="https://twitter.com/intent/tweet/?text=Virtual%20Memory%20Mechanisms&url=https%3a%2f%2fwww.bodunhu.com%2fblog%2fposts%2fvirtualaddressmechanism%2f&hashtags=os%2cmm"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Virtual Memory Mechanisms on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fwww.bodunhu.com%2fblog%2fposts%2fvirtualaddressmechanism%2f&title=Virtual%20Memory%20Mechanisms&summary=Virtual%20Memory%20Mechanisms&source=https%3a%2f%2fwww.bodunhu.com%2fblog%2fposts%2fvirtualaddressmechanism%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Virtual Memory Mechanisms on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fwww.bodunhu.com%2fblog%2fposts%2fvirtualaddressmechanism%2f&title=Virtual%20Memory%20Mechanisms"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Virtual Memory Mechanisms on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fwww.bodunhu.com%2fblog%2fposts%2fvirtualaddressmechanism%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Virtual Memory Mechanisms on whatsapp" href="https://api.whatsapp.com/send?text=Virtual%20Memory%20Mechanisms%20-%20https%3a%2f%2fwww.bodunhu.com%2fblog%2fposts%2fvirtualaddressmechanism%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Virtual Memory Mechanisms on telegram" href="https://telegram.me/share/url?text=Virtual%20Memory%20Mechanisms&url=https%3a%2f%2fwww.bodunhu.com%2fblog%2fposts%2fvirtualaddressmechanism%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer><script src=https://utteranc.es/client.js repo=BDHU/blog issue-term=pathname theme=github-light crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2021 <a href=https://www.bodunhu.com/blog/>std::bodun::blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)"><button class=top-link id=top-link type=button accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></button></a>
<script>let menu=document.getElementById('menu');menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)},document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script></body></html>