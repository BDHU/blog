<!doctype html><html><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="PhD student at University of Texas at Austin ðŸ¤˜. Doing systems for ML."><link rel="shortcut icon" href=https://www.bodunhu.com/blog/favicon.ico><link rel=stylesheet href=/blog/css/style.min.css><script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']]},svg:{fontCache:'global'}}</script><script type=text/javascript id=MathJax-script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js async></script><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)}(window,document,'script','https://www.google-analytics.com/analytics.js','ga'),ga('create','UA-108144808-1','auto'),ga('send','pageview'))</script><script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga('create','UA-108144808-1','auto'),ga('send','pageview'))</script><script async src=https://www.google-analytics.com/analytics.js></script><title>Whiz: Data-Driven Analytics Execution</title></head><body><header id=return><h2></h2><a href=https://www.bodunhu.com/blog/>std::bodun::blog</a></header><main id=content><article><header id=post-header><h1>Whiz: Data-Driven Analytics Execution</h1><div><time>Sep 5, 2021</time></div></header><p>This paper by <a href=https://utns.cs.utexas.edu/>UTNS</a> lab appeared in <a href=https://www.usenix.org/conference/nsdi21>NSDI 2021</a>. It presents a data-analytics framework that decouples intermediate data from computations.</p><p>Whiz addresses several challenged posed by current analytics frameworks. The first one is data opacity. Most modern data analytics frameworks relies on MapReduce execution engine. The developer specifies the map and reduce function, which then get submitted to the analytics framework. The workflow can be expressed as a logical graph; the physical graph (which includes the cluster configuration, disk quota, etc.) is generated transparently. The workflow is shown below:</p><p><img src=https://cdn.jsdelivr.net/gh/BDHU/Page_Pics/posts/whiz-data-driven-analytics-execution/limitation1.png#center alt=mapreduce-limitation></p><p>The problem is in the region marked yellow. It shows the execution engine has limited runtime visibility into the intermediate data. Thus, adapting processing logic of tasks based on the states of intermediate data becomes challenging.</p><p>In addition, task parallelism and intermediate data partition strategy are often static. In the graph above, the intermediate data partition tasks and the final reduce tasks might be determined prematurely, without taking the intermediate data partition characteristics into account. For example, <a href=https://itnext.io/handling-data-skew-in-apache-spark-9f56343e58e8>data skew</a> (unevenly distributed jobs) causes different reduce nodes to process different amount of tasks. The graph below illustrates how the shuffle stage can result in disproportional intermediate data partitions.</p><p><img src=https://cdn.jsdelivr.net/gh/BDHU/Page_Pics/posts/whiz-data-driven-analytics-execution/data-skew.png#center alt=data-skew></p><p>Finally, Whiz addresses the limitation posed by compute-driven scheduling. In compute-driven scheduling, one stage usually relies on the completion of the upstream tasks, the may lead to compute idling waiting for remaining data to become available, even if the a subset of workers in the current stage is ready for execution. Decoupling data from computation enables the execution engine to treat intermediate data as first-class citizen, thus allowing finer-grained control of data processing.</p><p>In summary, Whiz solves two problems presented in compute-centric execution engines:</p><ul><li>Tight coupling between intermediate data and compute.</li><li>intermediate data agnosticity.</li></ul><p>Thus, Whiz creates a feedback loop between the execution service and the data service so that the execution can dynamically adjust its policy based on the information offered by the data service to optimize system performances.</p><p><img src=https://cdn.jsdelivr.net/gh/BDHU/Page_Pics/posts/whiz-data-driven-analytics-execution/whiz-control-flow.png#center alt=whiz-control-flow></p><p>Whiz classifies itself as a <strong>data-driven</strong> execution engine, which drives execution based on intermediate data properties. Making intermediate data visible opens door for optimization opportunities, thus increasing performances. For more technical details regarding the architecture and implementation of Whiz, please refer to the original <a href=https://www.usenix.org/system/files/nsdi21-grandl.pdf>paper</a>.</p><div style=width:100% id=comment><script src=https://utteranc.es/client.js repo=BDHU/blog issue-term=pathname theme=preferred-color-scheme crossorigin=anonymous async></script></div></article></main><footer id=footer><p>Â© 2022 Bodun Hu. All rights reserved.</p></footer></body></html>