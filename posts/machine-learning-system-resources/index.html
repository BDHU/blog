<!doctype html><html lang=en-us><head><meta http-equiv=x-clacks-overhead content="GNU Terry Pratchett"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Machine Learning System Resources | std::bodun::blog</title><meta name=title content="Machine Learning System Resources"><meta name=description content="This is my personal list of resources related to machine learning systems. Feel free to drop me an email if you think there&rsquo;s something worth mentioning. I will try to update this page frequently to include the most recent stuffs in mlsys. Resources Facebook&rsquo;s external large-scale work NGC Container Doc Awesome-System-for-Machine-Learning: A curated list of research in machine learning systems (MLSys). Paper notes are also provided. Courses Deep Learning Systems:"><meta name=keywords content="mlsys,"><meta property="og:title" content="Machine Learning System Resources"><meta property="og:description" content="This is my personal list of resources related to machine learning systems. Feel free to drop me an email if you think there&rsquo;s something worth mentioning. I will try to update this page frequently to include the most recent stuffs in mlsys. Resources Facebook&rsquo;s external large-scale work NGC Container Doc Awesome-System-for-Machine-Learning: A curated list of research in machine learning systems (MLSys). Paper notes are also provided. Courses Deep Learning Systems:"><meta property="og:type" content="article"><meta property="og:url" content="https://www.bodunhu.com/blog/posts/machine-learning-system-resources/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-01-08T00:00:00+00:00"><meta property="article:modified_time" content="2023-04-09T10:59:57-05:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Machine Learning System Resources"><meta name=twitter:description content="This is my personal list of resources related to machine learning systems. Feel free to drop me an email if you think there&rsquo;s something worth mentioning. I will try to update this page frequently to include the most recent stuffs in mlsys. Resources Facebook&rsquo;s external large-scale work NGC Container Doc Awesome-System-for-Machine-Learning: A curated list of research in machine learning systems (MLSys). Paper notes are also provided. Courses Deep Learning Systems:"><meta name=twitter:site content="@https://twitter.com/BodunHu"><meta itemprop=name content="Machine Learning System Resources"><meta itemprop=description content="This is my personal list of resources related to machine learning systems. Feel free to drop me an email if you think there&rsquo;s something worth mentioning. I will try to update this page frequently to include the most recent stuffs in mlsys. Resources Facebook&rsquo;s external large-scale work NGC Container Doc Awesome-System-for-Machine-Learning: A curated list of research in machine learning systems (MLSys). Paper notes are also provided. Courses Deep Learning Systems:"><meta itemprop=datePublished content="2022-01-08T00:00:00+00:00"><meta itemprop=dateModified content="2023-04-09T10:59:57-05:00"><meta itemprop=wordCount content="854"><meta itemprop=keywords content="mlsys,"><meta name=referrer content="no-referrer-when-downgrade"><style>body{font-family:Verdana,sans-serif;margin:auto;padding:20px;max-width:720px;text-align:left;background-color:#fff;word-wrap:break-word;overflow-wrap:break-word;line-height:1.5;color:#444}h1,h2,h3,h4,h5,h6,strong,b{color:#222}a{color:#3273dc}.title{text-decoration:none;border:0}.title span{font-weight:400}nav a{margin-right:10px}textarea{width:100%;font-size:16px}input{font-size:16px}content{line-height:1.6}table{width:100%}img{max-width:100%}code{padding:2px 5px;background-color:#f2f2f2}pre code{color:#222;display:block;padding:20px;white-space:pre-wrap;font-size:14px;overflow-x:auto}div.highlight pre{background-color:initial;color:initial}div.highlight code{background-color:unset;color:unset}blockquote{border-left:1px solid #999;color:#222;padding-left:20px;font-style:italic}footer{padding:25px;text-align:center}.helptext{color:#777;font-size:small}.errorlist{color:#eba613;font-size:small}ul.blog-posts{list-style-type:none;padding:unset}ul.blog-posts li{display:flex}ul.blog-posts li span{flex:0 0 130px}ul.blog-posts li a:visited{color:#8b6fcb}@media(prefers-color-scheme:dark){body{background-color:#333;color:#ddd}h1,h2,h3,h4,h5,h6,strong,b{color:#eee}a{color:#8cc2dd}code{background-color:#777}pre code{color:#ddd}blockquote{color:#ccc}textarea,input{background-color:#252525;color:#ddd}.helptext{color:#aaa}}</style></head><body><header><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},svg:{fontCache:"global"}}</script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><a href=/blog/ class=title><h2>std::bodun::blog</h2></a><nav><a href=/blog/>Home</a>
<a href=/blog/posts/>Archive</a>
<a href=https://www.bodunhu.com/>About</a></nav></header><main><h1>Machine Learning System Resources</h1><p><i><time datetime=2022-01-08 pubdate>08 Jan, 2022</time></i></p><content><p>This is my personal list of resources related to machine learning systems. Feel free to drop me an email if you think there&rsquo;s something worth mentioning. I will try to update this page frequently to include the most recent stuffs in mlsys.</p><h2 id=resources>Resources</h2><ul><li><a href=https://github.com/facebookresearch/metaseq>Facebook&rsquo;s external large-scale work</a></li><li><a href=https://docs.nvidia.com/deeplearning/frameworks/support-matrix/index.html>NGC Container Doc</a></li><li><a href=https://github.com/HuaizhengZhang/Awesome-System-for-Machine-Learning>Awesome-System-for-Machine-Learning</a>: A curated list of research in machine learning systems (MLSys). Paper notes are also provided.</li></ul><h2 id=courses>Courses</h2><ul><li><a href=https://dlsyscourse.org/>Deep Learning Systems: Algorithms and Implementation</a></li><li><a href=https://mlc.ai/summer22/>Machine Learning Compilation</a>: offered by <a href=https://tqchen.com/>Tianqi Chen</a>, intro to ML compiler. Open to all.</li><li><a href=https://catalyst.cs.cmu.edu/15-884-mlsys-sp21/>15-884: Machine Learning Systems</a>: offered by <a href=https://tqchen.com/>Tianqi Chen</a> at CMU.</li><li><a href=https://cseweb.ucsd.edu/classes/wi19/cse291-f/>CSE 291F: Advanced Data Analytics and ML Systems</a>: offered by <a href=https://cseweb.ucsd.edu/~arunkk/>Arun Kumar</a> at UCSD.</li><li><a href=https://github.com/tqchen/tinyflow>Tinyflow</a>: tutorial code on how to build your own Deep Learning System in 2k Lines.</li><li><a href=https://dlsys.cs.washington.edu/>CSE 599W: Systems for ML</a>: offered by <a href=https://tqchen.com/>Tianqi Chen</a> at UW.</li><li><a href=https://docs.google.com/document/d/1aLkd6Nxhoa9s7_zf8AiT9dcFBxtM3oJAywRHBMHHvmg/edit>CS8803-SMR: Special Topics: Systems for Machine Learning</a>: offered by <a href=https://faculty.cc.gatech.edu/~atumanov/>Alexey Tumanov</a> at Georgia Tech. [<a href=https://docs.google.com/spreadsheets/d/14sRj5WJ1P0UpZULLj5ysS5Avl1czeAVUv47gEr40nu4/edit>schedule</a>]</li><li><a href=http://pages.cs.wisc.edu/~akella/CS744/F17/>CS 744: Big Data Systems</a>: offered by <a href=https://www.cs.utexas.edu/~akella/>Aditya Akella</a> back at UW-Madison.</li><li><a href=https://stanford-cs329s.github.io/>CS 329S: Machine Learning Systems Design</a>: offered by Stanford.</li><li><a href=https://github.com/mosharaf/eecs598/tree/w21-ai>EECS 598: Systems for AI</a>: offered by <a href=https://www.mosharaf.com/>Mosharaf Chowdhury</a> at UMich.</li><li><a href=https://www.cs.utexas.edu/~akella/CS378/S22/>CS 378: Big Data Systems</a>: offered by <a href=https://www.cs.utexas.edu/~akella/>Aditya Akella</a> at UT.</li><li><a href=https://ucbrise.github.io/cs294-ai-sys-fa19/>Machine Learning Systems (Fall 2019)</a>: from UCB</li><li><a href=https://sites.utexas.edu/neeraja/sysml-computer-systems-and-machine-learning-interplay-spring-2023/>ECE 382V SysML: Computer Systems and Machine Learning Interplay</a>: taught by <a href=https://sites.utexas.edu/neeraja/>Neeraja Yadwadkar</a> at UT.</li></ul><h2 id=labs--faculties>Labs & Faculties</h2><ul><li><a href=https://catalyst.cs.cmu.edu/>CMU Catalyst</a></li><li><a href=https://rise.cs.berkeley.edu/>Berkeley RISE Lab</a></li><li><a href=http://dsail.csail.mit.edu/>MIT DASIL Lab</a></li><li><a href=https://sampl.cs.washington.edu/>UW SAMPL</a></li><li><a href=https://symbioticlab.org/>SymbioticLab</a></li><li><a href=https://shivaram.org>Shivaram Venkataraman at UW-Madison</a></li><li><a href=https://utns.cs.utexas.edu/>UTNS Lab</a></li><li><a href=https://sites.utexas.edu/neeraja/>Neeraja Yadwadkar at UT Austin</a></li><li><a href=https://faculty.cc.gatech.edu/~atumanov/index.html#researchgroup>SAIL: Systems for Artificial Intelligence Lab @ GT</a></li><li><a href=https://www.microsoft.com/en-us/research/people/amar/>Amar Phanishayee at MSR</a></li></ul><h2 id=tutorials>Tutorials</h2><ul><li><a href=https://d2l.ai/>Dive into Deep Learning</a>: interactive deep learning book with code, math, and discussions.</li><li><a href=https://cs231n.github.io/>CS231n: Convolutional Neural Networks for Visual Recognition</a></li><li><a href=http://blog.ezyang.com/2019/05/pytorch-internals/>Pytorch-Internals</a>: must-read for PyTorch basics.</li><li><a href=https://ericmjl.github.io/dl-workshop/index.html>Differential Programming with JAX</a></li><li><a href=https://roberttlange.github.io/posts/2020/03/blog-post-10/>Getting started with JAX (MLPs, CNNs & RNNs)</a></li><li><a href=https://physicsbaseddeeplearning.org/intro.html>Physics-based Deep Learning</a></li><li><a href=https://openmlsys.github.io/>机器学习系统：设计和实现</a></li><li><a href=https://tvm.d2l.ai/>Dive into Deep Learning Compiler</a></li><li><a href=https://jax.readthedocs.io/en/latest/autodidax.html>Autodidax: JAX core from scratch</a>: really really good resource for learning Jax internals.</li><li><a href=https://github.com/dfm/extending-jax>Extending JAX with custom C++ and CUDA code</a></li><li><a href=http://cs231n.stanford.edu/vecDerivs.pdf>Vector, Matrix, and Tensor Derivatives</a></li><li><a href=https://dlsys.cs.washington.edu/pdf/lecture9.pdf>ML Memory Optimization</a>: slides from UW. Visualization of dataflow graph helps understand how to optimize memory.</li></ul><h2 id=posts--blogs>Posts & Blogs</h2><ul><li><a href=https://medium.com/ibm-data-ai/how-to-load-pytorch-models-340-times-faster-with-ray-8be751a6944c>How to Load PyTorch Models 340 Times Faster with Ray</a></li><li><a href=https://zhuanlan.zhihu.com/p/30976469>分布式深度学习系统</a></li><li><a href=https://zhuanlan.zhihu.com/p/104444471>MLsys各方向综述</a></li><li><a href=https://www.zhihu.com/people/jin-xue-feng/columns>金雪锋</a>: MindSpore 技术负责人</li><li><a href=https://zhuanlan.zhihu.com/p/495592456>解读谷歌Pathways架构（一）：Single-controller与Multi-controller</a></li><li><a href=https://petewarden.com/2021/12/24/why-are-ml-compilers-so-hard/>Why are ML Compilers so Hard?</a></li><li><a href=https://ai.googleblog.com/2022/05/alpa-automated-model-parallel-deep.html>Alpa: Automated Model-Parallel Deep Learning</a></li><li><a href=https://www.telesens.co/2022/04/23/data-transfer-speed-comparison-ray-plasma-store-vs-s3/>Data Transfer Speed Comparison: Ray Plasma Store vs. S3</a></li><li><a href=https://www.zhihu.com/column/giantpandacv>从零开始学深度学习编译器</a></li></ul><h2 id=papers>Papers</h2><p>This section could potentially be extremely long..</p><h3 id=ml-compilers>ML Compilers</h3><ul><li><a href=https://arxiv.org/pdf/1802.04799.pdf>TVM: An Automated End-to-End Optimizing Compiler for Deep Learning</a></li><li><a href=https://arxiv.org/pdf/1805.08166.pdf>Learning to Optimize Tensor Programs</a>: facilitate efficient ML kernel search using ML.</li><li><a href=https://arxiv.org/abs/1901.10008>The OoO VLIW JIT Compiler for GPU Inference</a>: JIT Compiler to enable better GPU multiplexing.</li><li><a href=https://arxiv.org/abs/2102.13267>LazyTensor: combining eager execution with domain-specific compilers</a>: combining dynamic graph with JIT. <a href=https://zhuanlan.zhihu.com/p/383547872>summary</a></li><li><a href=https://www.cs.utexas.edu/~bornholt/papers/quantized-cgo20.pdf>Automatic Generation of High-Performance Quantized Machine Learning Kernels</a></li><li><a href=https://proceedings.mlsys.org/paper/2022/file/fa7cdfad1a5aaf8370ebeda47a1ff1c3-Paper.pdf>DietCode: Automatic Optimization for Dynamic Tensor Programs</a></li><li><a href=https://proceedings.mlsys.org/paper/2022/file/d3d9446802a44259755d38e6d163e820-Paper.pdf>The CoRa Tensor Compiler: Compilation for Ragged Tensors with Minimal Padding</a></li><li><a href=https://arxiv.org/pdf/2002.03794.pdf>The Deep Learning Compiler: A Comprehensive Survey</a></li><li><a href=https://gnnsys.github.io/papers/GNNSys21_paper_10.pdf>Graphiler: A Compiler for Graph Neural Networks</a>: ML compiler specifically designed for GNN.</li></ul><h3 id=inference>Inference</h3><ul><li><a href=https://arxiv.org/pdf/2207.00032.pdf>DeepSpeed Inference: Enabling Efficient Inference of Transformer Models at Unprecedented Scale</a>: transformer-specific inference optimization done by DeepSpeed.</li><li><a href=https://www.usenix.org/system/files/conference/nsdi17/nsdi17-crankshaw.pdf>Clipper: A Low-Latency Online Prediction Serving System</a>: a nice overview of inference system. Not SOTA but a good starter.</li><li><a href=https://arxiv.org/pdf/2209.00159.pdf>Orloj: Predictably Serving Unpredictable DNNs</a>: shares similarity to Clipper, but targeting models that may yield unpredictable performance.</li><li><a href=https://arxiv.org/pdf/2302.11665.pdf>AlpaServe: Statistical Multiplexing with Model Parallelism for Deep Learning Serving</a>: how to multiplex devices to serve multiple model while meeting latency constraint.</li><li><a href=https://arxiv.org/pdf/2203.09040.pdf>A Survey of Multi-Tenant Deep Learning Inference on GPU</a>: efficient resource management for multi-tenant inference.</li></ul><h3 id=dynamic-neural-network>Dynamic Neural Network</h3><ul><li><a href=https://arxiv.org/pdf/2102.04906.pdf>Dynamic Neural Networks: A Survey</a></li><li><a href=https://arxiv.org/pdf/2204.00102.pdf>Dynamic Multimodal Fusion</a></li><li><a href=https://arxiv.org/pdf/2106.04426.pdf>Hash Layers For Large Sparse Models</a>: Using hashing for MoE gating.</li><li><a href=https://arxiv.org/pdf/2205.12755.pdf>An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale Multitask Learning Systems</a>: use evolution algorithm to update model structure during the training phase.</li></ul><h3 id=auto-placement>Auto Placement</h3><ul><li><a href=https://arxiv.org/pdf/2201.12023.pdf>Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning</a></li><li><a href=https://arxiv.org/pdf/1807.05358.pdf>Beyond Data and Model Parallelism for Deep Neural Networks</a>: called FlexFlow.</li></ul><h3 id=federated-learning>Federated Learning</h3><ul><li><a href=https://arxiv.org/pdf/1907.09693>A Survey on Federated Learning Systems: Vision, Hype and Reality for Data Privacy and Protection</a></li></ul><h3 id=switch--ml>Switch & ML</h3><ul><li><a href=https://www.cl.cam.ac.uk/~nz247/publications/xiong2019dream.pdf>Do Switches Dream of Machine Learning? Toward In-Network Classification</a></li><li><a href=https://arxiv.org/pdf/2002.08987.pdf>Taurus: A Data Plane Architecture for Per-Packet ML</a></li></ul><h3 id=memory-management>Memory Management</h3><ul><li><a href=https://arxiv.org/pdf/2104.07857.pdf>ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning</a></li></ul><h3 id=system-design>System Design</h3><ul><li><a href=https://arxiv.org/pdf/2203.12533.pdf>Pathways: Asynchronous Distributed Dataflow for ML</a>: Google&rsquo;s new DL systems, specifically designed for TPU.</li><li><a href=https://arxiv.org/pdf/1712.05889.pdf>Ray: A Distributed Framework for Emerging AI Applications</a>: RiseLab&rsquo;s new distributed system. Using shared memory for data communication.</li><li><a href=https://arxiv.org/pdf/2110.14883.pdf>Colossal-AI: A Unified Deep Learning System For Large-Scale Parallel Training</a></li><li><a href=https://arxiv.org/pdf/2110.15032.pdf>OneFlow: Redesign the Distributed Deep Learning Framework from Scratch</a>: shared many similarities to Google&rsquo;s Pathways.</li></ul></content><p></p></main><footer>Made with <a href=https://github.com/janraasch/hugo-bearblog/>Hugo ʕ•ᴥ•ʔ Bear</a></footer></body></html>