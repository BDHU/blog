<!doctype html><html><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="PhD student at University of Texas at Austin 🤘. Doing systems for ML."><link rel="shortcut icon" href=https://www.bodunhu.com/blog/favicon.ico><link rel=stylesheet href=/blog/css/style.min.css><script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']]},svg:{fontCache:'global'}}</script><script type=text/javascript id=MathJax-script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js async></script><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)}(window,document,'script','https://www.google-analytics.com/analytics.js','ga'),ga('create','UA-108144808-1','auto'),ga('send','pageview'))</script><script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga('create','UA-108144808-1','auto'),ga('send','pageview'))</script><script async src=https://www.google-analytics.com/analytics.js></script><title>Machine Learning System Resources</title></head><body><header id=return><h2></h2><a href=https://www.bodunhu.com/blog/><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" style="vertical-align:-.125em" width="1em" height="1em" viewBox="0 0 24 24"><path fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="m11 5-7 7 7 7m-7-7h16"/></svg>&nbsp;Back</a></header><main id=content><article><header id=post-header><h1>Machine Learning System Resources</h1><div><time>Jan 8, 2022</time></div></header><p>This is my personal list of resources related to machine learning systems. Feel free to drop me an email if you think there&rsquo;s something worth mentioning. I will try to update this page frequently to include the most recent stuffs in mlsys.</p><h2 id=resources>Resources</h2><ul><li><a href=https://github.com/facebookresearch/metaseq>Facebook&rsquo;s external large-scale work</a></li></ul><h2 id=courses>Courses</h2><ul><li><a href=https://mlc.ai/summer22/>Machine Learning Compilation</a>: offered by <a href=https://tqchen.com/>Tianqi Chen</a>, intro to ML compiler. Open to all.</li><li><a href=https://catalyst.cs.cmu.edu/15-884-mlsys-sp21/>15-884: Machine Learning Systems</a>: offered by <a href=https://tqchen.com/>Tianqi Chen</a> at CMU.</li><li><a href=https://cseweb.ucsd.edu/classes/wi19/cse291-f/>CSE 291F: Advanced Data Analytics and ML Systems</a>: offered by <a href=https://cseweb.ucsd.edu/~arunkk/>Arun Kumar</a> at UCSD.</li><li><a href=https://github.com/tqchen/tinyflow>Tinyflow</a>: tutorial code on how to build your own Deep Learning System in 2k Lines.</li><li><a href=https://dlsys.cs.washington.edu/>CSE 599W: Systems for ML</a>: offered by <a href=https://tqchen.com/>Tianqi Chen</a> at UW.</li><li><a href=https://docs.google.com/document/d/1aLkd6Nxhoa9s7_zf8AiT9dcFBxtM3oJAywRHBMHHvmg/edit>CS8803-SMR: Special Topics: Systems for Machine Learning</a>: offered by <a href=https://faculty.cc.gatech.edu/~atumanov/>Alexey Tumanov</a> at Georgia Tech. [<a href=https://docs.google.com/spreadsheets/d/14sRj5WJ1P0UpZULLj5ysS5Avl1czeAVUv47gEr40nu4/edit>schedule</a>]</li><li><a href=http://pages.cs.wisc.edu/~akella/CS744/F17/>CS 744: Big Data Systems</a>: offered by <a href=https://www.cs.utexas.edu/~akella/>Aditya Akella</a> back at UW-Madison.</li><li><a href=https://stanford-cs329s.github.io/>CS 329S: Machine Learning Systems Design</a>: offered by Stanford.</li><li><a href=https://github.com/mosharaf/eecs598/tree/w21-ai>EECS 598: Systems for AI</a>: offered by <a href=https://www.mosharaf.com/>Mosharaf Chowdhury</a> at UMich.</li><li><a href=https://www.cs.utexas.edu/~akella/CS378/S22/>CS 378: Big Data Systems</a>: offered by <a href=https://www.cs.utexas.edu/~akella/>Aditya Akella</a> at UT.</li><li><a href=https://ucbrise.github.io/cs294-ai-sys-fa19/>Machine Learning Systems (Fall 2019)</a>: from UCB</li></ul><h2 id=labs--faculties>Labs & Faculties</h2><ul><li><a href=https://catalyst.cs.cmu.edu/>CMU Catalyst</a></li><li><a href=https://rise.cs.berkeley.edu/>Berkeley RISE Lab</a></li><li><a href=http://dsail.csail.mit.edu/>MIT DASIL Lab</a></li><li><a href=https://sampl.cs.washington.edu/>UW SAMPL</a></li><li><a href=https://symbioticlab.org/>SymbioticLab</a></li><li><a href=https://shivaram.org>Shivaram Venkataraman at UW-Madison</a></li><li><a href=https://utns.cs.utexas.edu/>UTNS Lab</a></li><li><a href=https://sites.utexas.edu/neeraja/>Neeraja Yadwadkar at UT Austin</a></li><li><a href=https://faculty.cc.gatech.edu/~atumanov/index.html#researchgroup>SAIL: Systems for Artificial Intelligence Lab @ GT</a></li><li><a href=https://www.microsoft.com/en-us/research/people/amar/>Amar Phanishayee at MSR</a></li></ul><h2 id=tutorials>Tutorials</h2><ul><li><a href=https://d2l.ai/>Dive into Deep Learning</a>: interactive deep learning book with code, math, and discussions.</li><li><a href=https://cs231n.github.io/>CS231n: Convolutional Neural Networks for Visual Recognition</a></li><li><a href=http://blog.ezyang.com/2019/05/pytorch-internals/>Pytorch-Internals</a>: must-read for PyTorch basics.</li><li><a href=https://ericmjl.github.io/dl-workshop/index.html>Differential Programming with JAX</a></li><li><a href=https://roberttlange.github.io/posts/2020/03/blog-post-10/>Getting started with JAX (MLPs, CNNs & RNNs)</a></li><li><a href=https://physicsbaseddeeplearning.org/intro.html>Physics-based Deep Learning</a></li><li><a href=https://zhuanlan.zhihu.com/p/104444471>MLsys各方向综述</a></li><li><a href=https://zhuanlan.zhihu.com/p/30976469>分布式深度学习系统</a></li><li><a href=https://openmlsys.github.io/>机器学习系统：设计和实现</a></li><li><a href=https://tvm.d2l.ai/>Dive into Deep Learning Compiler</a></li><li><a href=https://jax.readthedocs.io/en/latest/autodidax.html>Autodidax: JAX core from scratch</a>: really really good resource for learning Jax internals.</li><li><a href=https://github.com/dfm/extending-jax>Extending JAX with custom C++ and CUDA code</a></li></ul><h2 id=backpropagation>Backpropagation</h2><ul><li><a href=http://cs231n.stanford.edu/vecDerivs.pdf>Vector, Matrix, and Tensor Derivatives</a></li></ul><h2 id=posts--blogs>Posts & Blogs</h2><ul><li><a href=https://medium.com/ibm-data-ai/how-to-load-pytorch-models-340-times-faster-with-ray-8be751a6944c>How to Load PyTorch Models 340 Times Faster with Ray</a></li><li><a href=https://www.zhihu.com/people/jin-xue-feng/columns>金雪锋</a>: MindSpore 技术负责人</li><li><a href=https://zhuanlan.zhihu.com/p/495592456>解读谷歌Pathways架构（一）：Single-controller与Multi-controller</a></li><li><a href=https://petewarden.com/2021/12/24/why-are-ml-compilers-so-hard/>Why are ML Compilers so Hard?</a></li><li><a href=https://ai.googleblog.com/2022/05/alpa-automated-model-parallel-deep.html>Alpa: Automated Model-Parallel Deep Learning</a></li><li><a href=https://www.telesens.co/2022/04/23/data-transfer-speed-comparison-ray-plasma-store-vs-s3/>Data Transfer Speed Comparison: Ray Plasma Store vs. S3</a></li><li><a href=https://www.zhihu.com/column/giantpandacv>从零开始学深度学习编译器</a></li></ul><h2 id=papers>Papers</h2><p>This section could potentially be extremely long..</p><h3 id=ml-compilers>ML Compilers</h3><ul><li><a href=https://arxiv.org/abs/1901.10008>The OoO VLIW JIT Compiler for GPU Inference</a>: JIT Compiler to enable better GPU multiplexing.</li><li><a href=https://arxiv.org/abs/2102.13267>LazyTensor: combining eager execution with domain-specific compilers</a>: combining dynamic graph with JIT. <a href=https://zhuanlan.zhihu.com/p/383547872>summary</a></li><li><a href=https://www.cs.utexas.edu/~bornholt/papers/quantized-cgo20.pdf>Automatic Generation of High-Performance Quantized Machine Learning Kernels</a></li><li><a href=https://arxiv.org/pdf/2002.03794.pdf>The Deep Learning Compiler: A Comprehensive Survey</a></li></ul><h3 id=dynamic-neural-network>Dynamic Neural Network</h3><ul><li><a href=https://arxiv.org/pdf/2102.04906.pdf>Dynamic Neural Networks: A Survey</a></li><li><a href=https://arxiv.org/pdf/2204.00102.pdf>Dynamic Multimodal Fusion</a></li><li><a href=https://arxiv.org/pdf/2106.04426.pdf>Hash Layers For Large Sparse Models</a>: Using hashing for MoE gating.</li><li><a href=https://arxiv.org/pdf/2205.12755.pdf>An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale Multitask Learning Systems</a></li></ul><h3 id=federated-learning>Federated Learning</h3><ul><li><a href=https://arxiv.org/pdf/1907.09693>A Survey on Federated Learning Systems: Vision, Hype and Reality for Data Privacy and Protection</a></li></ul><h3 id=switch--ml>Switch & ML</h3><ul><li><a href=https://www.cl.cam.ac.uk/~nz247/publications/xiong2019dream.pdf>Do Switches Dream of Machine Learning? Toward In-Network Classification</a></li><li><a href=https://arxiv.org/pdf/2002.08987.pdf>Taurus: A Data Plane Architecture for Per-Packet ML</a></li></ul><h3 id=memory-management>Memory Management</h3><ul><li><a href=https://arxiv.org/pdf/2104.07857.pdf>ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning</a></li></ul><div style=width:100% id=comment><script src=https://utteranc.es/client.js repo=BDHU/blog issue-term=pathname theme=github-light crossorigin=anonymous async></script></div></article></main><footer id=footer><p>© 2022 Bodun Hu. All rights reserved.</p></footer></body></html>