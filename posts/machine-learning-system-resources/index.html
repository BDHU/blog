<!doctype html><html><head><meta charset=utf-8><meta name=viewport content="width=device-width"><title>Machine Learning System Resources</title><link rel=stylesheet href=https://www.bodunhu.com/blog/css/colors-preference.min.3ad46450d59177206f28dcac6dd37d7032546cd0e43b77a576f6aa60a5e4d5d8.css><link rel="shortcut icon" href=https://www.bodunhu.com/blog/favicon.ico><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},svg:{fontCache:"global"}}</script><script type=text/javascript id=MathJax-script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js async></script><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-108144808-1","auto"),ga("send","pageview"))</script><script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-108144808-1","auto"),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script></head><body><header id=header><h1><a href=https://www.bodunhu.com/blog/>std::bodun::blog</a></h1><p>PhD student at University of Texas at Austin ü§ò. Doing systems for ML.</p></header><div id=page><div id=sidebar><nav><ul class=nav><li><a href=/blog/posts/><span>Archive</span>&nbsp;&nbsp;</a></li><li><a href=https://www.bodunhu.com/><span>About</span>&nbsp;&nbsp;</a></li><li><a href=/blog/index.xml><span>Feed</span>&nbsp;&nbsp;</a></li></ul></nav></div><div id=content><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/machine-learning-system-resources/>Machine Learning System Resources</a></h1><div class=post-content><p>This is my personal list of resources related to machine learning systems. Feel free to drop me an email if you think there&rsquo;s something worth mentioning. I will try to update this page frequently to include the most recent stuffs in mlsys.</p><h2 id=resources>Resources</h2><ul><li><a href=https://github.com/facebookresearch/metaseq>Facebook&rsquo;s external large-scale work</a></li></ul><h2 id=courses>Courses</h2><ul><li><a href=https://catalyst.cs.cmu.edu/15-884-mlsys-sp21/>15-884: Machine Learning Systems</a>: offered by <a href=https://tqchen.com/>Tianqi Chen</a> at CMU.</li><li><a href=https://cseweb.ucsd.edu/classes/wi19/cse291-f/>CSE 291F: Advanced Data Analytics and ML Systems</a>: offered by <a href=https://cseweb.ucsd.edu/~arunkk/>Arun Kumar</a> at UCSD.</li><li><a href=https://github.com/tqchen/tinyflow>Tinyflow</a>: tutorial code on how to build your own Deep Learning System in 2k Lines.</li><li><a href=https://dlsys.cs.washington.edu/>CSE 599W: Systems for ML</a>: offered by <a href=https://tqchen.com/>Tianqi Chen</a> at UW.</li><li><a href=https://docs.google.com/document/d/1aLkd6Nxhoa9s7_zf8AiT9dcFBxtM3oJAywRHBMHHvmg/edit>CS8803-SMR: Special Topics: Systems for Machine Learning</a>: offered by <a href=https://faculty.cc.gatech.edu/~atumanov/>Alexey Tumanov</a> at Georgia Tech. [<a href=https://docs.google.com/spreadsheets/d/14sRj5WJ1P0UpZULLj5ysS5Avl1czeAVUv47gEr40nu4/edit>schedule</a>]</li><li><a href=http://pages.cs.wisc.edu/~akella/CS744/F17/>CS 744: Big Data Systems</a>: offered by <a href=https://www.cs.utexas.edu/~akella/>Aditya Akella</a> back at UW-Madison.</li><li><a href=https://stanford-cs329s.github.io/>CS 329S: Machine Learning Systems Design</a>: offered by Stanford.</li><li><a href=https://github.com/mosharaf/eecs598/tree/w21-ai>EECS 598: Systems for AI</a>: offered by <a href=https://www.mosharaf.com/>Mosharaf Chowdhury</a> at UMich.</li><li><a href=https://www.cs.utexas.edu/~akella/CS378/S22/>CS 378: Big Data Systems</a>: offered by <a href=https://www.cs.utexas.edu/~akella/>Aditya Akella</a> at UT.</li><li><a href=https://ucbrise.github.io/cs294-ai-sys-fa19/>Machine Learning Systems (Fall 2019)</a>: from UCB</li></ul><h2 id=labs--faculties>Labs & Faculties</h2><ul><li><a href=https://catalyst.cs.cmu.edu/>CMU Catalyst</a></li><li><a href=https://rise.cs.berkeley.edu/>Berkeley RISE Lab</a></li><li><a href=http://dsail.csail.mit.edu/>MIT DASIL Lab</a></li><li><a href=https://sampl.cs.washington.edu/>UW SAMPL</a></li><li><a href=https://symbioticlab.org/>SymbioticLab</a></li><li><a href=https://shivaram.org>Shivaram Venkataraman at UW-Madison</a></li><li><a href=https://utns.cs.utexas.edu/>UTNS Lab</a></li><li><a href=https://sites.utexas.edu/neeraja/>Neeraja Yadwadkar at UT Austin</a></li><li><a href=https://faculty.cc.gatech.edu/~atumanov/index.html#researchgroup>SAIL: Systems for Artificial Intelligence Lab @ GT</a></li><li><a href=https://www.microsoft.com/en-us/research/people/amar/>Amar Phanishayee at MSR</a></li></ul><h2 id=tutorials>Tutorials</h2><ul><li><a href=https://d2l.ai/>Dive into Deep Learning</a>: interactive deep learning book with code, math, and discussions.</li><li><a href=https://cs231n.github.io/>CS231n: Convolutional Neural Networks for Visual Recognition</a></li><li><a href=http://blog.ezyang.com/2019/05/pytorch-internals/>Pytorch-Internals</a>: must-read for PyTorch basics.</li><li><a href=https://ericmjl.github.io/dl-workshop/index.html>Differential Programming with JAX</a></li><li><a href=https://roberttlange.github.io/posts/2020/03/blog-post-10/>Getting started with JAX (MLPs, CNNs & RNNs)</a></li><li><a href=https://physicsbaseddeeplearning.org/intro.html>Physics-based Deep Learning</a></li><li><a href=https://zhuanlan.zhihu.com/p/104444471>MLsysÂêÑÊñπÂêëÁªºËø∞</a></li><li><a href=https://zhuanlan.zhihu.com/p/30976469>ÂàÜÂ∏ÉÂºèÊ∑±Â∫¶Â≠¶‰π†Á≥ªÁªü</a></li><li><a href=https://openmlsys.github.io/>Êú∫Âô®Â≠¶‰π†Á≥ªÁªüÔºöËÆæËÆ°ÂíåÂÆûÁé∞</a></li><li><a href=https://tvm.d2l.ai/>Dive into Deep Learning Compiler</a></li></ul><h2 id=backpropagation>Backpropagation</h2><ul><li><a href=http://cs231n.stanford.edu/vecDerivs.pdf>Vector, Matrix, and Tensor Derivatives</a></li></ul><h2 id=posts--blogs>Posts & Blogs</h2><ul><li><a href=https://medium.com/ibm-data-ai/how-to-load-pytorch-models-340-times-faster-with-ray-8be751a6944c>How to Load PyTorch Models 340 Times Faster with Ray</a></li><li><a href=https://www.zhihu.com/people/jin-xue-feng/columns>ÈáëÈõ™Èîã</a>: MindSpore ÊäÄÊúØË¥üË¥£‰∫∫</li><li><a href=https://petewarden.com/2021/12/24/why-are-ml-compilers-so-hard/>Why are ML Compilers so Hard?</a></li></ul><h2 id=papers>Papers</h2><p>This section could potentially be extremely long..</p><h3 id=ml-compilers>ML Compilers</h3><ul><li><a href=https://arxiv.org/abs/1901.10008>The OoO VLIW JIT Compiler for GPU Inference</a>: JIT Compiler to enable better GPU multiplexing.</li><li><a href=https://arxiv.org/abs/2102.13267>LazyTensor: combining eager execution with domain-specific compilers</a>: combining dynamic graph with JIT. <a href=https://zhuanlan.zhihu.com/p/383547872>summary</a></li><li><a href=https://www.cs.utexas.edu/~bornholt/papers/quantized-cgo20.pdf>Automatic Generation of High-Performance Quantized Machine Learning Kernels</a></li><li><a href=https://arxiv.org/pdf/2002.03794.pdf>The Deep Learning Compiler: A Comprehensive Survey</a></li></ul><h3 id=dynamic-neural-network>Dynamic Neural Network</h3><ul><li><a href=https://arxiv.org/pdf/2102.04906.pdf>Dynamic Neural Networks: A Survey</a></li><li><a href=https://arxiv.org/pdf/2204.00102.pdf>Dynamic Multimodal Fusion</a></li><li><a href=https://arxiv.org/pdf/2106.04426.pdf>Hash Layers For Large Sparse Models</a>: Using hashing for MoE gating.</li></ul><h3 id=federated-learning>Federated Learning</h3><ul><li><a href=https://arxiv.org/pdf/1907.09693>A Survey on Federated Learning Systems: Vision, Hype and Reality for Data Privacy and Protection</a></li></ul><h3 id=switch--ml>Switch & ML</h3><ul><li><a href=https://www.cl.cam.ac.uk/~nz247/publications/xiong2019dream.pdf>Do Switches Dream of Machine Learning? Toward In-Network Classification</a></li><li><a href=https://arxiv.org/pdf/2002.08987.pdf>Taurus: A Data Plane Architecture for Per-Packet ML</a></li></ul><h3 id=memory-management>Memory Management</h3><ul><li><a href=https://arxiv.org/pdf/2104.07857.pdf>ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning</a></li></ul></div><p class=meta>Posted on <span class=postdate>08. January 2022</span></p></article></div><footer id=footer><p class=copyright><p>¬© 2022 <a href=https://www.bodunhu.com>Bodun Hu</a>. All rights reserved.</p></p></footer></div></body></html>