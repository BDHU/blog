<!doctype html><html lang=en-us><head><meta http-equiv=x-clacks-overhead content="GNU Terry Pratchett"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Paper Review - Dynamic Tensor Rematerialization | std::bodun::blog</title><meta name=title content="Paper Review - Dynamic Tensor Rematerialization"><meta name=description content="Dynamic Tensor Rematerialization (DTR) treats GPU memory as a large cache, where tensors can be evicted to save memory, and recomputed if needed later.
DTR&rsquo;s eviction policy relies on the heuristic \(h\). The heuristic assigns a value \(h(t)\) to each resident tensor \(t\), approximating the cost of evicting the tensor. DTR evicts the tensor with the lowest cost based on the value of \(h\). \(h\) can factor in arbitrary metadata."><meta name=keywords content="paper-review,ml,check-pointing,"><meta property="og:title" content="Paper Review - Dynamic Tensor Rematerialization"><meta property="og:description" content="Dynamic Tensor Rematerialization (DTR) treats GPU memory as a large cache, where tensors can be evicted to save memory, and recomputed if needed later.
DTR&rsquo;s eviction policy relies on the heuristic \(h\). The heuristic assigns a value \(h(t)\) to each resident tensor \(t\), approximating the cost of evicting the tensor. DTR evicts the tensor with the lowest cost based on the value of \(h\). \(h\) can factor in arbitrary metadata."><meta property="og:type" content="article"><meta property="og:url" content="https://www.bodunhu.com/blog/posts/paper-review-dynamic-tensor-rematerialization/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-11-09T00:00:00+00:00"><meta property="article:modified_time" content="2022-02-14T18:49:17-06:00"><meta property="og:site_name" content="std::bodun::blog"><meta name=twitter:card content="summary"><meta name=twitter:title content="Paper Review - Dynamic Tensor Rematerialization"><meta name=twitter:description content="Dynamic Tensor Rematerialization (DTR) treats GPU memory as a large cache, where tensors can be evicted to save memory, and recomputed if needed later.
DTR&rsquo;s eviction policy relies on the heuristic \(h\). The heuristic assigns a value \(h(t)\) to each resident tensor \(t\), approximating the cost of evicting the tensor. DTR evicts the tensor with the lowest cost based on the value of \(h\). \(h\) can factor in arbitrary metadata."><meta name=twitter:site content="@https://twitter.com/BodunHu"><meta itemprop=name content="Paper Review - Dynamic Tensor Rematerialization"><meta itemprop=description content="Dynamic Tensor Rematerialization (DTR) treats GPU memory as a large cache, where tensors can be evicted to save memory, and recomputed if needed later.
DTR&rsquo;s eviction policy relies on the heuristic \(h\). The heuristic assigns a value \(h(t)\) to each resident tensor \(t\), approximating the cost of evicting the tensor. DTR evicts the tensor with the lowest cost based on the value of \(h\). \(h\) can factor in arbitrary metadata."><meta itemprop=datePublished content="2021-11-09T00:00:00+00:00"><meta itemprop=dateModified content="2022-02-14T18:49:17-06:00"><meta itemprop=wordCount content="257"><meta itemprop=keywords content="paper-review,ml,check-pointing,"><meta name=referrer content="no-referrer-when-downgrade"><style>body{ <!-- font-family: Verdana, sans-serif; --> font-family: "Hoefler Text", "Palatino", "Palatino Linotype", "Libre Caslon Text", serif;margin:auto;padding:20px;max-width:720px;text-align:left;background-color:#fff;word-wrap:break-word;overflow-wrap:break-word;line-height:1.5;color:#444}h1,h2,h3,h4,h5,h6,strong,b{color:#222}a{color:#3273dc}.title{text-decoration:none;border:0}.title span{font-weight:400}nav a{margin-right:10px}textarea{width:100%;font-size:16px}input{font-size:16px}content{line-height:1.6}table{width:100%}img{max-width:100%}code{padding:2px 5px;background-color:#f2f2f2}pre code{color:#222;display:block;padding:20px;white-space:pre-wrap;font-size:14px;overflow-x:auto}div.highlight pre{background-color:initial;color:initial}div.highlight code{background-color:unset;color:unset}blockquote{border-left:1px solid #999;color:#222;padding-left:20px;font-style:italic}footer{padding:25px;text-align:center}.helptext{color:#777;font-size:small}.errorlist{color:#eba613;font-size:small}ul.blog-posts{list-style-type:none;padding:unset}ul.blog-posts li{display:flex}ul.blog-posts li span{flex:0 0 130px}ul.blog-posts li a:visited{color:#8b6fcb}@media(prefers-color-scheme:dark){body{background-color:#333;color:#ddd}h1,h2,h3,h4,h5,h6,strong,b{color:#eee}a{color:#8cc2dd}code{background-color:#777}pre code{color:#ddd}blockquote{color:#ccc}textarea,input{background-color:#252525;color:#ddd}.helptext{color:#aaa}}</style></head><body><header><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},svg:{fontCache:"global"}}</script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><a href=/blog/ class=title><h2>std::bodun::blog</h2></a><nav><a href=/blog/>Home</a>
<a href=/blog/posts/>Archive</a>
<a href=https://www.bodunhu.com/>About</a></nav></header><main><h1>Paper Review - Dynamic Tensor Rematerialization</h1><p><i><time datetime=2021-11-09 pubdate>09 Nov, 2021</time></i></p><content><p>Dynamic Tensor Rematerialization (<a href=https://arxiv.org/pdf/2006.09616.pdf>DTR</a>) treats GPU memory as a large cache, where tensors can be evicted to save memory, and recomputed if needed later.</p><p>DTR&rsquo;s eviction policy relies on the heuristic \(h\). The heuristic assigns a value \(h(t)\) to each resident tensor \(t\), approximating the cost of evicting the tensor. DTR evicts the tensor with the lowest cost based on the value of \(h\). \(h\) can factor in arbitrary metadata.</p><p>During every operator call in <a href=https://pytorch.org/>PyTorch</a>, DTR intercepts the call and performs the following tasks:</p><p><img src=https://cdn.jsdelivr.net/gh/BDHU/Page_Pics/posts/DTR/DTR-operator-intercept.png#center alt=DTR-operator-intercept></p><p>In short, whenever we perform an operation, we first recursively re-calculate all the non-resident tensors the current operation depends on, while evicting tensors we don&rsquo;t need until there are enough GPU space left. To decide which tensors to evict, DTR uses the tensor with the lowest value \(h\):</p><p><img src=https://cdn.jsdelivr.net/gh/BDHU/Page_Pics/posts/DTR/tensor-evict.png#center alt=tensor-evict></p><p>The heuristic \(h\) evicts tensors based on three properties: staleness, size, and compute cost. It evicts tensors that are: least recently used, takes large GPU memory space, and easy to recompute. \(H _{DTR}\) is computed as:</p><p>\[
h _{DTR}(s, m, c) (t) := \frac{c(t)}{m(t) \cdot s(t)&rsquo;}
\]</p><p>Recomputing an evicted tensor \(t\) may result in recomputing many more tensors that \(t\) recursively depends on. Thus, the paper proposes an improved heuristic to take the recursive recomputations into account (with more maintenance cost). These tensors are called <em>evicted neighborhood \(e ^{*} (t)\)</em>.</p><p>\[
h_ {DTR-improved}(s, m, c) (t) := \frac{c(t) + \sum _{u \in e ^{*} (t)} c(u)}{m(t) \cdot s(t)&rsquo;}
\]</p><p>This heuristic captures the recomputation costs for all tensors that \(t\) recursively depend on.</p></content><p></p></main><footer>Made with <a href=https://github.com/janraasch/hugo-bearblog/>Hugo ʕ•ᴥ•ʔ Bear</a></footer></body></html>