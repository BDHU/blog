<!doctype html><html><head><meta charset=utf-8><meta name=viewport content="width=device-width"><link href=/blog/posts/index.xml rel=alternate type=application/rss+xml title=std::bodun::blog><link href=/blog/posts/index.xml rel=feed type=application/rss+xml title=std::bodun::blog><title>Archive</title><link rel=stylesheet href=https://www.bodunhu.com/blog/css/colors-preference.min.dddc2fcdb891a1db68ce11889cba6460d5657d27aabe5603f335aa754f424381.css><link rel="shortcut icon" href=https://www.bodunhu.com/blog/favicon.ico><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},svg:{fontCache:"global"}}</script><script type=text/javascript id=MathJax-script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js async></script><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-108144808-1","auto"),ga("send","pageview"))</script><script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-108144808-1","auto"),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script></head><body><header id=header><h1><a href=https://www.bodunhu.com/blog/>std::bodun::blog</a></h1><p>PhD student at University of Texas at Austin ü§ò. Doing systems for ML.</p></header><div id=page><div id=sidebar><nav><ul class=nav><li><a href=https://www.bodunhu.com/><span>About</span></a></li><li><a href=https://twitter.com/BodunHu><span>Twitter</span></a></li><li><a href=/blog/index.xml><span>Feed</span></a></li></ul></nav></div><div id=content><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/flexflow/>FlexFlow</a></h1><div class=post-content><p>FlexFlow is a deep learning framework that discovers a fast parallelization strategy for distributed DNN training. It uses SOAP (Sample-Operation-Attribute-Parameter) search space of parallelization strategies. in short, FlexFlow automates the parallelization of model training.</p></div><p class=meta>Posted on <span class=postdate>22. February 2022</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/add-mermaid-to-hugo-with-dark-mode/>Add Mermaid to Hugo with Dark Mode</a></h1><div class=post-content><p>Recently, I was revisiting materials in Deep Learning. I need tools that generate diagrams easily. Drawing the graphs from scratch and upload them individually to the image hosting platform is a daunting process. This is when Mermaid comes into rescue. Now I can generate diagrams directly using Markdown. Here&rsquo;s how to do it inside a Hugo site.</p></div><p class=meta>Posted on <span class=postdate>15. February 2022</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/cross-entropy-loss/>Cross Entropy Loss</a></h1><div class=post-content><p>Many deep learning tasks involve classification, where a model outputs a series of probabilities for their corresponding labels. The goal is to correctly predict a given input&rsquo;s label. Mathematically, it means generating max probabilities for the correct label. The probabilities are generated through a process called softmax.
The softmax function outputs a vector \(\hat{y}\), which represents estimated conditional probabilities of each class given an input \(x\), For example, \(\hat{y}_1 = P(y=\textrm{car}\ |\ x)\). ‚Ä¶</p></div><p class=meta>Posted on <span class=postdate>13. February 2022</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/maximum-likelihood-for-classification/>Maximum Likelihood for Classification</a></h1><div class=post-content><p>Let&rsquo;s say we want to classify an input text \(y\) and give it a label \(x\). Formally, we want to find:
\[ \textrm{argmax} P(x | y) \]
By Bayes&rsquo; rule this is the same as
\[ \textrm{argmax} \frac{P(y|x)P(y)}{P(x)} \]
Suppose we have five documents as training data and one document as the input as testing data. Our objective is to give a label to the test sentence.
Credit: Eunsol Choi Let&rsquo;s define the probability of class as (\(N\) is the total number of classes) ‚Ä¶</p></div><p class=meta>Posted on <span class=postdate>24. January 2022</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/machine-learning-system-resources/>Machine Learning System Resources</a></h1><div class=post-content><p>This is my personal list of resources related to machine learning systems. Feel free to drop me an email if you think there&rsquo;s something worth mentioning. I will try to update this page frequently to include the most recent stuffs in mlsys. Courses 15-884: Machine Learning Systems: offered by Tianqi Chen at CMU. CSE 291F: Advanced Data Analytics and ML Systems: offered by Arun Kumar at UCSD. Tinyflow: tutorial code ‚Ä¶</p></div><p class=meta>Posted on <span class=postdate>08. January 2022</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/megatron-with-fastmoe/>Megatron with FastMoE</a></h1><div class=post-content><p>This is a guide on setting up Megatron-LM with FastMoE. Megatron is a transformer developed by the Applied Deep Learning Research team at NVIDIA. FastMoE enables PyTorch support for the Mixture of Experts (MoE) models. We use the FastMoE layer to replace the MLP layers in the transformer language model.
Prerequisites Docker We recommend using one of NGC&rsquo;s recent PyTorch containers. The Megatron-LM repo uses pytorch:20.12-py3. We pull the image with: ‚Ä¶</p></div><p class=meta>Posted on <span class=postdate>01. December 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/set-up-slurm-across-multiple-machines/>Set up Slurm across Multiple Machines</a></h1><div class=post-content><p>To install Slurm, we need to have admin access to the machine. This post explains how I got Slurm running in multiple Linux servers. All servers are running on Ubuntu 18.04 LTS.</p></div><p class=meta>Posted on <span class=postdate>16. November 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/paper-review-dynamic-tensor-rematerialization/>Paper Review - Dynamic Tensor Rematerialization</a></h1><div class=post-content><p>Dynamic Tensor Rematerialization (DTR) treats GPU memory as a large cache, where tensors can be evicted to save memory, and recomputed if needed later.
DTR&rsquo;s eviction policy relies on the heuristic \(h\). The heuristic assigns a value \(h(t)\) to each resident tensor \(t\), approximating the cost of evicting the tensor. DTR evicts the tensor with the lowest cost based on the value of \(h\). \(h\) can factor in arbitrary metadata. ‚Ä¶</p></div><p class=meta>Posted on <span class=postdate>09. November 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/paper-review-capuchin-tensor-based-gpu-memory-management-for-deep-learning/>Paper Review - Capuchin: Tensor-based GPU Memory Management for Deep Learning</a></h1><div class=post-content><p>This paper aims to reduce GPU memory usage during DNN training. Capuchin achieves this goal though swapping and recomputation, using tensor as unit of operation. The major question is how to balance between swapping and recomputation to achieve max resource utilization.
Swap and Recomputation Benefit The ultimate goal of swapping and recomputation is to hide the overhead as much as possible to minimize the wait time of back-access (a tensor evicted earlier being accessed again). ‚Ä¶</p></div><p class=meta>Posted on <span class=postdate>07. November 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/starting-out-phd/>Starting Out PhD</a></h1><div class=post-content><p>Today marks the third month of my PhD life. Things finally start to become a little bit clearer. I finally have some potentially concrete ideas to work on.
Finding a research topic was the most difficult part. For several months, I was wondering around like a headless chicken, reading papers after papers: serverless, ML inference, compiler, pathlet routing, RDMA, you name it. The feeling of not having a topic was suffocating. ‚Ä¶</p></div><p class=meta>Posted on <span class=postdate>05. November 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/handle-github-password-authentication-deprecation/>Handle GitHub Password Authentication Deprecation</a></h1><div class=post-content><p>Recently, GitHub deprecated the use of password for repos. You will have to generate GitHub tokens to access repos. It&rsquo;s difficult for me to memorize the token without serious efforts. Fortunately, it&rsquo;s easy to mitigate the problem.
After a repo is cloned, simply execute
git remote remove origin to remote the old remote. Then, execute the following command:
git remote add origin https://&lt;TOKEN>@github.com/&lt;GITHUB_USERNAME>/&lt;REPO>.git Finally, execute the following command to setup upstream: ‚Ä¶</p></div><p class=meta>Posted on <span class=postdate>19. October 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/consensus-problem-in-distributed-systems/>Consensus Problem in Distributed Systems</a></h1><div class=post-content><p>In a distributed system, it is common for processes to reach consensus. When all non-faulty processes terminate, we must guarantee that everyone agrees on a specific value.</p></div><p class=meta>Posted on <span class=postdate>18. October 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/fault-tolerance-in-distributed-systems/>Fault Tolerance in Distributed Systems</a></h1><div class=post-content><p>No systems can provide fault-free guarantees, including distributed systems. However, failures in distributed systems are independent. It means only a subset of processes fail at once.</p></div><p class=meta>Posted on <span class=postdate>05. October 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/consistency-models-explained/>Consistency Models Explained</a></h1><div class=post-content><p>In a distributed system, eventual consistency provides a weak guarantee that data updates will be reflected in all nodes eventually. However, the downside of eventual consistency is that clients could potentially observe awkward intermediate states</p></div><p class=meta>Posted on <span class=postdate>23. September 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/lamport-distributed-mutual-exclusion/>Lamport Distributed Mutual Exclusion</a></h1><div class=post-content><p>Normally, having consistent event ordering in a distributed system is hard because we have no common clock. Since we don&rsquo;t have a common clock to measure with, we rely on logical properties of time in the absence of clock.</p></div><p class=meta>Posted on <span class=postdate>21. September 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/specifying-token-ring-for-mutual-exclusion/>Specifying Token Ring for Mutual Exclusion</a></h1><div class=post-content><p>Mutual exclusion is a common term appearing frequently in computer sciences. In essence, it&rsquo;s a mechanism of concurrency control allowing exclusive access to some resource (or &lsquo;&lsquo;critical region&rsquo;&rsquo;).</p></div><p class=meta>Posted on <span class=postdate>11. September 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/writing-specifications-for-a-distributed-system-using-ivy/>Writing Specifications for a Distributed System using Ivy</a></h1><div class=post-content><p>Before we jump into how to write specifications in a distributed setting, we first define what a specification is. I take the definition from the magnificent Ken McMillan: a specification is a statement</p></div><p class=meta>Posted on <span class=postdate>08. September 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/whiz-data-driven-analytics-execution/>Whiz: Data-Driven Analytics Execution</a></h1><div class=post-content><p>This paper by UTNS lab appeared in NSDI 2021. It presents a data-analytics framework that decouples intermediate data from computations</p></div><p class=meta>Posted on <span class=postdate>05. September 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/in-network-aggregation-for-shared-machine-learning-clusters/>In-Network Aggregation for Shared Machine Learning Clusters</a></h1><div class=post-content><p>This paper by Nadeen appeared in MLSys 2021. It presents an in-network aggregation framework called PANAMA for distributed ML training tasks.</p></div><p class=meta>Posted on <span class=postdate>31. August 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/what-is-memcached/>What is Memcached</a></h1><div class=post-content><p>Memcached is a high-performance, distributed caching system. Although application-neutral, it&rsquo;s most commonly used to speed up dynamic Web applications by alleviating database load. Memcached is used on LiveJournal, Slashdot, Wikipedia and other high-traffic sites</p></div><p class=meta>Posted on <span class=postdate>29. August 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/deploy-hugo-site-to-github-pages/>Deploy Hugo Site to GitHub Pages</a></h1><div class=post-content><p>This post assumes the user has already setup two separate repositories: a private repository for Hugo source files, and a public repository for GitHub Pages.</p></div><p class=meta>Posted on <span class=postdate>27. August 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/quantum-search-algorithm/>Quantum Search Algorithm</a></h1><div class=post-content><p>This is a comprehensive summary over how Grover&rsquo;s quantum search algorithm works. It explains the three major steps involved in Grover&rsquo;s iteration</p></div><p class=meta>Posted on <span class=postdate>20. August 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/quantum-state-in-a-nutshell/>Quantum State in a Nutshell</a></h1><div class=post-content><p>There are thousands of articles trying to explain what exactly a quantum state is. Many of them boiled down to the state of a qubit is 0, 1, or 0 and 1 at the same time</p></div><p class=meta>Posted on <span class=postdate>19. August 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/writing-in-the-sciences-writing-process/>Writing in the Sciences - Writing Process</a></h1><div class=post-content><p>This post covers the topics mentioned in Writing in the Sciences offered on Coursera.
Writing Process The writing process includes three steps:
Prewriting Collect and organize information Brainstorm take-home messages Work out ideas away from the computer Develop a road map Writing the first draft Putting ideas together in organized prose Revision Read out loud Cut the clutter Verb check Get feedback A lot of people often convolute step 2 and 3. ‚Ä¶</p></div><p class=meta>Posted on <span class=postdate>09. August 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/writing-in-the-sciences-structure/>Writing in the Sciences - Structure</a></h1><div class=post-content><p>This post covers how to improve sentence structures, and builds to to writing strong paragraphs. Most contents comes from the Writing in the Sciences course offered on Coursera</p></div><p class=meta>Posted on <span class=postdate>08. August 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/writing-in-the-sciences-verbs/>Writing in the Sciences - Verbs</a></h1><div class=post-content><p>This is an overview of the second chapter of Writing in the Sciences offered by Stanford. This chapter focuses on writing with strong, active verbs. Lessons include how to</p></div><p class=meta>Posted on <span class=postdate>31. July 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/writing-in-the-sciences-cut-the-clutter/>Writing in the Sciences - Cut the Clutter</a></h1><div class=post-content><p>This is an overview over the first chapter of Writing in the Sciences offered by Stanford.
The secret of good writing is to strip every sentence to its cleanest components. Every word that serves no function, every long word that could be a short word, every adverb that carries the same meaning that&rsquo;s already in the verb, every passive construction that leaves the reader unsure of who is doing what. ‚Ä¶</p></div><p class=meta>Posted on <span class=postdate>30. July 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/unitary-matrix/>Unitary Matrix</a></h1><div class=post-content><p>Recently, I was trying to get the hang of quantum computing. I found myself in a position where I forgot most of the linear algebra stuff I&rsquo;ve learned in past semesters. So again, I decide to put them down in hope that some of the knowledge here will stay in my memory a bit longer</p></div><p class=meta>Posted on <span class=postdate>14. July 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/bgp-in-a-nutshell/>BGP in a Nutshell</a></h1><div class=post-content><p>Border Gateway Protocol (BGP) protocol has a very simple purpose: choose the fastest and the most efficient route to deliver a message from one autonomous system (AS) to another. In layman&rsquo;s term, BGP is the GPS for the internet. Many contents here are credit to Prof. Mohamed G. Gouda.
In a nutshell, BGP informs each router \(R\) how to route packets to an IP prefix \(pf\) (i.e. block of IP addresses) that is used in \(AS_i\) different from \(AS_j\), where \(R\) is located: ‚Ä¶</p></div><p class=meta>Posted on <span class=postdate>06. July 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/from-autotools-to-cmake/>From Autotools to CMake</a></h1><div class=post-content><p>Since my paper on GPU benchmarking was published, every once in a while, I got emails asking me why Altis doesn&rsquo;t build on their platforms. It almost always has something to do a small script which is responsible for finding CUDA dependencies. This script is invoked every single time make is executed. For some reason, the regular expression in the script sometimes breaks randomly, depending on the Linux distro, the kernel version, the host architecture, or even the CUDA version. ‚Ä¶</p></div><p class=meta>Posted on <span class=postdate>21. June 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/how-sat-solver-works/>How SAT Solver works</a></h1><div class=post-content><p>This is a summary over the high-level design of SAT solver covered in Prof. Dillig&rsquo;s Automated Logical Reasoning class. It&rsquo;s meant to cover the basic steps towards determining whether a given boolean formula is satisfiable or not</p></div><p class=meta>Posted on <span class=postdate>21. May 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/experience-on-dafny-programming/>Experience on Dafny Programming</a></h1><div class=post-content><p>Because of Professor Dillig&rsquo;s class, I finally got the chance to try out Dafny, a language made by Microsoft Research, with built-in support for formal specification through preconditions, postconditions, loop invariants and loop variants. I often think, what if we write programs in a verification language, would there be much less bugs and will it make our lives much easier than sitting in front a screen for hours grinding at bugs. ‚Ä¶</p></div><p class=meta>Posted on <span class=postdate>16. May 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/ethereum/>Ethereum</a></h1><div class=post-content><p>In my previous post, we&rsquo;ve gone over the high-level structure of blockchain and its corresponding attributes. This post is going to cover Ethereum and explore how blockchain can be used not only for money transfer but also application development</p></div><p class=meta>Posted on <span class=postdate>14. May 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/reflections-on-my-cs-phd-application-process/>Reflections on my CS PhD Application Process</a></h1><div class=post-content><p>I applied for CS Ph.D. programs this past fall and had interviews with schools from late December all the way to March. Now that the semester has ended, I decided to put down some reflections on this process. This post is not intended to be the most comprehensive CS Ph.D. application tutorial in the world, but merely a half-guide half-memoir of journey towards a PhD. Of course, you should take this post with a grain of salt, since I don&rsquo;t work on admission committees, and am no where near an expert in the application process</p></div><p class=meta>Posted on <span class=postdate>10. May 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/blockchain/>Blockchain</a></h1><div class=post-content><p>The first time I&rsquo;ve heard the term &lsquo;&lsquo;blockchain&rsquo;&rsquo; was around 2014. Since then, its popularity has grown rapidly. However, I&rsquo;ve never actually understand what blockchain is exactly, until recently. In fact, I didn&rsquo;t really understand the difference between blockchain and bitcoin. For me, blockchain is clubbed with cryptocurrencies. So here is a short summary of what blockchain is and why people use blockchain</p></div><p class=meta>Posted on <span class=postdate>19. April 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/hoare-logic/>Hoare Logic</a></h1><div class=post-content><p>Hoare logic forms the basis of all deductive verification. To illustrate Hoare logic, we will first consider a smaller imperative programming language IMP</p></div><p class=meta>Posted on <span class=postdate>17. April 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/congruence-closure/>Congruence Closure</a></h1><div class=post-content><p>This is a summary of how to compute congruence closure. I implemented the algorithm to compute congruence closure and thought I&rsquo;d never forget it. But my memory starts to get blurry just after two days. So I figured I&rsquo;d put things down so I don&rsquo;t have to watch the entire lecture again the next time I need it</p></div><p class=meta>Posted on <span class=postdate>27. March 2021</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/program-loading-and-memory-mapping-in-linux/>Program Loading and Memory Mapping in Linux</a></h1><div class=post-content><p>The goal here is to familiarize yourself with how programs are loaded, dynamically paged, and some of the mechanics of signal handling and memory mapping in Linux</p></div><p class=meta>Posted on <span class=postdate>03. November 2020</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/scheduler-activation/>Scheduler Activation</a></h1><div class=post-content><p>This is a summary on scheduler activation. To discuss about scheduler activation, we must first understand what is a thread. A thread of execution is the smallest sequence of programmed instructions that can be managed independently by a scheduler</p></div><p class=meta>Posted on <span class=postdate>24. October 2020</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/add-mathjax-v3-support-to-jekyll-and-hugo/>Add MathJax v3 Support to Jekyll and Hugo</a></h1><div class=post-content><p>I was using Mathjax v2 for a while and I heard v3 perform significantly better than v2. Many great tutorials explains explains how to add Mathjax support to Jekyll websites. Some of them only cover Mathjax v2. So here is the brief summary on how to add Mathjax v3 support to your Jekyll website (Recently I&rsquo;ve migrated to Hugo but adding support to Hugo is also pretty similar)</p></div><p class=meta>Posted on <span class=postdate>22. October 2020</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/linux-program-measurement-and-mmap/>Linux Program Measurement and mmap</a></h1><div class=post-content><p>This is a summary over Linux kernel program measurement and mmap. The specs of our experiment environment is listed below. For more details regarding the CPU spec please refer to cpu world for more info</p></div><p class=meta>Posted on <span class=postdate>23. September 2020</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/memory-resource-management-in-vmware-esx-server/>Memory Resource Management in VMware ESX Server</a></h1><div class=post-content><p>VMWare ESX Server is a software layer designed to multiplex hardware resources among virtual machines running unmodified commodity operating systems. ESX Server, different to VMware Workstation, is a type 1 hypervisor, which means it runs directly on bare metal. ESX Server focuses on running guest VMs without modifying the guest OSes at all, which is challenging.
Memory Virtualization is done by interposing an extra abstraction layer between a physical address from the VM&rsquo;s point of view, and a machine address which represents the actual hardware memory. ‚Ä¶</p></div><p class=meta>Posted on <span class=postdate>21. September 2020</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/xen-and-the-art-of-virtualization/>Xen and the Art of Virtualization</a></h1><div class=post-content><p>Xen is an x86 virtual machine monitor which allows multiple commodity operating systems to share conventional hardware in a safe and resource managed fashion, without sacrificing either performance or functionality. Xen is type I hypervisor, which directly runs on top of bare metal. We will summarize what Xen is what its attributes are.
paravirtualization - presents a virtual machine abstraction that is similar but not identical to the underlying hardware. ‚Ä¶</p></div><p class=meta>Posted on <span class=postdate>16. September 2020</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/start-linux-kernel-hacking/>Start Linux Kernel Hacking</a></h1><div class=post-content><p>This is a summary of how to compile and boot the Linux kernel on the KVM-qemu virtual machine. It covers how to get a VM running in KVM, how to build a customized kernel, and how to use GDB with the Linux kernel. The experiment is conducted on an amd64 architecture CPU. We use Ubuntu as our testing environment but the steps covered here should apply to other distros as well</p></div><p class=meta>Posted on <span class=postdate>14. September 2020</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/performance-anomaly-of-802.11b/>Performance Anomaly of 802.11b</a></h1><div class=post-content><p>This research is conducted by Martin Heusse, Franck Rousseau, Cilles Berger-Sabbatel, Andrzej Duda on analyzing the performance of the IEEE 802.11b wireless local area networks. Degraded transmitting rate is caused by CSMA/CA channel access method</p></div><p class=meta>Posted on <span class=postdate>13. September 2020</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/exokernel/>Exokernel</a></h1><div class=post-content><p>Exokernel is a term every system researcher has heard of at some point in life. However, according to the PDOS group at MIT, there aren&rsquo;t any exokernel-based operating systems in active use today. It&rsquo;s interesting to discover what ideas exokernels brought to the OS high-level design and some potential drawbacks of such design choice</p></div><p class=meta>Posted on <span class=postdate>01. September 2020</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/sketch-on-the-unix-timesharing-system/>Sketch on the UNIX Timesharing System</a></h1><div class=post-content><p>Unix is general-purpose, multi-user, interactive operating system, it offers several new features hardly found in other larger operating systems back in the day. These features include (1) a hierarchical file system incorporating demountable volumes; (2) compatible file, device, and inter-process I/O; (3) the ability to initiate asynchronous processes; (4) system command language selectable on a per-user basis; and (5) over 100 subsystems including a dozen languages</p></div><p class=meta>Posted on <span class=postdate>27. August 2020</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/monads-in-haskell/>Monads in Haskell</a></h1><div class=post-content><p>I&rsquo;ve scratched my head for quite a while trying to understand the concept of monad in Haskell. This is a brief summary of monads. I take William Cook&rsquo;s Anatomy of Programming Languages as my reference</p></div><p class=meta>Posted on <span class=postdate>01. March 2020</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/singular-value-decomposition/>Singular Value Decomposition</a></h1><div class=post-content><p>Unitary matrices and the Singular Value Decomposition (SVD) are two important concepts in linear algebra. In order to fully understand these concepts, we will need to first discuss orthogonality. Most materials are converted in Advanced Linear Algebra: Foundations to Frontiers taught by professor Robert van de Geijn. This is a brief summary over the important concepts covered in Chapter 2</p></div><p class=meta>Posted on <span class=postdate>10. February 2020</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/understanding-probabilistic-clock-synchronization/>Understanding Probabilistic Clock Synchronization</a></h1><div class=post-content><p>This post is meant to discuss the probabilistic clock synchronization technique. The main goal of this technique is to bound the difference between systems by setting up an upper bound. Formally, we define the problem as \(|P(t)-Q(t)|\leq \varepsilon\), or the difference between clocks across the network. We will go over the technical detains and discuss what these symbols represent in later sections. Most of these materials are from Prof. Mok&rsquo;s slides on dependable systems classes. ‚Ä¶</p></div><p class=meta>Posted on <span class=postdate>17. September 2019</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/how-to-put-papers-on-arxiv/>How to Put Papers on ArXiv</a></h1><div class=post-content><p>I was recently trying to put my research paper draft on ArXiv. I thought it would be as simple as submitting the pdf file, which should take approximately less than ten minutes. I was wrong. It took several hours to figure what was going on. I included some tips here to prevent mistakes I made from happening again</p></div><p class=meta>Posted on <span class=postdate>25. June 2019</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/a-little-review-on-barrelfish-memory-managements/>A Little Review on Barrelfish Memory Managements</a></h1><div class=post-content><p>The memory management has been mentioned numerous times and still remains huge topic. virtual vs. physical memory, physical frame allocation, MMUs, page faults, address space layout, and demand paging and swapping are familiar terms for every undergrad in college. In monolithic kernels such as Linux, much of the functionality is handled in kernel. However, there are OSes, such as Barrelfish, that takes a different approach by pushing these functionalities to user space. ‚Ä¶</p></div><p class=meta>Posted on <span class=postdate>18. February 2019</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/pascal-gpu-memory-and-cache-hierarchy/>Pascal GPU memory and cache hierarchy</a></h1><div class=post-content><p>Memory access efÔ¨Åciency is an important factor in fully utilizing the computational power of graphics processing units (GPUs). However, many GPU vendors like NVIDIA kept the GPU memory hierarchy as a secret. Therefore it becomes hard to measure GPUs performance and sets barriers to understand memory access patterns, which is a key component to improve program&rsquo;s performance. Here we introduce a novel fine-grained microbenchmark approach and apply to the Pascal generation. Turing architecture might have different results, but the method we used here can be applied as well with slight modification. The method we use in this guide is inspired by the research paper: Dissecting GPU Memory Hierarchy through Microbenchmarking. Here we will explain how P-Chase works and walk through a small example</p></div><p class=meta>Posted on <span class=postdate>15. January 2019</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/map-reduce/>Map Reduce</a></h1><div class=post-content><p>I was always interested by the name &lsquo;&lsquo;map reduce&rsquo;&rsquo; since two years ago when I first heard this term. But I&rsquo;ve never put any effort to know the concept until Chris mentioned it in class because it will be on the next exam so I figured I&rsquo;d better figure out what is going on before it was too late. Just kidding:) But map reduce does borrows a lot of characteristics from traditional relational databases even though many useful and important features in RDBMS are eliminated from the map reduce system. You can check this long list of roasts on map reduce here</p></div><p class=meta>Posted on <span class=postdate>01. April 2018</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/networks/>Networks</a></h1><div class=post-content><p>The concept of a worldwide of networks of information was introduced long before the technology used to build the internet. The first workable prototype came in the late 1960s with the creation of ARPANET(The Advanced Research Projects Agency Network). The famous TCP/IP, or Transmission Control Protocol and Internet Protocol, was developed by Robert Kahn and Vinton Cerf in the 1970s. In the 1980s, research by Tim Berners-Lee gave birth to the World Wide Web, linking hypertext documents into an information system, making them accessible from any node on the network (History of Internet). ‚Ä¶</p></div><p class=meta>Posted on <span class=postdate>13. November 2017</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/file-system-design/>File System Design</a></h1><div class=post-content><p>What exactly is a file system? The general concept is that the file system provides naming organization. It manages the physical disk layout such as picking a block constituting a file, balancing locality with expandability, and managing free space. It can translate from file name and offset to the actual data block. In a nutshell, it is a servant that manages all the dirty details of communicating the data between system and the hardware in an optimal way which you aren&rsquo;t required to understand so you can go on and do other things with your life. So what are the functionalities of file systems? In general, it provides file name organizations such as directories. It can manage disk layout by picking blocks that constitute a file, balancing locality with expandability, and manage free space. It can translate from file name and offset to the actual data block</p></div><p class=meta>Posted on <span class=postdate>30. October 2017</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/disk-introduction/>Disk Introduction</a></h1><div class=post-content><p>This chapter is all about disk. Before we start. We won&rsquo;t go deep into the mechanical part of disk operation; rather we will be focusing on general concept related to disk and algorithms to improve disk performance</p></div><p class=meta>Posted on <span class=postdate>25. October 2017</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/virtual-memory-mechanisms/>Virtual Memory Mechanisms</a></h1><div class=post-content><p>As we can see in the previous post, all allocation algorithms we discussed lead to external fragmentation. As time goes by, external fragmentation is going to get worse and we need solutions for the problem. We can use swap areas to swap out memory onto the disk, or move allocated memory together(a process named memory compaction), leaving empty spaces together. Even these approaches can reduce external fragmentation and allow a higher degree of multiprogramming, they are not perfect. ‚Ä¶</p></div><p class=meta>Posted on <span class=postdate>19. October 2017</span></p></article><article class=post><h1><a href=https://www.bodunhu.com/blog/posts/virtual-memory-overview/>Virtual Memory Overview</a></h1><div class=post-content><p>I love pointers. Pointer is very a useful feature in programming languages like C/C++. I can pass weird hexadecimal numbers to a function and then it will magically locate where the program is in memory. However, all those values we see are merely virtual addresses, a running program&rsquo;s view of memory in system. Any address we can see while programming user-level programs is a virtual address. It is no more than an illusion of where the data is actually laid out in memory. ‚Ä¶</p></div><p class=meta>Posted on <span class=postdate>08. October 2017</span></p></article></div><footer id=footer><p class=copyright>Powered by <a href=https://gohugo.io/>Hugo</a> and the
<a href=https://github.com/bake/solar-theme-hugo>Solar</a>-theme.</p></footer></div></body></html>