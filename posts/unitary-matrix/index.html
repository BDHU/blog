<!doctype html><html><head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta name=description content="std::bodun::blog. Personal Blog of Bodun (Edward) Hu. CS PhD student at University of Texas at Austin. Operating systems, network, heterogeneity, MLSys, anything system. UTCS">
<link rel="shortcut icon" href=https://www.bodunhu.com/blog/favicon.ico>
<link rel=stylesheet href=/blog/css/style.min.css>
<script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']]},svg:{fontCache:'global'}}</script>
<script type=text/javascript id=MathJax-script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js async></script>
<script src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script>
<script>let isDark=window.matchMedia('(prefers-color-scheme: dark)').matches,mermaidTheme=isDark?'dark':'default',mermaidConfig={startOnLoad:!0,securityLevel:'strict',flowchart:{useMaxWidth:!0,htmlLabels:!0},theme:mermaidTheme};mermaid.initialize(mermaidConfig)</script>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(a,e,f,g,b,c,d){a.GoogleAnalyticsObject=b,a[b]=a[b]||function(){(a[b].q=a[b].q||[]).push(arguments)},a[b].l=1*new Date,c=e.createElement(f),d=e.getElementsByTagName(f)[0],c.async=1,c.src=g,d.parentNode.insertBefore(c,d)}(window,document,'script','https://www.google-analytics.com/analytics.js','ga'),ga('create','UA-108144808-1','auto'),ga('send','pageview'))</script>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga('create','UA-108144808-1','auto'),ga('send','pageview'))</script>
<script async src=https://www.google-analytics.com/analytics.js></script>
<link href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css rel=stylesheet>
<title>Unitary Matrix</title>
</head>
<body>
<header id=return>
<h2></h2><a href=https://www.bodunhu.com/blog/><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" style="vertical-align:-.125em" width="1em" height="1em" viewBox="0 0 16 16"><path fill="currentcolor" fill-rule="evenodd" d="M15 2a1 1 0 00-1-1H2A1 1 0 001 2v12a1 1 0 001 1h12a1 1 0 001-1V2zM0 2a2 2 0 012-2h12a2 2 0 012 2v12a2 2 0 01-2 2H2a2 2 0 01-2-2V2zm11.5 5.5a.5.5.0 010 1H5.707l2.147 2.146a.5.5.0 01-.708.708l-3-3a.5.5.0 010-.708l3-3a.5.5.0 11.708.708L5.707 7.5H11.5z"/></svg>
</a>
</header>
<main id=content>
<article>
<header id=post-header>
<h1>Unitary Matrix</h1>
<div>
<time>Jul 14, 2021</time>
</div>
</header><p>Recently, I was trying to get the hang of quantum computing. I found myself in a position where I forgot most of the linear algebra stuff I&rsquo;ve learned in past semesters. So again, I decide to put them down in hope that some of the knowledge here will stay in my memory a bit longer.</p>
<h2 id=general-single-qubit-gates>General single-qubit Gates</h2>
<p>Trying to understand unitary matrix in the context of pure linear algebra is, I must admit, rather boring. Perhaps that is one reason why I brushed them off so quickly and so easily. However, explaining it in the context of quantum computing feels a lot more fun. Maybe it&rsquo;s because I can associate a unitary matrix with a quantum gate, which is something a bit more concrete, or simply because the term &lsquo;&lsquo;quantum computing&rsquo;&rsquo; makes me sound smarter.</p>
<p>Speaking of something concrete, here ara two example unitary matrices: the NOT gate (\(X\)) and <a href=https://en.wikipedia.org/wiki/Quantum_logic_gate>Hadamard gate</a> (\(H\)):</p>
<p>\[
X =\begin{bmatrix}
0 & 1 \\ 1 & 0
\end{bmatrix}
;\
H = \frac{1}{\sqrt{2}} \begin{bmatrix}
1 & 1 \\ 1 & -1
\end{bmatrix}
\]</p>
<p>For example, if we take the Hadamard gate (\(H\)) and compute its adjoint \(H^{\dagger}\):</p>
<p>\[
H^{\dagger} = \begin{pmatrix} \begin{pmatrix}\frac{1}{\sqrt{2}} \begin{bmatrix}
1 & 1 \\ 1 & -1
\end{bmatrix} \end{pmatrix}^T \end{pmatrix}^{*}
\]</p>
<p>We know the transpose of \(H\) is still \(H\), and taking the complex conjugate of \(H^T\) doesn&rsquo;t do anything since \(H^T\) is a real matrix. Thus, we can verify that \(H^{\dagger}H = I\).</p>
<p>There are other single-qubit quantum gates such as the <a href=https://en.wikipedia.org/wiki/Pauli_matrices>\(Y\) and \(Z\) matrices</a> (Pauli matrices) introduced by physicist <a href=https://en.wikipedia.org/wiki/Wolfgang_Pauli>Wolfgang Pauli</a>. It&rsquo;s a good exercise to verify they are also unitary matrices.</p>
<h2 id=what-does-it-mean-for-a-matrix-to-be-unitary>What does it mean for a matrix to be unitary</h2>
<p>The most important property of unitary matrices is that they <em>preserve the length of inputs</em>. It means that given a quantum state, represented as vector \(|\psi\rangle\), it must be that \( \left\lVert U|\psi\rangle \rangle \right\rVert = \left\lVert |\psi\rangle \right\rVert \).</p>
<p>Proving unitary matrix is length-preserving is straightforward. We wanna show that \( \left\lVert U |\psi\rangle \right\rVert_2 = \left\lVert |\psi\rangle \right\rVert_2 \):</p>
<p>\[\begin{aligned} \left\lVert U |\psi\rangle \right\rVert_2^2 &= (U |\psi\rangle)^H(U |\psi\rangle) \\ &= |\psi\rangle^H U^H U |\psi\rangle \\ &=|\psi\rangle^H |\psi\rangle \\ &= \left\lVert |\psi\rangle \right\rVert_2^2 \end{aligned}\]</p>
<h2 id=why-are-unitaries-the-only-matrices-that-preserve-length>Why are unitaries the only matrices that preserve length</h2>
<p>Previously, we use the <em>ket</em> notation for quantum state vectors. We can extend the two-dimensional quantum state vectors to more general vectors and the properties of unitary matrix will still hold.</p>
<p>Putting our questions in formal terms, we want to show that if \(A \in \mathbb{C}^{m \times m}\) preserves length (\(\left\lVert A x \right\rVert_2 = \left\lVert x \right\rVert_{2}\ \forall x \in \mathbb{C}^m\), then \(A\) is unitary).</p>
<p>We first prove that \((Ax)^H(Ay) = x^Hy\) for all \(x\), \(y\) by considering that \( \left\lVert x - y \right\rVert_2^2 = \left\lVert A(x - y) \right\rVert_2^2 \). Then we will the result to evaluate \(e_i^H A^HAe_j\).</p>
<p>Let \(x\), \(y \in \mathbb{C}^m\), then we can use the alternative definition for the matrix 2-norm (e.g. \(\left\lVert y \right\rVert_2 = y^Hy\)) for \( \left\lVert x - y \right\rVert_2^2 = \left\lVert A(x - y) \right\rVert_2^2 \),</p>
<p>\[
(x-y)^H(x-y) = (A(x-y))^HA(x-y)
\]</p>
<p>Based on that fact that the hermitian transpose rule that \((Ax)^H = x^HA^H\), we get</p>
<p>\[
(x-y)^H(x-y) = (x-y)^HA^HA(x-y)
\]</p>
<p>Multiplying the above formula out,</p>
<p>\[
x^Hx - y^Hx - x^Hy + y^Hy = x^HA^HAx - y^HA^HAx - x^HA^HAy + y^HA^HAy
\]</p>
<p>The alternative definition for \(y^Hx\) is \(\overline{x^Hy}\), so we apply the definition here,</p>
<p>\[
x^Hx - (\overline{x^Hy} + x^Hy) + y^Hy = x^HA^HAx - (\overline{x^HA^HAy} + x^HA^HAy) + y^HA^HAy
\]</p>
<p>We know that \(A\) preserves length, and that \(\frac{\alpha + \overline{\alpha}}{2} = Re(\alpha)\). so we can simplify the above formula as:</p>
<p>\[
Re(x^Hy) = Re((Ax)^H(Ay))
\]</p>
<p>We know that \(A\) preserves length, and thus we need to show that \(A^HA = I\) by using the fact that the standard basis vectors have the property that</p>
<p>\[
\begin{equation}
e_i^H e_j = \begin{cases} 1 & \text{if \(i = j\)}\\ 0 & \text{otherwise} \end{cases}
\end{equation}
\]</p>
<p>Therefore, \(e_i M e_j\) will essentially extract the \(i,\ j\)th entry in matrix \(M\). So we know that</p>
<p>\[
e_i A^HA e_i = \left\lVert Ae_i \right\rVert^2 = \left\lVert e_i \right\rVert^2 = 1
\]</p>
<p>We can conclude that all the diagonal elements of \(A^HA\) are \(1\).</p>
<p>A side question remains, how do we prove that all the off-diagonal elements in \(A^HA\) are \(0\)? Turns out it very straightforward to illustrate the process if we resort back to the two-dimensional quantum vector state matrix.</p>
<p>Suppose we have \(|\psi\rangle = |e_i\rangle + |e_j\rangle\), we already know that \(\left\lVert A |\psi\rangle \right\rVert^2 = \left\lVert |\psi\rangle \right\rVert^2 = 1 + 1 = 2\), and we know we can expand \(\left\lVert A |\psi\rangle \right\rVert^2\) to \(1 + e_i A^HA e_j + e_j A^HA e_i + 1\), we would get \(e_i A^HA e_j + e_j A^HA e_i = 0\).</p>
<p>Then, suppose instead we have \(|\psi\rangle = |e_i\rangle + i|e_j\rangle\), following the same process, we would get \(e_i A^HA e_j - e_j A^HA e_i = 0\). Combining with the fact that \(e_i A^HA e_j + e_j A^HA e_i = 0\), we&rsquo;ve proven that the off-diagonal elements in \(A^HA\) are all \(0\). We can extend the vector \(\psi\) to higher-dimensional vectors and the proof will be similar.</p>
<div style=width:100% id=comment>
<script src=https://utteranc.es/client.js repo=BDHU/blog issue-term=pathname theme=preferred-color-scheme crossorigin=anonymous async></script>
</div>
</article>
</main><footer id=footer>
<p>Â© 2022 Bodun Hu. All rights reserved.</p>
</footer>
</body>
</html>