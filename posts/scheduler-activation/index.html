<!doctype html><html><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="PhD student at University of Texas at Austin ðŸ¤˜. Doing systems for ML."><link rel="shortcut icon" href=https://www.bodunhu.com/blog/favicon.ico><link rel=stylesheet href=/blog/css/style.min.css><script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']]},svg:{fontCache:'global'}}</script><script type=text/javascript id=MathJax-script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js async></script><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)}(window,document,'script','https://www.google-analytics.com/analytics.js','ga'),ga('create','UA-108144808-1','auto'),ga('send','pageview'))</script><script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga('create','UA-108144808-1','auto'),ga('send','pageview'))</script><script async src=https://www.google-analytics.com/analytics.js></script><title>Scheduler Activation</title></head><body><header id=banner><h2><a href=https://www.bodunhu.com/blog/>std::bodun::blog</a></h2><nav><ul><li><a href=/blog/posts/ title=posts>Archive</a></li><li><a href=https://www.bodunhu.com/ title=about>About</a></li></ul></nav></header><main id=content><article><header id=post-header><h1>Scheduler Activation</h1><div><time>Oct 24, 2020</time></div></header><p>This is a summary on scheduler activation. To discuss about scheduler activation, we must first understand what is a thread. A thread of execution is the smallest sequence of programmed instructions that can be managed independently by a scheduler.</p><h2 id=kernel-level-threads-proscons>Kernel Level Threads Pros/Cons</h2><ul><li>Good functionality, system wide integration</li><li>Threads are seen and scheduled only by the kernel. A lot of kernel information should be invisible to user thread and can be useful for scheduling</li><li>Poor performance, every thread_related call traps. This situation is a lot worse in the 1990s than it is now mainly due to clock speed.
The scheduling quanta are roughly the same, but because the clock speeds are much faster today, you can execute orders of magnitude more instructions
per quanta today than you could in 1990. Even if traps, let&rsquo;s say, costs 10 cycles to complete, it would be a much bigger fraction of the quanta in 1990 than
it is today.</li></ul><h2 id=user-level-threads-proscons>User Level Threads Pros/Cons</h2><ul><li>Good performances. (most threads operations don&rsquo;t involve kernel)</li><li>Good scheduling policy flexibility: done by thread lib</li><li>Poor system-wide integration</li><li>Multi-programmed workloads are hard to schedule</li><li>I/O, page faults invisible</li><li>Potential for incorrect behavior<ul><li>User level scheduler may not be cooperative. With user threads running on kernel threads, it may be that kernel threads block when a user-thread blocks, thus an application can run out of kernel threads to run their user threads.May be gilding the lily.</li></ul></li></ul><h2 id=some-problems-about-user-level-threads-on-kernel-interface>Some Problems about User-Level Threads on Kernel Interface</h2><ul><li>Insufficient visibility between the kernel and user thread lib</li><li>Kernel event such as pr-emption or I/O are not visible to user lib<ul><li>For example, if user level threads block, then the kernel thread serving it also blocks.</li></ul></li><li>Kernel threads are scheduled with respect to user-level thread library, we can have this interferences between two schedulers.</li><li>Kernel time-slicing of threads<ul><li>For example, user level threads holding a spin-lock can be pre-emptied, which can potentially cause all other user threads to wait.</li></ul></li></ul><h2 id=scheduler-activation>Scheduler Activation</h2><p>The basic principle about scheduler activation is to expose revocation: telling me when you take something away. This is basically the same idea as the exokernel. For example, interfaces like</p><ul><li>add_processor()</li><li>has_blocked()</li></ul><p>The basics about scheduler activation are</p><ul><li>Multi-threaded programs are still given an address space</li><li>Facilitate flow of kernel information between user and kernel threads</li><li>Kernel explicitly vectors kernel events to the user-level thread<ul><li>via scheduler activation (upcall)</li></ul></li><li>Extended kernel interface for processor allocation-related events<ul><li>Essentially exchanging information</li></ul></li></ul><h2 id=scheduler-activation-vs-kernel-threads>Scheduler Activation vs Kernel Threads</h2><p>Key differences:</p><ul><li>Pre-emptied threads never resumed by the kernel directly.<ul><li>Essentially, every new SA is a brand new context.</li><li>For example, if you do blocking I/O, the kernel will provide a new scheduling activation and vector into that application space. There isn&rsquo;t a notion of &ldquo;resume&rdquo;. The kernel is simply going to find some new schedule activation to notify you that a work has unblocked. In modern kernels, you would do something like stack unwinding to get back into user space.</li></ul></li></ul><p>An important problem is what happened if a user thread is forced to be de-scheduler while it&rsquo;s in a scheduler. The user thread will hold a a lock on user level run queue. That means no other user thread can be scheduled to run because none of them can acquire the lock. Because there&rsquo;s no notion of &ldquo;resume&rdquo; in scheduling activation, we can&rsquo;t really resume the execution in the scheduler. Thus, we run into a deadlock situation.</p><p>One solution is to detect whether we are using a lock and keep executing until we leave the locked region. Of course, there are too many gotchas in this solution.</p><p>Another solution is that the kernel can make a copy of the critical section and execute the critical section itself regardless of what the user thread chooses to do. Therefore, we can guarantee by the time you vector back into user space the lock is no longer held. So the kernel is basically executing the user code! Crazy, right?
Now we ran into more gotchas. What if the code is written in Java? How to find a locked region in userspace? What if &mldr;</p><p>Another thing we want to mention is page fault. Page fault indicates that you are missing part of your address. So there will be a notification with a new scheduler activation. Once you do something with it, you will likely touch that same piece in the space and double fault again.</p><p>What is the solution?</p><div style=width:100% id=comment><script src=https://utteranc.es/client.js repo=BDHU/blog issue-term=pathname theme=preferred-color-scheme crossorigin=anonymous async></script></div></article></main><footer id=footer><p>Â© 2022 Bodun Hu. All rights reserved.</p></footer></body></html>