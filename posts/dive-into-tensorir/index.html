<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="PhD student at University of Texas at Austin ðŸ¤˜. Doing systems for ML."><link rel="shortcut icon" href=https://www.bodunhu.com/blog/favicon.ico><link rel=stylesheet href=/blog/css/style.min.css><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},svg:{fontCache:"global"}}</script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-ZLK2GHB055"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-ZLK2GHB055")}</script><link rel=canonical href=https://www.bodunhu.com/blog/posts/dive-into-tensorir/><title>std::bodun::blog</title></head><body><header id=banner><span><a href=https://www.bodunhu.com/blog/>blog</a> | <a href=https://www.bodunhu.com/blog//posts>posts</a> | <a href=https://www.bodunhu.com/>about</a></span></header><main id=content><article><header id=post-header><h2>Dive into TensorIR</h2><div><time>August 29, 2022</time></div></header><p><a href=https://arxiv.org/abs/2207.04296>TensorIR</a> is a compiler abstraction for optimizing programs with tensor computation primitives in <a href=https://tvm.apache.org/>TVM</a>. Imagine a DNN task as a graph, where each node represents a tensor computation. TensorIR explains how each node/tensor computation primitive in the graph is carried out. This post explains my attempt to implement 2D convolution using TensorIR. It is derived from the <a href=https://mlc.ai/summer22/>Machine Learning Compilation</a> course offered by <a href=https://tqchen.com/>Tianqi Chen</a>.</p><h2 id=implement-2d-convolution>Implement 2D Convolution</h2><p>2D convolution is a common operation in image processing. The image below captures how 2D convolution operates. I won&rsquo;t go into details here. But you can find plenty information online regarding convolution.</p><p><img src=https://cdn.jsdelivr.net/gh/BDHU/Page_Pics/posts/dive-into-tensorIR/2d-conv.png alt=2D-convolution></p><p>First, we initialize both the input matrix and the weight matrix:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># batch, input_channel_dim, image_height, image_width, output_channel_dim, kernel_width &amp; height</span>
</span></span><span class=line><span class=cl><span class=n>N</span><span class=p>,</span> <span class=n>CI</span><span class=p>,</span> <span class=n>H</span><span class=p>,</span> <span class=n>W</span><span class=p>,</span> <span class=n>CO</span><span class=p>,</span> <span class=n>K</span> <span class=o>=</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>8</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span>
</span></span><span class=line><span class=cl><span class=c1># output_height, output_width, assuming kernel has stride=1 and padding=0</span>
</span></span><span class=line><span class=cl><span class=n>OUT_H</span><span class=p>,</span> <span class=n>OUT_W</span> <span class=o>=</span> <span class=n>H</span> <span class=o>-</span> <span class=n>K</span> <span class=o>+</span> <span class=mi>1</span><span class=p>,</span> <span class=n>W</span> <span class=o>-</span> <span class=n>K</span> <span class=o>+</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl><span class=n>data</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>N</span><span class=o>*</span><span class=n>CI</span><span class=o>*</span><span class=n>H</span><span class=o>*</span><span class=n>W</span><span class=p>)</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>N</span><span class=p>,</span> <span class=n>CI</span><span class=p>,</span> <span class=n>H</span><span class=p>,</span> <span class=n>W</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>weight</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>CO</span><span class=o>*</span><span class=n>CI</span><span class=o>*</span><span class=n>K</span><span class=o>*</span><span class=n>K</span><span class=p>)</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>CO</span><span class=p>,</span> <span class=n>CI</span><span class=p>,</span> <span class=n>K</span><span class=p>,</span> <span class=n>K</span><span class=p>)</span>
</span></span></code></pre></div><p>We can validate the results using <code>torch.nn.functional.conv2d()</code> from PyTorch.</p><p>One thing Tianqi recommended for starters is to write the implementation first in numpy, and then translate the numpy implementation to TensorIR. I started my implementation directly from TensorIR, before totally getting confused. So here&rsquo;s how I approach the problem.</p><p>First, and perhaps most importantly, you should figure out the accessing pattern of the output matrix, and gradually fill up the compute rules for each element in the output matrix. So, we know the output matrix has a shape of <code>(N, CO, OUT_H, OUT_w)</code> (which corresponds to batch, number of output channels, output height, and output width). The numpy loop will look like:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>for</span> <span class=n>b</span> <span class=ow>in</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>N</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>co</span> <span class=ow>in</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>CO</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>h</span> <span class=ow>in</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>OUT_H</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>w</span> <span class=ow>in</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>OUT_W</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=n>Y</span><span class=p>[</span><span class=n>b</span><span class=p>,</span> <span class=n>co</span><span class=p>,</span> <span class=n>h</span><span class=p>,</span> <span class=n>w</span><span class=p>]</span> <span class=o>=</span> <span class=mi>0</span>
</span></span></code></pre></div><p>Here, we access element in the output matrix one by one and initialize each element to be 0. Next, we will try to figure out how to compute each element. We know each element in the output matrix is just the sum of element-wise multiplication of both the 2D convolutional kernel (1 by 3 by 3) and the corresponding area in the input matrix (1 by 3 by 3):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>for</span> <span class=n>b</span> <span class=ow>in</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>N</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>co</span> <span class=ow>in</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>CO</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>h</span> <span class=ow>in</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>OUT_H</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>w</span> <span class=ow>in</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>OUT_W</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=c1># init to 0</span>
</span></span><span class=line><span class=cl>                <span class=n>Y</span><span class=p>[</span><span class=n>b</span><span class=p>,</span> <span class=n>co</span><span class=p>,</span> <span class=n>h</span><span class=p>,</span> <span class=n>w</span><span class=p>]</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>                <span class=c1># 2d conv kernel</span>
</span></span><span class=line><span class=cl>                <span class=k>for</span> <span class=n>ci</span> <span class=ow>in</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>CI</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                    <span class=k>for</span> <span class=n>kh</span> <span class=ow>in</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>K</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                        <span class=k>for</span> <span class=n>kw</span> <span class=ow>in</span> <span class=n>np</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>K</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                            <span class=c1># reduction</span>
</span></span><span class=line><span class=cl>                            <span class=n>Y</span><span class=p>[</span><span class=n>b</span><span class=p>,</span> <span class=n>co</span><span class=p>,</span> <span class=n>h</span><span class=p>,</span> <span class=n>w</span><span class=p>]</span> <span class=o>+=</span> <span class=n>A</span><span class=p>[</span><span class=n>b</span><span class=p>,</span> <span class=n>ci</span><span class=p>,</span> <span class=n>h</span><span class=o>+</span><span class=n>kh</span><span class=p>,</span> <span class=n>w</span><span class=o>+</span><span class=n>kw</span><span class=p>]</span> <span class=o>*</span> <span class=n>W</span><span class=p>[</span><span class=n>co</span><span class=p>,</span> <span class=n>ci</span><span class=p>,</span> <span class=n>kh</span><span class=p>,</span> <span class=n>kw</span><span class=p>]</span>
</span></span></code></pre></div><p>We can verify the function has the same output as <code>torch.nn.functional.conv2d()</code> from PyTorch.</p><p>The next part is to translate the numpy code into TensorIR. I won&rsquo;t go into every the details of every single line here, but you can find all explanations from this <a href=https://mlc.ai/chapter_tensor_program/case_study.html>note</a>.</p><p>The nested loop can be encapsulated using <code>T.grid()</code> like this:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@tvm.script.ir_module</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>MyConv</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=nd>@T.prim_func</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>conv2d</span><span class=p>(</span><span class=n>data</span><span class=p>:</span> <span class=n>T</span><span class=o>.</span><span class=n>Buffer</span><span class=p>[(</span><span class=n>N</span><span class=p>,</span> <span class=n>CI</span><span class=p>,</span> <span class=n>H</span><span class=p>,</span> <span class=n>W</span><span class=p>),</span> <span class=s2>&#34;int64&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                <span class=n>weight</span><span class=p>:</span> <span class=n>T</span><span class=o>.</span><span class=n>Buffer</span><span class=p>[(</span><span class=n>CO</span><span class=p>,</span> <span class=n>CI</span><span class=p>,</span> <span class=n>K</span><span class=p>,</span> <span class=n>K</span><span class=p>),</span> <span class=s2>&#34;int64&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                <span class=n>result</span><span class=p>:</span> <span class=n>T</span><span class=o>.</span><span class=n>Buffer</span><span class=p>[(</span><span class=n>N</span><span class=p>,</span> <span class=n>CO</span><span class=p>,</span> <span class=n>OUT_H</span><span class=p>,</span> <span class=n>OUT_W</span><span class=p>),</span> <span class=s2>&#34;int64&#34;</span><span class=p>]):</span>
</span></span><span class=line><span class=cl>        <span class=n>T</span><span class=o>.</span><span class=n>func_attr</span><span class=p>({</span><span class=s2>&#34;global_symbol&#34;</span><span class=p>:</span> <span class=s2>&#34;conv2d&#34;</span><span class=p>,</span> <span class=s2>&#34;tir.noalias&#34;</span><span class=p>:</span> <span class=kc>True</span><span class=p>})</span>
</span></span><span class=line><span class=cl>        <span class=c1># loop through each elem in the output matrix</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>b</span><span class=p>,</span> <span class=n>o</span><span class=p>,</span> <span class=n>h</span><span class=p>,</span> <span class=n>w</span> <span class=ow>in</span> <span class=n>T</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=n>N</span><span class=p>,</span> <span class=n>CO</span><span class=p>,</span> <span class=n>OUT_H</span><span class=p>,</span> <span class=n>OUT_W</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=c1># kernel access pattern</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>kc</span><span class=p>,</span> <span class=n>kh</span><span class=p>,</span> <span class=n>kw</span> <span class=ow>in</span> <span class=n>T</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=n>CI</span><span class=p>,</span> <span class=n>K</span><span class=p>,</span> <span class=n>K</span><span class=p>):</span>
</span></span></code></pre></div><p>Next, we define the block (a basic unit of computation in TensorIR). A block contains a set of block axes <code>(vi, vj, vk)</code> and computations defined around them. Here, we define the property about each block axes:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>MyConv</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=nd>@T.prim_func</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>conv2d</span><span class=p>(</span><span class=n>data</span><span class=p>:</span> <span class=n>T</span><span class=o>.</span><span class=n>Buffer</span><span class=p>[(</span><span class=n>N</span><span class=p>,</span> <span class=n>CI</span><span class=p>,</span> <span class=n>H</span><span class=p>,</span> <span class=n>W</span><span class=p>),</span> <span class=s2>&#34;int64&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                <span class=n>weight</span><span class=p>:</span> <span class=n>T</span><span class=o>.</span><span class=n>Buffer</span><span class=p>[(</span><span class=n>CO</span><span class=p>,</span> <span class=n>CI</span><span class=p>,</span> <span class=n>K</span><span class=p>,</span> <span class=n>K</span><span class=p>),</span> <span class=s2>&#34;int64&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                <span class=n>result</span><span class=p>:</span> <span class=n>T</span><span class=o>.</span><span class=n>Buffer</span><span class=p>[(</span><span class=n>N</span><span class=p>,</span> <span class=n>CO</span><span class=p>,</span> <span class=n>OUT_H</span><span class=p>,</span> <span class=n>OUT_W</span><span class=p>),</span> <span class=s2>&#34;int64&#34;</span><span class=p>]):</span>
</span></span><span class=line><span class=cl>        <span class=n>T</span><span class=o>.</span><span class=n>func_attr</span><span class=p>({</span><span class=s2>&#34;global_symbol&#34;</span><span class=p>:</span> <span class=s2>&#34;conv2d&#34;</span><span class=p>,</span> <span class=s2>&#34;tir.noalias&#34;</span><span class=p>:</span> <span class=kc>True</span><span class=p>})</span>
</span></span><span class=line><span class=cl>        <span class=c1># impl</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>b</span><span class=p>,</span> <span class=n>o</span><span class=p>,</span> <span class=n>h</span><span class=p>,</span> <span class=n>w</span> <span class=ow>in</span> <span class=n>T</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=n>N</span><span class=p>,</span> <span class=n>CO</span><span class=p>,</span> <span class=n>OUT_H</span><span class=p>,</span> <span class=n>OUT_W</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>kc</span><span class=p>,</span> <span class=n>kh</span><span class=p>,</span> <span class=n>kw</span> <span class=ow>in</span> <span class=n>T</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=n>CI</span><span class=p>,</span> <span class=n>K</span><span class=p>,</span> <span class=n>K</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=k>with</span> <span class=n>T</span><span class=o>.</span><span class=n>block</span><span class=p>(</span><span class=s2>&#34;A&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                    <span class=n>vb</span> <span class=o>=</span> <span class=n>T</span><span class=o>.</span><span class=n>axis</span><span class=o>.</span><span class=n>spatial</span><span class=p>(</span><span class=n>N</span><span class=p>,</span> <span class=n>b</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>vc_o</span> <span class=o>=</span> <span class=n>T</span><span class=o>.</span><span class=n>axis</span><span class=o>.</span><span class=n>spatial</span><span class=p>(</span><span class=n>CO</span><span class=p>,</span> <span class=n>o</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>vh</span> <span class=o>=</span> <span class=n>T</span><span class=o>.</span><span class=n>axis</span><span class=o>.</span><span class=n>spatial</span><span class=p>(</span><span class=n>OUT_H</span><span class=p>,</span> <span class=n>h</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>vw</span> <span class=o>=</span> <span class=n>T</span><span class=o>.</span><span class=n>axis</span><span class=o>.</span><span class=n>spatial</span><span class=p>(</span><span class=n>OUT_W</span><span class=p>,</span> <span class=n>w</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>vc_i</span> <span class=o>=</span> <span class=n>T</span><span class=o>.</span><span class=n>axis</span><span class=o>.</span><span class=n>reduce</span><span class=p>(</span><span class=n>CI</span><span class=p>,</span> <span class=n>kc</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>vw_h</span> <span class=o>=</span> <span class=n>T</span><span class=o>.</span><span class=n>axis</span><span class=o>.</span><span class=n>reduce</span><span class=p>(</span><span class=n>K</span><span class=p>,</span> <span class=n>kh</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>vw_w</span> <span class=o>=</span> <span class=n>T</span><span class=o>.</span><span class=n>axis</span><span class=o>.</span><span class=n>reduce</span><span class=p>(</span><span class=n>K</span><span class=p>,</span> <span class=n>kw</span><span class=p>)</span>
</span></span></code></pre></div><p>The outer loop all receives <code>T.axis.spatial()</code>, because we access each element in the output matrix element by element (spatially), without doing anything else. On the other hand, we see parameters in the innter loop receives <code>T.axis.reduce()</code>. Remember, each element in the output matrix is just the sum of element-wise multiplication of both the 2D convolutional kernel (1 by 3 by 3) and the corresponding area in the input matrix (1 by 3 by 3). Therefore, after the element-wise multiplication finishes, we need perform a reduction operation over all three axes. More concretely, we will sum up all elements in the row(K), column(K), and channel(CI): (1, 3, 3) -> (1)</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@tvm.script.ir_module</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>MyConv</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=nd>@T.prim_func</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>conv2d</span><span class=p>(</span><span class=n>data</span><span class=p>:</span> <span class=n>T</span><span class=o>.</span><span class=n>Buffer</span><span class=p>[(</span><span class=n>N</span><span class=p>,</span> <span class=n>CI</span><span class=p>,</span> <span class=n>H</span><span class=p>,</span> <span class=n>W</span><span class=p>),</span> <span class=s2>&#34;int64&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                <span class=n>weight</span><span class=p>:</span> <span class=n>T</span><span class=o>.</span><span class=n>Buffer</span><span class=p>[(</span><span class=n>CO</span><span class=p>,</span> <span class=n>CI</span><span class=p>,</span> <span class=n>K</span><span class=p>,</span> <span class=n>K</span><span class=p>),</span> <span class=s2>&#34;int64&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                <span class=n>result</span><span class=p>:</span> <span class=n>T</span><span class=o>.</span><span class=n>Buffer</span><span class=p>[(</span><span class=n>N</span><span class=p>,</span> <span class=n>CO</span><span class=p>,</span> <span class=n>OUT_H</span><span class=p>,</span> <span class=n>OUT_W</span><span class=p>),</span> <span class=s2>&#34;int64&#34;</span><span class=p>]):</span>
</span></span><span class=line><span class=cl>        <span class=n>T</span><span class=o>.</span><span class=n>func_attr</span><span class=p>({</span><span class=s2>&#34;global_symbol&#34;</span><span class=p>:</span> <span class=s2>&#34;conv2d&#34;</span><span class=p>,</span> <span class=s2>&#34;tir.noalias&#34;</span><span class=p>:</span> <span class=kc>True</span><span class=p>})</span>
</span></span><span class=line><span class=cl>        <span class=c1># impl</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>b</span><span class=p>,</span> <span class=n>o</span><span class=p>,</span> <span class=n>h</span><span class=p>,</span> <span class=n>w</span> <span class=ow>in</span> <span class=n>T</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=n>N</span><span class=p>,</span> <span class=n>CO</span><span class=p>,</span> <span class=n>OUT_H</span><span class=p>,</span> <span class=n>OUT_W</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>kc</span><span class=p>,</span> <span class=n>kh</span><span class=p>,</span> <span class=n>kw</span> <span class=ow>in</span> <span class=n>T</span><span class=o>.</span><span class=n>grid</span><span class=p>(</span><span class=n>CI</span><span class=p>,</span> <span class=n>K</span><span class=p>,</span> <span class=n>K</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=k>with</span> <span class=n>T</span><span class=o>.</span><span class=n>block</span><span class=p>(</span><span class=s2>&#34;A&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                    <span class=n>vb</span> <span class=o>=</span> <span class=n>T</span><span class=o>.</span><span class=n>axis</span><span class=o>.</span><span class=n>spatial</span><span class=p>(</span><span class=n>N</span><span class=p>,</span> <span class=n>b</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>vc_o</span> <span class=o>=</span> <span class=n>T</span><span class=o>.</span><span class=n>axis</span><span class=o>.</span><span class=n>spatial</span><span class=p>(</span><span class=n>CO</span><span class=p>,</span> <span class=n>o</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>vh</span> <span class=o>=</span> <span class=n>T</span><span class=o>.</span><span class=n>axis</span><span class=o>.</span><span class=n>spatial</span><span class=p>(</span><span class=n>OUT_H</span><span class=p>,</span> <span class=n>h</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>vw</span> <span class=o>=</span> <span class=n>T</span><span class=o>.</span><span class=n>axis</span><span class=o>.</span><span class=n>spatial</span><span class=p>(</span><span class=n>OUT_W</span><span class=p>,</span> <span class=n>w</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>vc_i</span> <span class=o>=</span> <span class=n>T</span><span class=o>.</span><span class=n>axis</span><span class=o>.</span><span class=n>reduce</span><span class=p>(</span><span class=n>CI</span><span class=p>,</span> <span class=n>kc</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>vw_h</span> <span class=o>=</span> <span class=n>T</span><span class=o>.</span><span class=n>axis</span><span class=o>.</span><span class=n>reduce</span><span class=p>(</span><span class=n>K</span><span class=p>,</span> <span class=n>kh</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>vw_w</span> <span class=o>=</span> <span class=n>T</span><span class=o>.</span><span class=n>axis</span><span class=o>.</span><span class=n>reduce</span><span class=p>(</span><span class=n>K</span><span class=p>,</span> <span class=n>kw</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                    <span class=k>with</span> <span class=n>T</span><span class=o>.</span><span class=n>init</span><span class=p>():</span>
</span></span><span class=line><span class=cl>                        <span class=n>result</span><span class=p>[</span><span class=n>vb</span><span class=p>,</span> <span class=n>vc_o</span><span class=p>,</span> <span class=n>vh</span><span class=p>,</span> <span class=n>vw</span><span class=p>]</span> <span class=o>=</span> <span class=n>T</span><span class=o>.</span><span class=n>int64</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=c1># compute rule</span>
</span></span><span class=line><span class=cl>                    <span class=n>result</span><span class=p>[</span><span class=n>vb</span><span class=p>,</span> <span class=n>vc_o</span><span class=p>,</span> <span class=n>vh</span><span class=p>,</span> <span class=n>vw</span><span class=p>]</span> <span class=o>+=</span> <span class=n>data</span><span class=p>[</span><span class=n>vb</span><span class=p>,</span> <span class=n>vc_i</span><span class=p>,</span> <span class=n>vh</span><span class=o>+</span><span class=n>vw_h</span><span class=p>,</span> <span class=n>vw</span><span class=o>+</span><span class=n>vw_w</span><span class=p>]</span> <span class=o>*</span> <span class=n>weight</span><span class=p>[</span><span class=n>vc_o</span><span class=p>,</span> <span class=n>vc_i</span><span class=p>,</span> <span class=n>vw_h</span><span class=p>,</span> <span class=n>vw_w</span><span class=p>]</span>
</span></span></code></pre></div><script src=https://giscus.app/client.js data-repo=BDHU/blog-comments data-repo-id=R_kgDOKZLDLA data-category=Announcements data-category-id=DIC_kwDOKZLDLM4CZrU- data-mapping=pathname data-strict=0 data-reactions-enabled=0 data-emit-metadata=0 data-input-position=bottom data-theme=light data-lang=en crossorigin=anonymous async></script></article></main><footer id=footer><p>Â© 2025 Bodun Hu â€¢
<a href=/blog/index.xml>RSS</a></p></footer></body></html>