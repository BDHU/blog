<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>os | std::bodun::blog</title><meta name=keywords content><meta name=description content="Personal Blog for Bodun Hu. Longhorn at UT Austin"><meta name=author content><link rel=canonical href=https://www.bodunhu.com/blog/tags/os/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/blog/assets/css/stylesheet.min.758151a3f029732139c5ed917da59127bed78e4d7fce57610c1cd24d4cb52b2a.css integrity="sha256-dYFRo/ApcyE5xe2RfaWRJ77Xjk1/zldhDBzSTUy1Kyo=" rel="preload stylesheet" as=style><link rel=icon href=https://www.cs.utexas.edu/sites/default/files/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://www.utexas.edu/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://www.utexas.edu/favicon-32x32.png><link rel=apple-touch-icon href=https://www.utexas.edu/apple-touch-icon.png><link rel=mask-icon href=https://www.cs.utexas.edu/sites/default/files/favicon.ico><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.83.1"><link rel=alternate type=application/rss+xml href=https://www.bodunhu.com/blog/tags/os/index.xml><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(a,e,f,g,b,c,d){a.GoogleAnalyticsObject=b,a[b]=a[b]||function(){(a[b].q=a[b].q||[]).push(arguments)},a[b].l=1*new Date,c=e.createElement(f),d=e.getElementsByTagName(f)[0],c.async=1,c.src=g,d.parentNode.insertBefore(c,d)}(window,document,'script','https://www.google-analytics.com/analytics.js','ga'),ga('create','UA-108144808-1','auto'),ga('send','pageview'))</script><meta property="og:title" content="os"><meta property="og:description" content="Personal Blog for Bodun Hu. Longhorn at UT Austin"><meta property="og:type" content="website"><meta property="og:url" content="https://www.bodunhu.com/blog/tags/os/"><meta property="og:image" content="https://www.bodunhu.com/blog/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="Bodun's blog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://www.bodunhu.com/blog/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="os"><meta name=twitter:description content="Personal Blog for Bodun Hu. Longhorn at UT Austin"><script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']]},svg:{fontCache:'global'}}</script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add('dark')</script><noscript><style type=text/css>#theme-toggle,.top-link{display:none}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://www.bodunhu.com/blog/ accesskey=h title="std::bodun::blog (Alt + H)">std::bodun::blog</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://www.bodunhu.com/blog/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://www.bodunhu.com/blog/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://www.bodunhu.com/blog/about/ title=About><span>About</span></a></li><li><a href=https://www.bodunhu.com/blog/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://www.bodunhu.com/blog/>Home</a>&nbsp;»&nbsp;<a href=https://www.bodunhu.com/blog/tags/>Tags</a></div><h1>os</h1></header><article class="post-entry tag-entry"><header class=entry-header><h2><a href=https://www.bodunhu.com/blog/posts/kernelhacking/>Start Linux Kernel Hacking</a></h2></header><footer class=entry-footer>September 14, 2020&nbsp;·&nbsp;12 min</footer><section class=entry-content><p><p align=center><a href=https://www.redandblack.com/opinion/opinion-make-the-switch-to-a-linux-operating-system/article_0b8bb324-5425-11e9-9d96-ab61c820e566.html><img src=https://raw.githubusercontent.com/BDHU/Page_pics/master/posts/linux_kernel_hacking/linux.jpg width=80%></a></p><p>This is a summary of how to compile and boot the Linux kernel on the KVM-qemu virtual machine. It covers how to get a VM running in KVM, how to build a customized kernel, and how to use GDB with the Linux kernel. The experiment is conducted on an amd64 architecture CPU. We use Ubuntu as our testing environment but the steps covered here should apply to other distros as well.</p><h2 id=getting-a-vm-running-in-kvm>Getting a VM running in KVM</h2><p>The Ubuntu ISO image is downloaded from the <a href=https://ubuntu.com/download/desktop>Canonical website</a>. The kernel is downloaded directly from <a href=https://www.kernel.org/>kernel.org</a>. The specs of our test environment is:</p><ul><li>CPU: Intel(R) Core(TM) i7-6800K CPU @ 3.40GHz</li><li>RAM: 32 GB</li><li>Host and Guest OS: Ubuntu 20.04.1 LTS</li><li>Host Kernel Version: 5.4.0-47-generic</li><li>GCC: 7.5.0</li><li>QEMU emulator version: 4.2.0</li><li>Guest Kernel Version: 5.8.6</li></ul><p>After we obtained the Ubuntu ISO image, we use GUI virt-manager to install the OS. One thing to notice here is the default directory for virtual disks is <code>/var/lib/libvirt/images</code>, since my system partition is located on a separate SSD with limited space, the virtual disk directory is changed to my <code>/home</code> directory instead.</p><p>We also create the new virtual disk inside virt-manager. We chose raw format instead of qcow2. Creating a new image file can also be done in command line using:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>qemu-img create -f raw -o preallocation<span style=color:#f92672>=</span>full vmdisk.img 40G
</code></pre></div><p>The preallocation can be turn either on or off depends on personal choices. After the disk image is created, we proceeds in virt-manager to install Ubuntu on the newly allocated virtual disk. We enabled storage for this virtual machine so that we don&rsquo;t need to repeat the installation process every time we launch the VM. One thing to be noticed here is we don&rsquo;t need swap area inside a virtual machine. We can simply use the whole virtual disk for <code>/</code> partition.</p><p>To start the VM from cmd, you might need to change the owner of the disk image. We add the user to both <code>kvm</code> and <code>libvirt</code>. The image created or accessed by virt-manager seems to change the file owner to libvirt-qemu, which may cause problems when starting from cmd.</p><p>After the installation is finished, we can simply launch the virtual machine inside virt-manager through its GUI interface. We can also use command line to start the VM:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kvm -accel kvm -m 8G -smp <span style=color:#ae81ff>6</span> --snapshot -drive format<span style=color:#f92672>=</span>raw,file<span style=color:#f92672>=</span>/home/ed/virtimg/ubuntu20.04
</code></pre></div><p>The argument <code>-accel kvm</code> enables Kernel-based Virtual Machine full virtualization, which uses hardware acceleration. Without this option the VM will become extremely slow. The <code>-m 8G</code> assigns the given amount of memory to the VM. The <code>-smp 6</code> assigns the given number of cores to the guest if the host has multiple cores. The <code>--snapshot</code> ensures that no changes are made to your image during an execution so you can do something dangerous and have the original image file preserved. The <code>-drive</code> option specifies the location of the virtual disk and its format. We will use some of these options later.</p><p>To confirm the VM has internet access, simply execution <code>apt install pkg-name</code> in the guest terminal. No error message would indicates properly functioning network access from the guest VM. For example, when we execute <code>sudo apt install llvm</code> it shows:</p><pre><code>Reading package lists... Done
Building dependency tree       
Reading state information... Done
The following additional packages will be installed:
  llvm-runtime
The following NEW packages will be installed:
  llvm llvm-runtime
0 upgraded, 2 newly installed, 0 to remove and 0 not upgraded.
Need to get 6,796 B of archives.
After this operation, 128 kB of additional disk space will be used.
Do you want to continue? [Y/n] 
</code></pre><h2 id=building-the-kernel>Building the Kernel</h2><p>We can use out customized kernel for our newly created VM. After we obtain the Linux kernel from <a href=https://www.kernel.org/>kernel.org</a>, we extract the source into &lt;kernel dir> and create a separate build directory &lt;kbuild> (outside &lt;kernel dir>).</p><p>Then we enter the &lt;kbuild> directory, run</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>yes <span style=color:#e6db74>&#34;&#34;</span> | make -C /home/ed/Desktop/linux_kernel/kbuild O<span style=color:#f92672>=</span><span style=color:#66d9ef>$(</span>pwd<span style=color:#66d9ef>)</span> config
</code></pre></div><p>This will create a <code>.config</code> file inside &lt;kbuild> with the default options selected. We then open the configuration file and ensures <code>CONFIG_SATA_AHCI=y</code>, which builds the SATA disk driver into the kernel. That will allow your kernel to boot off a (virtual) SATA drive without having to load a module to do it.</p><p>Next we build the kernel by running <code>make</code> in &lt;kbuild>. We use the -j 6 option speedup the building process using multiple processor cores. This process can take a long time.</p><h2 id=build-and-install-kernel-modules>Build and Install Kernel Modules</h2><p>To build modules locally on host, we create another separate &lt;install_mod_dir> directory for building kernel modules. Then in &lt;kbuild>, execute</p><pre><code>make INSTALL_MOD_PATH=/home/ed/Desktop/linux_kernel/install_mod_dir modules_install 
</code></pre><p>Now there is a <code>lib</code> directory inside <code>/home/ed/Desktop/linux_kernel/install_mod_dir</code>, which holds all the kernel modules we are about to install.</p><p>The complete list of modules can be listed using <code>cat modules.builtin</code> inside <code>lib/moduels/5.8.6</code>. Here is a <a href=https://gist.github.com/BDHU/4d31d18ad106a13caceac4a961d04a44>link</a> to all the modules being built. We didn&rsquo;t modify anything in the configuration.</p><p>Then we use guestmount to mount the virtual disk to a mount point on the host</p><pre><code>guestmount -a /home/ed/virtimg/ubuntu20.04 -i ~/vm/linux/
</code></pre><p>In Ubuntu this step yields the following message:</p><pre><code>libguestfs: error: /usr/bin/supermin exited with error status 1.
To see full error messages you may need to enable debugging.
Do:
  export LIBGUESTFS_DEBUG=1 LIBGUESTFS_TRACE=1
and run the command again.  For further information, read:
  http://libguestfs.org/guestfs-faq.1.html#debugging-libguestfs
You can also run 'libguestfs-test-tool' and post the *complete* output
into a bug report or message to the libguestfs mailing list.
</code></pre><p>The underlying problem is that the kernel cannot be read and according to the <a href=https://askubuntu.com/questions/1046828/how-to-run-libguestfs-tools-tools-such-as-virt-make-fs-without-sudo>post</a> and the <a href=https://bugs.launchpad.net/fuel/+bug/1467579>bug report</a> on Ubuntu Launchpad.</p><p>To fix the issue, we need to run</p><pre><code>sudo chmod +r /boot/vmlinuz-*
</code></pre><p>We can verify the contents inside ~/vm/linux by simply cd into it.</p><p>To install the modules we just built, we can copy the <code>&lt;install_mod_dir>lib/modules</code> into the mounted filesystem <code>&lt;mount_point>/lib/modules</code>.</p><p>Finally, we unmount the filesystem by doing</p><pre><code>fusermount -u /mnt/hdd1/vm/linux
</code></pre><h2 id=booting-kvm-with-new-kernel>Booting KVM with new Kernel</h2><p>To boot up the VM with the new kernel, we will add a few extra command line options to kvm. For convenience, we put the scripts into a file. It&rsquo;s also available on <a href=https://gist.github.com/BDHU/8c6ab518ab37571a1cae132d79ac9a9e>gist</a>:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=color:#75715e>#!/bin/bash
</span><span style=color:#75715e></span>
kvm <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    -s <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    -display gtk <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    -cpu host <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    -vga qxl <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    -accel kvm <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    -kernel <span style=color:#e6db74>&#34;/home/ed/Desktop/linux_kernel/kbuild/arch/x86/boot/bzImage&#34;</span> <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    -append <span style=color:#e6db74>&#34;root=/dev/sda1 console=ttyS0,115200n8 nokaslr&#34;</span> <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    -drive format<span style=color:#f92672>=</span>raw,file<span style=color:#f92672>=</span>/home/ed/virtimg/ubuntu20.04 <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    -m 8G <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    -smp <span style=color:#ae81ff>6</span> <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    --snapshot <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>    -S
</code></pre></div><p>Aside from the command line arguments we discussed before, there are a few new members here. the <code>-s</code> switch is a shorthand for <code>-gdb tcp::1234</code>. The <code>-display gtk</code> is optional. It enables the opengl context in the display device for gtk display output. <code>-cpu host</code> says the guest should emulate the host processor. <code>-vga qxl</code> enables 3D acceleration on the guest system. <code>-vga virtio</code> also offers good performance in our case. <code>-kernel</code> allows bootloader to pickup the new kernel. The <code>-append</code> along with its arguments specifies where the root partition of the hard disk is and the console parameter adds a serial console at boot so you can see boot messages. The <code>--snapshot</code> in QEMU says the images that refer to an original image will use Redirect-on-Write to avoid changing the original image. The <code>-S</code> means the kernel won&rsquo;t start executing unless we attach a debugger to it. We only use it later in the debugging stage.</p><p>Again, we can verify there is internet access using the new kernel using <code>apt update</code>. There are no errors shown, which indicates the network is functioning correctly.</p><h2 id=booting-process>Booting Process</h2><p>Now we are able to boot up the VM successfully, we can first measure how much time the kernel spends in booting. Running <code>dmesg -d</code> shows the timestamp and time delta spent between messages. The final line shows <code>[10.842998]</code>. If we use <code>systemd-analyze</code>, it outputs</p><pre><code>Startup finished in 795ms (kernel) + 5.451s (userspace) = 6.247s
graphical.target reached after 5.439s in userspace
</code></pre><p>The reason why there is a gap between these two measurement is because <code>dmesg</code> is not a reliable test of how long a boot-up process goes. <code>dmesg</code> itself merely collects information. The drivers and other system processes can output messages at any point in time. There may or may not be processes spawning between those messages.</p><p>Next, we are going to look at how PCI device is involved in kernel startup. <code>lspci</code> outputs the follow</p><pre><code>00:00.0 Host bridge: Intel Corporation 440FX - 82441FX PMC [Natoma] (rev 02)
00:01.0 ISA bridge: Intel Corporation 82371SB PIIX3 ISA [Natoma/Triton II]
00:01.1 IDE interface: Intel Corporation 82371SB PIIX3 IDE [Natoma/Triton II]
00:01.3 Bridge: Intel Corporation 82371AB/EB/MB PIIX4 ACPI (rev 03)
00:02.0 VGA compatible controller: Red Hat, Inc. Virtio GPU (rev 01)
00:03.0 Ethernet controller: Intel Corporation 82540EM Gigabit Ethernet Controller (rev 03)
</code></pre><p>We can use the PCI address here to search for corresponding information in <code>dmesg</code>. For example, if we use the domain value \(0000:\) as query, we get something like:</p><pre><code>[    0.295026] PCI host bridge to bus 0000:00
[    0.299055] pci 0000:00:00.0: [8086:1237] type 00 class 0x060000
[    0.300133] pci 0000:00:01.0: [8086:7000] type 00 class 0x060100
[    0.301163] pci 0000:00:01.1: [8086:7010] type 00 class 0x010180
[    0.311006] pci 0000:00:02.0: [1af4:1050] type 00 class 0x030000
[    0.319650] pci 0000:00:03.0: [8086:100e] type 00 class 0x020000
</code></pre><p>The full result is also available as <a href=https://gist.github.com/BDHU/4d31d18ad106a13caceac4a961d04a44#file-dmesg_output>gist</a>.</p><p>The <code>lspci</code> command specifies the type of device right after the address. For example, the first one is host bridge. We specifically selected the message in the <em>type 00 class</em> format here. The significance here is that the class value actually telss us the type of the corresponding device. We can check the <a href=https://github.com/torvalds/linux/blob/master/include/linux/pci_ids.h>include/linux/pci_ids.h</a> for each macro respectively. For example,</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=color:#75715e>#define PCI_CLASS_NETWORK_ETHERNET	0x0200
</span></code></pre></div><p>this line shows the value 0x0200 corresponds to a network PCI device. This aligns with our <code>dmesg</code> output as well as the <code>lspci</code> result.</p><h2 id=debugging-kernel>Debugging Kernel</h2><p>To build KVM+GDB-friendly kernel, we need to have proper CONFIG_DEBUG* options set in the .config file. More specifically, we need to have the following options enabled:</p><ul><li>CONFIG_DEBUG_INFO y: compile the kernel with debug info. The full list of definitions can be found <a href=https://cateee.net/lkddb/web-lkddb/DEBUG_INFO.html>here</a>.</li><li>CONFIG_DEBUG_INFO_DWARF4 y: generate dwarf4 debug info. Definition can be found <a href=https://cateee.net/lkddb/web-lkddb/DEBUG_INFO_DWARF4.html>here</a>.</li><li>CONFIG_GDB_SCRIPTS y: creates the required links to GDB helper scripts in the build directory. Full definition can be found <a href=https://cateee.net/lkddb/web-lkddb/GDB_SCRIPTS.html>here</a>.</li><li>CONFIG_GDB_INFO_REDUCED n: disable reduced gdb info.</li><li>CONFIG_KGDB y: kernel debugging location. Full list of definitions found <a href=https://cateee.net/lkddb/web-lkddb/KGDB.html>here</a>.</li><li>CONFIG_FRAME_POINTER y: compile the kernel with frame pointers. Full list of definitions found <a href=https://cateee.net/lkddb/web-lkddb/FRAME_POINTER.html>here</a>.</li><li>CONFIG_SATA_AHCI y: this option enables support for AHCI Serial ATA. Definition found <a href=https://cateee.net/lkddb/web-lkddb/SATA_AHCI.html>here</a>.</li><li>CONFIG_KVM_GUEST y: this option enables various optimizations for running under the KVM hypervisor. Definition found <a href=https://cateee.net/lkddb/web-lkddb/KVM_GUEST.html>here</a>.</li><li>CONFIG_RANDOMIZE_BASE n: drop support for Kernel Address Space Layout Randomization (KASLR). Definition found <a href=https://cateee.net/lkddb/web-lkddb/RANDOMIZE_BASE.html>here</a>. We also added <code>nokaslr</code> in our qemu arguments.</li><li>CONFIG_SMP y: enable Symmetric multi-processing support. Definition found <a href=https://cateee.net/lkddb/web-lkddb/SMP.html>here</a>.</li></ul><p>Now we can recompile the kernel and attack gdb to it. We simply add <code>-S</code> option to kvm to only start the VM when gdb is attached. Then we enter our &lt;kbuild> directory and execute:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>gdb vmlinux
<span style=color:#f92672>(</span>gdb<span style=color:#f92672>)</span> target remote:1234
</code></pre></div><p>The step is also documented in the kernel community <a href=https://www.kernel.org/doc/html/latest/dev-tools/gdb-kernel-debugging.html>documentation</a>.</p><h2 id=set-breakpoints>Set Breakpoints</h2><p>Spin lock is easy to find in a kernel. Therefore, we will set break points on <code>spin_lock</code>. For kernel 5.8.6, we see that <code>spin_lock</code> is defined in <a href=https://elixir.bootlin.com/linux/v5.8.6/source/include/linux/spinlock.h#L351>https://elixir.bootlin.com/linux/v5.8.6/source/include/linux/spinlock.h#L351</a> as a inline function. If we trace the function, we can see the actual function we should use is <code>_raw_spin_lock</code> defined <a href=https://elixir.bootlin.com/linux/v5.8.6/source/kernel/locking/spinlock.c#L149>here</a>:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=color:#75715e>#ifndef CONFIG_INLINE_SPIN_LOCK
</span><span style=color:#75715e></span><span style=color:#66d9ef>void</span> __lockfunc <span style=color:#a6e22e>_raw_spin_lock</span>(raw_spinlock_t <span style=color:#f92672>*</span>lock)
{
	__raw_spin_lock(lock);
}
</code></pre></div><p>If we need to break the execution only when a given program is executed, we can use the program PID to as the condition. The problem is, how do we get the program PID if it doesn&rsquo;t last for long?</p><p>We could instead first set a breakpoint on <code>fork</code>. We can break its kernel call at <code>_do_fork</code> which is defined <a href=https://elixir.bootlin.com/linux/v5.8.6/source/kernel/fork.c#L2416>here</a>. After that, we can simply continue executing the kernel until we run the program.</p><blockquote><p>Note: we need to compile the program and open a new terminal first. Since they both involves forking new processes, which will hit <code>_do_fork</code> before our program runs.</p></blockquote><p>Then we print the process PID using <code>p $lx_current().pid</code>, we then use this value as the condition for <code>b _raw_spin_lock if $lx_current().pid == pid_value</code> inside gdb.</p><p>If we want <code>_raw_spin_lock</code> to break under different contexts, we can simply use PID as different contexts. We can also set break points in functions in different contexts that calls <code>spin_lock</code> and see what they do. For example, we can set break point at <code>expand_downwards</code> defined in <a href=https://elixir.bootlin.com/linux/v5.8.6/source/mm/mmap.c#L2428>here</a>, if we back trace this function, we will get a series of calls, we mention the important ones here</p><pre><code>#1  0xffffffff81284c4e in expand_stack
#3 0xffffffff813843db in load_elf_binary
#8  do_execve
#12 0xffffffff81b1f658 in do_syscall_64
</code></pre><p>We also added a helper script in .gdbinit to print our the name of the function, which is &lsquo;&lsquo;anacron&rsquo;&rsquo; in this case.
In short, this process execute commands periodically, and it performs a sys call which loads elf binary, thus requiring stack expansion.</p><p>Another example is timer interrupt. The <code>get_next_timer_interrupt</code> calls <code>_raw_spin_lock</code>. We select some messages from backtrace:</p><pre><code>#1  0xffffffff8113b224 in get_next_timer_interrupt
#2  0xffffffff8114d52e in tick_nohz_next_event
#4  tick_nohz_idle_stop_tick ()
#5  0xffffffff810df567 in cpuidle_idle_call ()
</code></pre><p>In short, the is a timer interrupt that gets called when CPU is idle.</p><p>The last example is <code>hrtimer_interrupt</code>. The selected messages are:</p><pre><code>#4  0xffffffff8114d80c in tick_sched_timer
#7  0xffffffff8113c8e7 in hrtimer_interrupt
#12 run_on_irqstack_cond
#14 0xffffffff81c00cc2 in asm_sysvec_apic_timer_interrupt
</code></pre><p>In summary, <code>hrtimer_interrupt</code> is called as event handler. This function is responsible to select all timers that have expired and either move them to the expiration list (if they may be processed in softIRQ context) or call the handler function directly.</p><h2 id=syscall>Syscall</h2><p>Essentially, processor switches from the user mode to kernel mode and starts execution of the sys call entry - <code>entry_SYSCALL_64</code>, we can find its definition at <a href=https://elixir.bootlin.com/linux/v5.8.6/source/arch/x86/entry/entry_64.S#L94>here</a>. This is the only entry point used for 64-bit system calls. We can set a break point here. When the break point is hit, we use <code>info registers</code> in gdb to get the value of cr3. In our case, it is 0x22a6d5806. Then we simply step from this breakpoint, and will likely reach <code>SWITCH_TO_KERNEL_CR3 scratch_reg=%rsp</code>. After this call the value in cr3 is changed to 0x22a6d4006. The macro is defined <a href=https://elixir.bootlin.com/linux/v5.8.6/source/arch/x86/entry/entry_32.S#L165>here</a>.</p><p>We can see whenever the processor switch from the user mode to kernel mode the value of cr3 is changed. The root cause the Page <a href=https://www.kernel.org/doc/html/latest/x86/pti.html>Table Isolation (PTI)</a>. It is a countermeasure against attacks on the shared user/kernel address space such as the &lsquo;&lsquo;Meltdown&rsquo;&rsquo; approach. To mitigate this class of attacks, two independent page table copies are created, one in kernel space, one in user space. The cr3 register enables the processor to translate linear addresses into physical addresses by locating the page directory and page tables for the current task. So whenever the process enters kernel mode, the kernel copy requires its page directory address to be loaded into cr3 register.</p><p>If we add <code>nopti</code> in <code>-append</code> in the QEMU cmd argument and perform the same steps. We get 0x231466005 before and after <code>SWITCH_TO_KERNEL_CR3 scratch_reg=%rsp</code> is executed. Based on the desciption in the <a href="https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git/tree/Documentation/admin-guide/kernel-parameters.txt?h=v5.1.3#L3656">linux kernel tree</a>, the <code>nopti</code> on X86_64 is equivalent to pti=off, therefore explaining the constant value of cr3.</p></p></section></article><article class="post-entry tag-entry"><header class=entry-header><h2><a href=https://www.bodunhu.com/blog/posts/exokernel/>Exokernel</a></h2></header><footer class=entry-footer>September 1, 2020&nbsp;·&nbsp;8 min</footer><section class=entry-content><p><p>Exokernel is a term every system researcher has heard of at some point in life. However, according to the <a href=https://pdos.csail.mit.edu/>PDOS</a> group at MIT, there aren&rsquo;t any exokernel-based operating systems in active use today. It&rsquo;s interesting to discover what ideas exokernels brought to the OS high-level design and some potential drawbacks of such design choice.</p><p>Perhaps the most important thing to keep in mind is that exokernel operating system architecture pushes management of physical resources to the application level, contrary to what most monolithic kernel would do: providing hardware resource management through some form of abstraction, usually hiding hardware-related details.</p><h2 id=limitations-of-traditional-approaches>Limitations of Traditional Approaches</h2><p>Monolithic kernels usually enforce centralized resource management via a set of abstractions. In microkernel-based system, they are usually provided through some form of trusted user-level servers. There are several drawbacks:</p><ul><li><p>Too general. Over generalizing can limit application diversity and have performance implications (domain/application-specific approach usually have performance improvements, in the cost of, well, being more &ldquo;specific&rdquo;.). For example, in UNIX, two applications exhibiting rather different memory access patterns are subject to the general-purpose OS scheduler and page replacement policy. Letting applications define such policies can open doors for performance improvements since applications have better knowledge of their behaviors.</p></li><li><p>Hide information. This is further expanded from the previous point. Applications tend to have better &ldquo;self-awareness&rdquo; and can implement custom policies that outclass the general-purpose ones provided by the kernel.</p></li><li><p>Limited functionality. Having limited resources in hand can inhibit implementation of new ideas.</p></li></ul><p>However, generalization may not be a bad thing. As discussed in the <em>UNIX the Timesharing System</em> paper, having a generalized and unified yet limited file system API can simplify programming efforts. Accessing both ordinary files and I/O devices is achieved by utilizing a unified interface. Nobody today wants to implement a different set of policies just for character device or block device.</p><h2 id=design>Design</h2><p>Essentially, exokernel consists of thin veneet that multiplexes and exports physical resources through a set of primitives. The libraries, running in the application space, use them to implement with special-purpose functionalities in a higher abstraction level. The architecture is shown in the Paper:</p><p align=center><a href=https://pdos.csail.mit.edu/6.828/2008/readings/engler95exokernel.pdf><img src=https://raw.githubusercontent.com/BDHU/Page_pics/master/posts/exokernel/exokernel_arch.png width=90%></a></p><p>There are three majors tasks to separate protection from management:</p><ul><li><p>Tracking ownership of resources.</p></li><li><p>Ensure protection by guarding resource usage.</p></li><li><p>Revoke access.</p></li></ul><p>The paper presents three techniques to achieve these goals:</p><ul><li><p><em>secure binding</em>: lib OS can securely bind to machine resources.</p></li><li><p><em>visible revocation</em>: lib OS can participate in a resource revocation protocol. (Keep in mind why the revocation needs to be visible)</p></li><li><p><em>abort protocol</em>: exokernel itself can break secure binding of uncooperative lib OS.</p></li></ul><p>In general, exokernel should expose hardware resources such as disk memory, CPU, interrupts, through low-level primitives with as few abstractions as possible. The resource management policy should be enforced by the library OS instead. <strong>The policy control boils down to whether the exokernel permits resource allocation</strong>.</p><h2 id=secure-binding>Secure Binding</h2><p>One of the primary tasks of an exokernel is to multiplex resources securely, providing protection for mutually distrustful applications. Secure binding allows the kernel to protect resources without understanding them.</p><p>There are three techniques to implement secure bindings:
hardware mechanisms,software caching, and downloading application code.</p><h2 id=understanding-secure-binding-through-examples>Understanding Secure Binding through Examples</h2><p>Secure binding is rather abstract and hard-to-comprehend concept without concrete examples. Here are some examples illustrating how secure multiplying is achieved through secure binding.</p><p>Take memory allocation for an example. When a library OS tries to allocate a physical memory page, the exokernel creates a secure binding for that page by recording the owner and the capabilities specified by the library OS. Essentially, accessing memory resources is achieved through capability. The exokernel acts as a door-keeper that checks the validity of the capability from the library OS.</p><p>I personally like to think the role of the exokernel in memory system is to act as a security guard that protects resources that can be access by the library OS through some form of interface. For example, if the hardware defines a page-table interface, which can be accessed by the lib OS, the exokernel must guard the page table. If the lib OS tries to enter a new virtual-to-physical memory mapping, then the exokernel must check the corresponding memory capability.</p><p>In summary, privileged machine operations must be guarded by the exokernel.</p><h3 id=aegis-the-exokernel>Aegis: the exokernel</h3><p>Up to this point I find it still hard to full understand what exokernel is capable of. Having a concrete system to study for is much more helpful. So here comes Aegis.</p><p>Here is a subset of Aegis&rsquo;s primitives and sys call interfaces that encapsulate these exported primitives. Having a concrete list feels so much better than reading a list of abstract terms!</p><p>Here is a sublist of primitives:</p><table><thead><tr><th><strong>Primitive Operations</strong></th><th style=text-align:center>Description</th><th></th></tr></thead><tbody><tr><td>TLBwr</td><td style=text-align:center>Insert mapping into TLB</td><td></td></tr><tr><td>TLBvadelete</td><td style=text-align:center>Delete virtual address from TLB</td><td></td></tr></tbody></table><p>And here is a sublist of system call interfaces:</p><table><thead><tr><th><strong>System Call</strong></th><th style=text-align:center>Description</th><th></th></tr></thead><tbody><tr><td>Yield</td><td style=text-align:center>Yield processor to named process</td><td></td></tr><tr><td>Alloc</td><td style=text-align:center>Allocation of resources</td><td></td></tr><tr><td>Scall</td><td style=text-align:center>Synchronous protected control transfer</td><td></td></tr></tbody></table><h3 id=address-translation>Address Translation</h3><p>It&rsquo;s important to first mention that Aegis provides a small number of guaranteed mappings by partitioning an application&rsquo;s virtual address space into two segments. The first segments hold normal application data; the other one has guaranteed mapping and holds exception code and page-table. (Guaranteed mapping is sort of a safe lock.)</p><p>When a TLB miss happens, there are several steps happening:</p><ul><li><p>Aegis checks which segment the virtual address resides in. If it&rsquo;s in the standard user segment the exception is dispatched to the application. Otherwise, the exokernel handles the exception or forwards it to the application depends on whether there&rsquo;s guaranteed mapping.</p></li><li><p>The application looks up the address in it page table, inserts TLB entry and creates capability, then invokes Aegis system routine.</p></li><li><p>Aegis validifies the capability. Upon approval, the mapping is installed.</p></li><li><p>Application resumes execution from kernel mode.</p></li></ul><p>The key takeaway here is the exokernel itself is involved in very few privileged operations such as interacting directly with the hardware via low-level primitives. the bulk of the work is done in the application level.</p><p>Because the kernel contains minimal functionalities, it can be extremely fast compared to a monolithic kernel. However, does that mean the overhead is shifted to the library OS instead?</p><h3 id=exos-the-library-os>ExOS: the Library OS</h3><p>The most prominent feature about library OS is that it manages operating system abstractions at application level.</p><p>The GEMM operation on both ExOS and Ultrix (a monolithic kernel OS) doesn&rsquo;t seem to have much difference since GEMM doesn&rsquo;t use any special abilities of both OSes. It does indicates that the performance gain from the minimal design of exokernel is somewhat cancelled out by the application-space overhead.</p><blockquote><p>The exokernel paper mentions that in the context of networking, the major reason for ExOS to download code is that the network buffers on our machines cannot be easily mapped into application space in a secure way. Downloading the code into the kernel allows applications integrating operations such as checksum during the copy of the message from these buffers to user space. However, I&rsquo;m a little bit skeptical of this statement today. Usually a highly performant TCP stack will be implemented in userspace, along with some polling (DPDK for example). But it will be interesting to compare the exokernel approach to the gigantic Linux TCP stack. The second reason is downloaded code is bounded, thus allowed full context switch to an unscheduled application.</p></blockquote><p>I do find the graph in the exokernel paper interesting. It shows that when application-level message handlers are downloaded into the kernel, the roundtrip latency is almost not affected by the number of processes. Since the operation is performed inside kernel upon message arrival, no handling is needed from the application. This has the advantage that application handler is subject to scheduling, which has performance implications. (The choice of scheduler is the key bottleneck here.)</p><p align=center><a href=https://pdos.csail.mit.edu/6.828/2008/readings/engler95exokernel.pdf><img src=https://raw.githubusercontent.com/BDHU/Page_pics/master/posts/exokernel/throughput.png width=80%></a></p><h2 id=modularity>Modularity</h2><p>It a natural property of exokernel since the exokernel itself is simplistic. Thus, operating system abstractions can be redefined simply by changing the library OS. Thus, applications have finer-grained control over resources. However, I think it comes at a cost. In a monolithic kernel, applications are subject to general purpose scheduler. Having modular domain-specific schedulers can indeed improve performances, however, it might also leads to multiple scheduler contention, which is not covered in the paper.</p><h2 id=conclusion>Conclusion</h2><p>Exokernel does offer some new insights into system design. The simple design concept of the exokernel itself has major performance benefits as well as a limited set of primitives which gives much freedom to the application. However, that means the library OS has to take more responsibility. The paper didn&rsquo;t cover enough analytics on more general use cases. The performance gain seems to come from some highly specialized, exokernel-specific implementations of OS abstractions (such as IPC, VM, etc.). The more general case, such as GEMM, seem to be much less performance, when compared to traditional approaches. It will be good to see how exokernel performs under more diverse workloads.</p><p>I&rsquo;ve also heard that one reason microkernels never took off was partially due to the performance slowdown compared to monolithic kernels. Since exokernel shared many similarities with microkernels (seems like exokernel is a more stripped-down version of microkernel since it barely has an OS core), it will likely fall into the same caveat. However, there doesn&rsquo;t seems to have a comprehensive benchmarking trials to compare all major types of kernels.</p></p></section></article><article class="post-entry tag-entry"><header class=entry-header><h2><a href=https://www.bodunhu.com/blog/posts/unix/>Sketch on the UNIX Timesharing System</a></h2></header><footer class=entry-footer>August 27, 2020&nbsp;·&nbsp;7 min</footer><section class=entry-content><p><p>Unix is general-purpose, multi-user, interactive operating system, it offers
several new features hardly found in other larger operating systems back in
the day. These features include (1) a hierarchical file system incorporating demountable volumes; (2) compatible file, device, and inter-process I/O; (3) the ability to initiate asynchronous processes; (4) system command language selectable on a per-user basis; and (5) over 100 subsystems including a dozen languages.</p><h2 id=simplicity-at-its-core>Simplicity at its Core</h2><p>Simplicity was engraved into the gene of Unix since its birth, as the paper states: &ldquo;Perhaps the most important achievement of UNIX is to demonstrate that a powerful operating system for interactive use need not be expensive either in equipment or in human effort&rdquo;. Therefore, it is important to keep in mind how simplicity
is reflected in the design of Unix.</p><h2 id=the-file-system>The File System</h2><p>Perhaps the singly most important part of Unix. The &ldquo;everything is file&rdquo; concept that influences all modern system designs. Here is a short description of each major file types.</p><ul><li><strong>Ordinary Files</strong>: no particular structuring is expected by the system. The structure of files is controlled by the programs which use them, not by the system.</li><li><strong>Directories</strong> provide the mapping between the names of files and the files themselves, inducing a structure on the file system. The only difference between directory and normal file is the the directory can&rsquo;t be written on by unprivileged programs, meaning the contents of directories are controlled by the system.</li></ul><blockquote><p><em>linking</em> allows the same non-directory file to appear in several directories under possibly different names; a directory entry for a file is sometimes called a link. All links to a file have equal rights. A directory entry for a file consists merely of its name and a pointer to the file metadata. Therefore a file exists independently of any
directory entry. Directory can be considered as link.</p></blockquote><ul><li><strong>Special Files</strong>: perhaps the most prominent feature of the &ldquo;everything is a file&rdquo; principle. They are read and written just like ordinary disk files, but requests to read and write will result in activation of the I/O device. It blurs the line between file and device I/O since they share identical interfaces and are subject to the same protection mechanism.</li></ul><h2 id=removable-file-system>Removable File System</h2><p>The Unix file system has a <em>mount</em> system request which, in effect, replaces a leaf of the hierarchy tree (the ordinary file) by a whole new subtree (the hierarchy stored on the removable volume). It provides a unified abstraction of the file system hierarchy where the underlying storage components become transparent to the user.</p><blockquote><p>One exception to the identical treatment of files on different devices: no link may exist between one file sys hierarchy and another. Otherwise, some form of bookkeeping would be required to when a removable volume is dismounted from one file system but not the other.</p></blockquote><h2 id=protection>Protection</h2><p>Each user is assigned a unique user ID. A file, upon its creation, is marked with the user ID of its owner. Also given for new files is a set of seven protection bits. Six of these specify independently read, write, and execute permission for the owner of the file and for all other users. This is a perfect example of ACL (access control list) system.</p><h2 id=io-calls>I/O Calls</h2><p>Once again, we see how Unix is trying to provide a unified interface such that performing I/O on different devices doesn&rsquo;t would not require different accessing patterns or styles. There is no distinction between &ldquo;random&rdquo; and sequential I/O, nor is any logical record size imposed by the system. Calls like <em>open</em>, <em>seed</em>, <em>read</em>, and <em>write</em> can be found in all major Unix-like systems today.</p><p>I found it interesting that the authors were arguing why there are no user-visible locks in the file system. The first argument says: &ldquo;they are unnecessary because we are not faced with large, single-file data bases maintained by independent processes&rdquo;. It might be different today on modern systems so I have some doubts on that argument. The next one is &ldquo;they are insufficient because locks in the ordinary sense, whereby one user is prevented from writing on a file which another user is reading, cannot prevent confusion when, for example, both users are editing a file with an editor which makes a copy of the file being edited.&rdquo; This certainly is true because the the copies are separate files with distinct metadata during editing but once the editing is finished then it becomes tricky when the updated content needs to be written back to the original file without some form of synchronization or ordering.</p><p>The paper further explains the the system has sufficient internal interlocks to prevent these situations from happening. The exact details of how it works is not quite clear at this stage.</p><h2 id=implementation>Implementation</h2><p>As we&rsquo;ve already known, a directory entry contains only a name for the associated file and a pointer to the file itself. This pointer is an integer called the <em>i-number</em>. When the file is accessed, its i-number is used as an index into a system table (the i-list) stored in a known part of the device on which the directory resides.</p><blockquote><p>Directory entry -> (File Name, i-number) -> i-list -> i-node -> description of the file</p></blockquote><p>Because the file is described by its corresponding i-node, any copy and deleting operations are circulating around modifying directory entry or i-node link-count field without actually touching the bulk of the file itself.</p><blockquote><p>It important to distinguish between file descriptor and inode. By definition, files are represented by inodes. The inode of a file is a structure kept by the filesystem which holds information about a file, like its type, owner, permissions, inode links count and so on. Other other hand, the file descriptor is the value returned by an open call is termed a file descriptor and is essentially an index into an array of open files kept by the kernel. There is an inode in the i-list but every process can have its own file descriptor for one file.</p></blockquote><h2 id=processes>Processes</h2><p>A process is the execution of an image. An image is a computer execution environment. It includes a core image, general register values, status of open files, current directory, and the like. An image is the current state of a pseudo computer. You can imagine the image as a motionless snapshot of current state of the processor, or you can image as the content saved to the main memory when a currently executing process is preemptied by another one.</p><p>The user-core part of an image has three logical segments. The program text segments starting from location 0. At the first 8K byte boundary above the text segment is a non-shared, writable data segment. The highest address in the virtual address space is a stack segment.</p><p>One key feature of UNIX is a new process can come into existence only by ise of the <em>fork</em> system call. Another system primitive is invoked by <em>execute</em>. This call resembles a &ldquo;jump&rdquo; machine instruction rather than a sub-routine call.</p><h2 id=shell>Shell</h2><p>Shell is a command line interpreter. Programs executed by the Shell start off with two open files which have file descriptors 0 and 1, representing files for reading and writing. The symbol &ldquo;&lt;&rdquo; and &ldquo;>&rdquo; represent what files the file descriptor 0 and 1 will refer to for the duration of the command passed to shell.</p><p>A filter, represented by &ldquo;|&rdquo;, is a program that copies its standard input to its standard output (without processing).</p><p>Command separator, represented by &ldquo;;&rdquo;, is used to separate multiple commands. A related feature is &ldquo;&&rdquo;, which execute the command in the background. When the shell doesn&rsquo;t wait for the completion of a command, the identification of the process running that command is printed. In addition, parentheses can be used to enforce order of execution.</p><blockquote><p>It&rsquo;s worth noting the shell is itself a command, and may be called recursively.<br>Since it&rsquo;s a command, it also shared the luxury of having standard I/O file descriptor. Thus, command such as:<br><strong>sh &lt; file_containing_shell_commands</strong> would work.</p></blockquote><p>The last step in the initialization of UNIX is the creation of a single process and the invocation of a program called <em>init</em>. <em>init</em> have various sub-instances prompting for user login information. If the login succeeds, <em>init</em> performs an <em>execute</em> of the Shell. Essentially, <em>init</em> is the parent process of Shell.</p></p></section></article><article class="post-entry tag-entry"><header class=entry-header><h2><a href=https://www.bodunhu.com/blog/posts/operatingsystemmemorymanagement/>A Little Review on Barrelfish Memory Management</a></h2></header><footer class=entry-footer>February 18, 2019&nbsp;·&nbsp;9 min</footer><section class=entry-content><p><p>The memory management has been mentioned numerous times and still remains huge topic. virtual vs. physical memory, physical frame allocation, MMUs, page faults, address space layout, and
demand paging and swapping are familiar terms for every undergrad in college.</p><p>In monolithic kernels such as Linux, much of the functionality is handled in kernel. However, there are OSes that push these functionalities to user space such as Barrelfish. Many concept here will thus be borrowed from the <a href=http://www.barrelfish.org/>Barrelfish OS</a>. I will also borrow some materials from the main pdf from Barrelfish course materials provided by Professor Simon Peter.</p><h2 id=memory-management-in-general>Memory Management in General</h2><p>Microkernels like L4, Mach, Chorus, and Spring trapped page faults in the kernel but then reflected them up to other processes which carried out the
actual page fault handling. This was done on a per-region basis, so each area of
virtual memory was associated with some paging server. Memory objects could be shared between different processes and mapped differently in different address spaces.</p><p align=center><img src=https://raw.githubusercontent.com/BDHU/Page_pics/master/posts/Barrelfish/os.png width=400></p><p>Such abstraction means that what happens when a page fault happens is entirely dependent on the code in the user-level pager. This design is highly extensible since it&rsquo;s all user code and thus isolated, which means that if a user-level pager crashes, there&rsquo;s a good chance the rest of the OS can continue quite happily since much of the functionality is moved away from the kernel.</p><p>However, moving functionality out of the kernel an important question: if user-space processes can manipulate virtual address spaces, how can
we make sure that one user&rsquo;s program can&rsquo;t manipulate another address space and memory? Here we will introduce the concept of capabilities.</p><h2 id=capabilities>Capabilities</h2><p>Capabilities are introduced to solve the access control problem in operating systems. Access control is the problem of specifying, and enforcing, which subjects (or principals) can perform particular actions on particular objects in an operating system.</p><p>The Barrelfish documentation does a good job illustrating capabilities: abstractly, access control can be thought of as a matrix, which represents all possible combinations of operations in the system. Each row of the matrix represents a
different subject, and each column represents a different object. Each entry in the
matrix contains a list of permissible actions.</p><p>Thus, we have two targets to emphasis: the subject and the object. The ACL(access control list) focuses on the object being operated on.</p><p>A good example will be whenever you enter <em>ls -a</em> in a Linux terminal, you will get list of entries specifies the attributes of a file. Here the attributes represent how a object (in this case, a file) may be accessed.</p><p>On the other hand, a capability can be thought of as a &ldquo;key&rdquo; or &ldquo;licence&rdquo;. It is an unforgettable token which grants authority. Possession of a capability for an object gives the holder the right to perform certain operations on the object.</p><p>A good example will be the file descriptor in Linux. A file is accessed through its file descriptor. Here the file descriptor serves as the &ldquo;key&rdquo; to gain access to the file itself. Capabilities provide fine-grained access control: it is easy to provide access to specific subjects, and it is easy to delegate permissions to others in a controlled manner.</p><p>Note that to be correct, any capability representation must protect capabilities
against forgery. Capabilities can be implemented in various ways such as tagged capabilities, sparse capabilities, or partitioned capabilities. In Barrelfish we used the partitioned capabilities.</p><p>In partitioned capabilities, the kernel ensures that memory used to store capabilities is always separated from that used by user processes to store data and code, for example by using the MMU or ensuring that capability memory is only accessible in kernel mode. The OS maintains the list of capabilities each user principal holds (the clist), and explicitly validates access when performing any privileged operation. Thus, whenever the user accesses memory, the operation can only be done through the resources' corresponding capability. For example, one can map a page frame in the page table page through functions calls with only capabilities.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c>Caprefa<span style=color:#f92672>-&gt;</span>install(Caprefb, slot, flags)
</code></pre></div><h2 id=capabilities-in-barrelfish>Capabilities in Barrelfish</h2><p>According to Barrelfish documentation, all memory in Barrelfish (and some other system resources which do not occupy memory) is described using capabilities. Capabilities are typed, and capabilities can be retyped by users holding them according to certain rules and restrictions. The official documentation has very good explanation on the capability management in Barrelfish. Here is the permissible types for the retype invocation capability retyping:</p><p align=center><img src=https://raw.githubusercontent.com/BDHU/Page_pics/master/posts/Barrelfish/cap.png width=400></p><p align=center><a href=http://www.barrelfish.org/publications/TN-013-CapabilityManagement.pdf>Image source</a></p><p>Capabilities referring to memory regions. Capabilities can also be split, resulting 2 new capabilities of the same type, one for each half of the region. Some of the more important capability types in Barrelfish are shown in figure below. The picture is from the Barrelfish manual provided in CS378 Mutlicore class by Simon Peter:</p><p align=center><img src=https://raw.githubusercontent.com/BDHU/Page_pics/master/posts/Barrelfish/cap_aos.png width=400></p><p>Allocation and management of physical memory is achieved by retyping and splitting operations on capabilities. For most kernels, the implementation is to constantly allocate and deallocate memory for a wide variety of purposes, much as any large C program relies heavily on malloc and free.</p><p>The problem is what the kernel should do when this runs out. The current solution in Linux is little more than &ldquo;kill a random process and reclaim its memory&rdquo;, which can be a problem for system stability. In Barrelfish, all kernel objects are actually allocated by user programs. If a user process wants to create another process (or dispatcher in Barrelfish parlance), it has to get a capability to a DRAM area of the right size, retype this capability to type Dispatcher, and hand this to the kernel. This will be covered in later posts. To access different types of memory resources, the corresponding capability has to be retyped to the right type.</p><h2 id=more-on-implementation>More On Implementation</h2><p>In Barrelfish, every capability resides in a slot in a CNode, so a pair (CNode, slot) would identify a capability. It is important to point out that the CNode is another capability itself. Each process in Barrelfish has a CSpace which is structured as a two-level table. So there are actually two different CNode capability types - one for the first level of the table, and one for the second. Every process has, within its &ldquo;dispatcher control block&rdquo;, a pointer to the top-level or root CNode which the kernel can traverse.</p><p>A capability reference in Barrelfish is very similar to VA: the first few bits can represent an index into the first level L1CNode, while the next few bits refer to a slot in a CNode referred to by the capability in the L1CNode slot. Here is a picture from the main pdf showing how the the CSpace is represented in Barrelfish:</p><p align=center><img src=https://raw.githubusercontent.com/BDHU/Page_pics/master/posts/Barrelfish/Cspace.png width=400></p><h2 id=thoughts-on-design-decisions>Thoughts on Design Decisions</h2><p>Even though it is pretty straight forward to understand the CSpace structure, the actual implementation is a lot more complicated than that. Since the CSpace is not directly accessible by user space program, there are additional data structures used to keep track of available memory resources.</p><p>In our implementation, the user process keeps a doubly linked list of <em>struct mmnode</em> to indicate the memory available for allocation. Each element in the free list tracks the information corresponding to one capability. However, there is a big problem with this seemingly simple implementation. Every time we allocate a practical memory space from the memory region, a new capability is created while the old capability still remain in the physical memory pointing to a memory range before the allocation happens. Therefore, the old capability would cover extra memory spaces that are already allocated and managed by other capabilities.</p><p>To solve this problem, we maintain the allocation information in the <em>struct mmnode</em> each time an allocation occurs. If a capability covering physical address space from 0 to 100 is requested for 20 units of memory space, then the memory available for the next allocation would be from 20 to 100 even though the capability itself still manages 0 to 100. By restricting subsequent accesses only to the new memory range, the old capability can still be kept around and used later for retyping.</p><p>Another Problem emerges when we try to free a memory. Since everything is managed by capabilities, freeing a piece of memory also involves managing the capability responsible for the memory. So an intuitive thought could be whenever a memory space is freed, the corresponding capability is merged back to a piece of memory adjacent to it, managed by a different capability.</p><p>However, since capabilities can not be merged, an alternative choice would be to simple destroy it during free. However, this is even a bigger problem in Barrelfish.</p><p>Imagine the scenario where capability A is partially allocate from memory space 30 to 100. Later on another memory is freed and that piece of memory is managed by capability with base 100 and size 20, so the memory range covers 100 to 120, which indicates these the two capability could be &ldquo;merged&rdquo;.</p><p>In this case, if the first capability is destroyed, all children of the first capability will also be destroyed, thus the already allocated memory from 0 to 20 will be thrown away, which is not desired. If the second capability is destroyed, the first one will also be destroyed to create a new capability covering 20 to 120, which will still results in the destruction of capability A.</p><p>Our assumption here is that the parent or root capability is never destroyed when added to the free list. Whenever a capability needs to be freed, the memory manager is responsible to make sure the capability is only merged with another capability from the same parent capability.</p><p>This is done by creating another list of nodes that tracks all parent capabilities. It is only added when the memory manager adds new capabilities to the free list. After the user initializes free, the memory manager actually creates a new free struct mmnode first, then it find the node&rsquo;s parent node, copying the parent&rsquo;s capability and attributes to the newly created node with updated offset to indicate that the memory hasn&rsquo;t been freed yet.</p><p>After that, the memory manager insert the node into the free list. If the memory manager finds out that there are capabilities adjacent to the just-added node, then we simply need to update the attributes of the corresponding mmnode to indicate that merging succeeds. The old mmnode is simply thrown away.</p><p>The advantage of this implementation is that root or parent capabilities are kept around and the next retype will be fairly simple. The implementation is also very straightforward.</p><p>There is of course more efficient solution than a linked list. For example, Linux uses both linked list and red-black tree to store thread information. The redundant data structures can be used in different scenarios when appropriate. However, we only use this simplified version to prove our concepts. Optimizations vary but the general concept still works pretty well.</p></p></section></article><article class="post-entry tag-entry"><header class=entry-header><h2><a href=https://www.bodunhu.com/blog/posts/gpumemoryhierarchy/>Pascal GPU memory and cache hierarchy</a></h2></header><footer class=entry-footer>January 15, 2019&nbsp;·&nbsp;10 min</footer><section class=entry-content><p><p>Memory access efﬁciency is an important factor in fully utilizing the computational power of graphics processing units (GPUs). However, many GPU vendors like NVIDIA kept the GPU memory hierarchy as a secret. Therefore it becomes hard to measure GPUs performance and sets barriers to understand memory access patterns, which is a key component to improve program&rsquo;s performance. Here we introduce a novel fine-grained microbenchmark approach and apply to the Pascal generation. Turing architecture might have different results, but the method we used here can be applied as well with slight modification. The method we use in this guide is inspired by the research paper: <a href=https://ieeexplore.ieee.org/document/7445236>Dissecting GPU Memory Hierarchy through Microbenchmarking</a>. Here we will explain how P-Chase works and walk through a small example.</p><h2 id=memory-hierarchy-overview>Memory Hierarchy Overview</h2><p>GPU memory hierarchy is different compared to CPU memory hierarchy. Using the terminologies of CUDA, GPU memory space can be categorized in these groups: register, constant memory, shared memory, texture memory, local memory, and global memory. Each different memory space have its own properties. Since we are interested the
cache systems, here is a picture demonstrating the memory hierarchy of a NVIDIA GPU:</p><p align=center><img src=https://gistbok.ucgis.org/sites/default/files/1000px-Memory.svg_.png width=450></p><p align=center><a href=https://gistbok.ucgis.org/bok-topics/graphics-processing-units-gpus>Image source</a></p><p>The characteristics of each memory space can be found in <a href=https://developer.download.nvidia.com/compute/DevZone/docs/html/C/doc/CUDA_C_Programming_Guide.pdf>NVIDIA CUDA C Programming Guide
</a>. Here we will focus on some target memory space we are interested in. The paper lists some properties of our target memory space:</p><table><thead><tr><th>Memory</th><th style=text-align:center>Type</th><th style=text-align:right>Cached</th><th style=text-align:right>Scope</th></tr></thead><tbody><tr><td>Global</td><td style=text-align:center>R/W</td><td style=text-align:right>Yes</td><td style=text-align:right>All Threads</td></tr><tr><td>Shared</td><td style=text-align:center>R/W</td><td style=text-align:right>N/A</td><td style=text-align:right>Thread Blocks</td></tr><tr><td>Texture</td><td style=text-align:center>R</td><td style=text-align:right>Yes</td><td style=text-align:right>All Threads</td></tr></tbody></table><p>Even though the paper targets Fermi, Kepler and Maxwell generations of GPU, the properties of the table still holds for Pascal GPU and possibly Turing as well. The cached global/texture memory uses a two-level caching system. The L1 cache is located in each stream multiprocessor (SM), while the L2 cache is off-chip and shared among all SMs. It is unified for instruction, data and page table access. According to CUDA documentation, like Maxwell, Pascal combines the functionality of the L1 and texture caches into a unified L1/Texture cache which acts as a coalescing buffer for memory accesses, gathering up the data requested by the threads of a warp prior to delivery of that data to the warp. This function previously was served by the separate L1 cache in Fermi and Kepler. Page table is used by GPU to map virtual addresses to physical addresses, and is usually stored in the global memory. The page table is cached in TLB to reduce memory access latency. Once a thread cannot ﬁnd the page entry in the TLB, it would access the global memory to search in the page table, which introduced significant memory access latency. The GPU-specific shared memory is located in the SMs. On the Fermi and Kepler devices, it shares memory space with the L1 data cache. On Maxwell and Pascal devices, it has a dedicated space, since the functionality of the L1 and texture caches have been merged. One thing to note here is that shared memory is accessed by the thread blocks. Thread-blocks remain limited to 48 KB of shared memory in Pascal. Therefore, NVIDIA recommends that applications use at most 32 KB of shared memory in any one thread block. This would, for example, allow at least two thread blocks to fit per GP100 SM, or 3 thread blocks per GP104 SM.</p><p>However, we should be careful that by default, GP100 caches global loads in the L1/Texture cache. In contrast, GP104 follows Kepler and Maxwell in caching global loads in L2 only, unless using the LDG read-only data cache mechanism introduced in Kepler. As with previous architectures, GP104 allows the developer to opt-in to caching all global loads in the unified L1/Texture cache by passing the -Xptxas -dlcm=ca flag to nvcc at compile time. Even though both GP100 and GP104 belongs to Pascal family, we only focus on GP100 here because that&rsquo;s the GPU we use. Another thing to notice is that unlike Maxwell but similar to Kepler, Pascal caches thread-local memory in the L1 cache. This can mitigate the cost of register spills compared to Maxwell. To illustrate our point, we checked both cudaDevAttrGlobalL1CacheSupported and cudaDevAttrLocalL1CacheSupported on Tesla P100 and GTX 1080 and find both attributes to be 1.</p><p>In addition to the L2 data cache, global memory data that is read-only for the entire lifetime of a kernel can be cached in the read-only data cache with a compute capability of 3.5 or above. We will also explore the size of this read-only cache using __ldg() intrinsic.</p><h2 id=p-chase>P-Chase</h2><p>Most existing GPU microbenchmark studies on cache architecture assume a classical set-associative cache model with the least recently used (LRU) replacement policy, the same as the conventional CPU cache. So here we will use this assumption and proceed with our experiments. Here are some notations we will use throughout this post.</p><table><thead><tr><th>Notation</th><th style=text-align:center>Description</th><th style=text-align:right>Notation</th><th style=text-align:right>Description</th></tr></thead><tbody><tr><td>C</td><td style=text-align:center>Cache Size</td><td style=text-align:right>N</td><td style=text-align:right>array size</td></tr><tr><td>b</td><td style=text-align:center>cache line size</td><td style=text-align:right>s</td><td style=text-align:right>stride size</td></tr><tr><td>a</td><td style=text-align:center>cache associativity</td><td style=text-align:right>k</td><td style=text-align:right>iterations</td></tr><tr><td>T</td><td style=text-align:center>number of cache set</td><td style=text-align:right>r</td><td style=text-align:right>cache miss rate</td></tr></tbody></table><p>Under our assumptions, data is loaded from main memory to lower cache in the basic unit of a cache line. The number of words in a cache line is referred to as the line size (b). For the LRU set-associative cache, the cache memory is divided into T cache sets, each of which consists of \(a\) cache lines. It is essential to have these three assumptions using this kind of cache model:</p><ul><li><p><strong>Assumption 1</strong> All cache sets have the same size. The cache parameter should satisfy \(T \cdot a \cdot b = C\).</p></li><li><p><strong>Assumption 2</strong> In the memory address, the bits representing the cache set are immediately followed by the bits representing the offset.</p></li><li><p><strong>Assumption 3</strong> Cache replacement policy should be LRU.</p></li></ul><p>We will later see why these assumptions are essential as we proceed with the experiment. We won&rsquo;t go through how P-Chase work exactly. To find more information, this <a href=https://arxiv.org/pdf/1509.02308.pdf>paper</a> does a good job illustrating how P-Chase work. The takeaway is, we need to brute force an array with one element more than a cache can hold so that cache miss will start to occur periodically whereas such array with less or equal elements to the cache capacity will always result in cache hit and thus no access overhead will be introduced after all data is loaded into the cache. This is the algorithm the paper proposed and we will use it to do the experiment:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c>__global__ <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>KernelFunction</span> ( . . . ) {
    <span style=color:#75715e>//declare shared memory space
</span><span style=color:#75715e></span>    __shared__ <span style=color:#66d9ef>unsigned</span> <span style=color:#66d9ef>int</span> s tvalue [ ] ;
    __shared__ <span style=color:#66d9ef>unsigned</span> <span style=color:#66d9ef>int</span> s index [ ] ;
    preheat the data ; <span style=color:#75715e>// implementation varies
</span><span style=color:#75715e></span>    <span style=color:#66d9ef>for</span> (it <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; it <span style=color:#f92672>&lt;</span> iter ; it<span style=color:#f92672>++</span>) {
        start_time<span style=color:#f92672>=</span>clock();
        j <span style=color:#f92672>=</span> my_array[j];
        <span style=color:#75715e>//store the array index
</span><span style=color:#75715e></span>
        <span style=color:#75715e>// This following line is essential because due to
</span><span style=color:#75715e></span>        <span style=color:#75715e>// instruction-level parallelism (ILP), function clock() may
</span><span style=color:#75715e></span>        <span style=color:#75715e>// overlap with its previous instruction and even return before
</span><span style=color:#75715e></span>        <span style=color:#75715e>// the previous instruction finishes. For example,
</span><span style=color:#75715e></span>        <span style=color:#75715e>// end_time=clock() can return before j = my_array[j] returns.
</span><span style=color:#75715e></span>        <span style=color:#75715e>// adding s_index [it]= j since it have data dependency on the
</span><span style=color:#75715e></span>        <span style=color:#75715e>// previous line. Thus the memory access will be over before
</span><span style=color:#75715e></span>        <span style=color:#75715e>// end_time=clock() started.
</span><span style=color:#75715e></span>        s_index [it]<span style=color:#f92672>=</span> j;
        end_time<span style=color:#f92672>=</span>clock();
        <span style=color:#75715e>//store the access latency
</span><span style=color:#75715e></span>        s_tvalue[it]<span style=color:#f92672>=</span> end_time<span style=color:#960050;background-color:#1e0010>−</span>start_time ;
    }
}
</code></pre></div><p>The steps is the same as the paper proposes, so here we show the paper&rsquo;s method:</p><ol><li><p>Determine cache size C . We set s to 1. We then initialize N with a small value and increase it gradually until the ﬁrst cache miss appears. C equals the maximum N where all memory accesses are cache hits.</p></li><li><p>Determine cache line size b. We set s to 1. We begin with N = C + 1 and increase N gradually again. When N &lt; C + b + 1, the numbers of cache misses are close. When N is increased to C + b + 1, there is a sudden increase on the number of cache misses, despite that we only increase N by 1. Accordingly we can ﬁnd b. Based on the memory access patterns, we can also have a general idea on the cache replacement policy.</p></li><li><p>Determine number of cache sets T . We set s to b. We then start with N = C and increase N at the granularity of b. Every increment causes cache misses of a new cache set. When N > C + (T − 1)b, all cache sets are missed. We can then deduce T from cache miss patterns accordingly.</p></li><li><p>Determine cache replacement policy. As mentioned before, if the cache replacement policy is LRU, then the memory access process should be periodic and all the cache ways in the cache set are missed. If memory access process is aperiodic, then the replacement policy cannot be LRU. Under this circumstance, we set N = C + b, s = b with a considerable large k (k &#187; N/s) so that we can traverse the array multiple times. All cache misses are from one cache set. Every cache miss is caused by its former cache replacement because we overﬂow the cache by only one cache line. We have the accessed data indices thus we can reproduce the full memory access process and ﬁnd how the cache lines are updated.</p></li></ol><h2 id=texture-l1-cache-and-read-only-data-cache>Texture L1 Cache and Read-only Data Cache</h2><p>When use the <a href=http://www.comp.hkbu.edu.hk/~chxw/Code/fine_grain_Maxwell_texture_L1.cu>code</a> with increased our own data preheat implementation because the texture L1 cache can potentially be greater than the shared memory. The original code uses the first iteration of the loop in the algorithm as a way to preheat data:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=color:#66d9ef>const</span> <span style=color:#66d9ef>int</span> it <span style=color:#f92672>=</span>  <span style=color:#ae81ff>6144</span> <span style=color:#75715e>// texture L1 may hold more elements,
</span><span style=color:#75715e></span>                     <span style=color:#75715e>// So the first iteration may not cold
</span><span style=color:#75715e></span>                     <span style=color:#75715e>// hit all elements, some cold hits can
</span><span style=color:#75715e></span>                     <span style=color:#75715e>// be moved to the second iteration,
</span><span style=color:#75715e></span>                     <span style=color:#75715e>// causing confusion
</span><span style=color:#75715e></span><span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>int</span> cnt<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>; cnt <span style=color:#f92672>&lt;</span> it; cnt<span style=color:#f92672>++</span>) {
	start<span style=color:#f92672>=</span>clock();
        j<span style=color:#f92672>=</span>tex1Dfetch(tex_ref, j);
	s_value[cnt] <span style=color:#f92672>=</span> j;
			
	end<span style=color:#f92672>=</span>clock();			
	s_tvalue[cnt] <span style=color:#f92672>=</span> (end <span style=color:#f92672>-</span>start);
}
</code></pre></div><p>However, if texture L1 cache is greater than the shared memory allowed for each thread block, then some reads in the second loop will trigger cache misses. But such misses are in fact cold misses, not misses caused after the texture L1 cache is completely filled up. One solution is increase iteration to a much larger number so that the first iteration will always fill up the texture L1 cache. Note that if you move the data
preheat out such as</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>int</span> cnt<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>; cnt <span style=color:#f92672>&lt;</span> it; cnt<span style=color:#f92672>++</span>) {
        tmp<span style=color:#f92672>=</span>tex1Dfetch(tex_ref, tmp);
}
</code></pre></div><p>The compiler can optimize this whole step out and thus nothing actually gets executed.</p><p>After we run the modified code, the result shows that the we the cache missed starts when we set our array size to 6145, indicating the texture L1 cache can hold 6144 ints, which is equivalent to 24 kb. We also notice that each miss is followed by 7 consecutive hits. This means the cache line size is 8 words(b = 32 bytes). The structure of the L1 TLB is shown below, notice there are 192 lines in each set:</p><table><thead><tr><th>Set1</th><th style=text-align:center>Set2</th><th style=text-align:right>Set3</th><th style=text-align:right>Set4</th></tr></thead><tbody><tr><td>1-8</td><td style=text-align:center>33-40</td><td style=text-align:right>65-72</td><td style=text-align:right>97-104</td></tr><tr><td>9-16</td><td style=text-align:center>41-48</td><td style=text-align:right>&mldr;</td><td style=text-align:right>&mldr;</td></tr><tr><td>17-24</td><td style=text-align:center>46-56</td><td style=text-align:right>&mldr;</td><td style=text-align:right>&mldr;</td></tr><tr><td>25-32</td><td style=text-align:center>57-64</td><td style=text-align:right>89-96</td><td style=text-align:right>121-128</td></tr><tr><td>129-136</td><td></td><td></td><td></td></tr><tr><td>&mldr;</td><td style=text-align:center>&mldr;</td><td style=text-align:right>&mldr;</td><td style=text-align:right>&mldr;</td></tr><tr><td>2969-2976</td><td style=text-align:center>3001-3008</td><td style=text-align:right>3033-3040</td><td style=text-align:right>3065-3072</td></tr></tbody></table><p>According to CUDA documentation, GK110 adds the ability for read-only data in global memory to be loaded through the same cache used by the texture pipeline via a standard pointer without the need to bind a texture beforehand and without the sizing limitations of standard textures. The read-only data cache is loaded by calling __ldg(const restricted * address). We modified the code used to test texture L1 cache. The basic logic remains the same. When the arrays size is set to 6144 integers no cache misses occur with stride set as 32 (s=32 bytes). As soon as we increased one more element in the array cache misses start occurring. This shows the read-only cache is 24kb. We then noticed that the misses occur in a group of either 4 or 8. We infer the cache line to be 32 bytes and the replacement policy is LRU, same as Maxwell. We we increase the array to include 6248 elements(6144+32<em>3+8, 6144 is the max capacity of the cache, 32 consecutive number in a set, 32</em>3 to cause cache miss in set1, set2, and set3, only need to include 8 more to cause cache miss in set4 since s=32bytes), no caches hits occur. Therefore, we infer the caches set number to be 4, each cache line is 32 bytes, and each set contains 192 cache lines, the same as the texture L1 cache. The memory mapping seems arbitrary because the hit and miss patterns didn&rsquo;t follow that of the texture L1 cache.</p></p></section></article><footer class=page-footer><nav class=pagination><a class=prev href=https://www.bodunhu.com/blog/tags/os/>« Prev Page</a>
<a class=next href=https://www.bodunhu.com/blog/tags/os/page/3/>Next Page »</a></nav></footer></main><footer class=footer><span>&copy; 2021 <a href=https://www.bodunhu.com/blog/>std::bodun::blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)"><button class=top-link id=top-link type=button accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></button></a>
<script>let menu=document.getElementById('menu');menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)},document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script></body></html>