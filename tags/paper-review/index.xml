<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>paper-review on std::bodun::blog</title><link>https://www.bodunhu.com/blog/tags/paper-review/</link><description>Recent content in paper-review on std::bodun::blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 31 Aug 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://www.bodunhu.com/blog/tags/paper-review/index.xml" rel="self" type="application/rss+xml"/><item><title>In-Network Aggregation for Shared Machine Learning Clusters</title><link>https://www.bodunhu.com/blog/posts/in-network-aggregation-for-shared-machine-learning-clusters/</link><pubDate>Tue, 31 Aug 2021 00:00:00 +0000</pubDate><guid>https://www.bodunhu.com/blog/posts/in-network-aggregation-for-shared-machine-learning-clusters/</guid><description>This &lt;a href="https://proceedings.mlsys.org/paper/2021/file/eae27d77ca20db309e056e3d2dcd7d69-Paper.pdf" target="_blank" rel="noopener">paper&lt;/a> by Nadeen appeared in MLSys 2021. It presents an in-network aggregation framework called &lt;em>PANAMA&lt;/em> for distributed ML training tasks. &lt;em>PANAMA&lt;/em> has two components: (1) an in-network hardware accelerator with support for floating-point gradient aggregation; (2) a domain-specific load-balancing and congestion control protocol</description></item></channel></rss>