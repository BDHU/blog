<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>2023 on std::bodun::blog</title><link>https://www.bodunhu.com/blog/categories/2023/</link><description>Recent content in 2023 on std::bodun::blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 19 Apr 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://www.bodunhu.com/blog/categories/2023/index.xml" rel="self" type="application/rss+xml"/><item><title>SHEPHERD: Serving DNNs in the Wild</title><link>https://www.bodunhu.com/blog/posts/shepherd-serving-dnns-in-the-wild/</link><pubDate>Wed, 19 Apr 2023 00:00:00 +0000</pubDate><guid>https://www.bodunhu.com/blog/posts/shepherd-serving-dnns-in-the-wild/</guid><description>Paper link: SHEPHERD: Serving DNNs in the Wild
Achieving scalability, high system goodput and maximize resource utilization, at the same time is hard for an inference system.
while individual request streams can be highly unpredictable, aggregating request streams into moderately-sized groups greatly improves predictability, permitting high resource utilization as well as scalability
SHEPHERD&amp;rsquo;s main observation is</description></item></channel></rss>