<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>2019 on std::bodun::blog</title>
    <link>https://www.bodunhu.com/blog/categories/2019/</link>
    <description>Recent content in 2019 on std::bodun::blog</description>
    <image>
      <url>https://www.bodunhu.com/blog/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://www.bodunhu.com/blog/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Tue, 17 Sep 2019 00:00:00 +0000</lastBuildDate><atom:link href="https://www.bodunhu.com/blog/categories/2019/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Understanding Probabilistic Clock Synchronization</title>
      <link>https://www.bodunhu.com/blog/posts/probabilistic_clock_synchronization/</link>
      <pubDate>Tue, 17 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.bodunhu.com/blog/posts/probabilistic_clock_synchronization/</guid>
      <description>This post is meant to discuss the probabilistic clock synchronization technique. The main goal of this technique is to bound the difference between systems by setting up an upper bound. In short, \(|P(t)-Q(t)|\leq \varepsilon\). We will discuss what these symbols represent later.
 Perfect Synchronization The motivation behind this technique is that synchronization always involves overheads. In a perfect environment where network delay and request processing time are both 0, the clocks can be synchronized with ease.</description>
    </item>
    
    <item>
      <title>How to Put Papers on ArXiv</title>
      <link>https://www.bodunhu.com/blog/posts/arxivsubmition/</link>
      <pubDate>Tue, 25 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.bodunhu.com/blog/posts/arxivsubmition/</guid>
      <description>I was recently trying to put my research paper draft on ArXiv. I thought it would be as simple as submitting the pdf file, which should take approximately less than ten minutes. I was wrong. It took several hours to figure what was going on. I included some tips here to prevent mistakes I made from happening again.
 The first mistake I made was assuming a single submission of pdf file would be sufficient.</description>
    </item>
    
    <item>
      <title>A Little Review on Barrelfish Memory Management </title>
      <link>https://www.bodunhu.com/blog/posts/operatingsystemmemorymanagement/</link>
      <pubDate>Mon, 18 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.bodunhu.com/blog/posts/operatingsystemmemorymanagement/</guid>
      <description>The memory management has been mentioned numerous times and still remains huge topic. virtual vs. physical memory, physical frame allocation, MMUs, page faults, address space layout, and demand paging and swapping are familiar terms for every undergrad in college.
In monolithic kernels such as Linux, much of the functionality is handled in kernel. However, there are OSes that push these functionalities to user space such as Barrelfish. Many concept here will thus be borrowed from the Barrelfish OS.</description>
    </item>
    
    <item>
      <title>Pascal GPU memory and cache hierarchy</title>
      <link>https://www.bodunhu.com/blog/posts/gpumemoryhierarchy/</link>
      <pubDate>Tue, 15 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.bodunhu.com/blog/posts/gpumemoryhierarchy/</guid>
      <description>Memory access efÔ¨Åciency is an important factor in fully utilizing the computational power of graphics processing units (GPUs). However, many GPU vendors like NVIDIA kept the GPU memory hierarchy as a secret. Therefore it becomes hard to measure GPUs performance and sets barriers to understand memory access patterns, which is a key component to improve program&amp;rsquo;s performance. Here we introduce a novel fine-grained microbenchmark approach and apply to the Pascal generation.</description>
    </item>
    
  </channel>
</rss>
